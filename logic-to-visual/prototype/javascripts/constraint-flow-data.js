export const STEPS = [{"tag": "Overview", "title": "Constraint Collection Flow", "nodes": [], "body": "\n<p>The full lifecycle of how the timeboxing agent discovers, stores, and applies\nscheduling preferences. Use the steps on the left to walk through each part.</p>\n<ul class=\"fact-list\">\n  <li><b>Phase 1 â€” Blue</b> â€” live extraction from the Slack conversation</li>\n  <li><b>Stores â€” Yellow/Green</b> â€” Notion DB (durable) and SQLite (session-scoped)</li>\n  <li><b>Phase 2 â€” Purple</b> â€” background prefetch triggered at date commit</li>\n  <li><b>Phase 3 â€” Orange</b> â€” Notion query with server-side filters</li>\n  <li><b>Phase 4 â€” Green</b> â€” post-retrieval dedup, suppression, metadata</li>\n  <li><b>Red</b> â€” final merge into <code>session.active_constraints</code></li>\n</ul>\n<div class=\"callout info\">Use â† â†’ arrow keys to step through, or click the sidebar buttons.</div>\n"}, {"tag": "Step 1 of 8", "title": "The two constraint stores", "nodes": ["stores", "stores.notion_db", "stores.sqlite_db"], "body": "\n<p>There are <b>two separate stores</b>, each with a different role.</p>\n<ul class=\"fact-list\">\n  <li><b>Notion (TB Constraints DB)</b> â€” durable, cross-session memory. Lives forever.\n      Stores preferences like \"no meetings before 9am.\"</li>\n  <li><b>SQLite (Session Store)</b> â€” session-scoped scratch space, only for the current\n      Slack thread. Stores constraints extracted live, proposed but not yet locked.</li>\n</ul>\n<div class=\"callout info\">Notion is the source of truth for preferences. SQLite is the\nfast local cache and current-session workspace. <code>_collect_constraints()</code> merges both.</div>\n"}, {"tag": "Step 2 of 8", "title": "Live extraction from Slack", "nodes": ["extraction", "extraction.slack", "extraction.llm_agent", "extraction.notion_extractor"], "body": "\n<p>Every time the user sends a message, an <b>LLM constraint agent</b> runs in the background.</p>\n<ul class=\"fact-list\">\n  <li>The LLM reads the conversation and extracts scheduling preferences the user stated</li>\n  <li>E.g. <em>\"I want to exercise in the morning\"</em>, <em>\"no calls after 5pm\"</em></li>\n  <li>The extractor writes new constraints to <b>Notion</b>, deduped by UID</li>\n  <li>A session copy also goes to <b>SQLite</b> so the Slack UI can display them immediately</li>\n</ul>\n<div class=\"callout\">The LLM is told: never extract generic timeboxing definitions â€” only\nconcrete, user-stated preferences.</div>\n"}, {"tag": "Step 3 of 8", "title": "The prefetch trigger", "nodes": ["prefetch", "prefetch.date_commit", "prefetch.retriever"], "body": "\n<p>The durable prefetch is a <b>background task</b> fired as soon as the user commits\nto a planning date (Stage 0).</p>\n<ul class=\"fact-list\">\n  <li><code>_queue_durable_constraint_prefetch()</code> is called on date commit</li>\n  <li>It runs in the background â€” the user is not blocked</li>\n  <li>The agent awaits it (with a 20s timeout) before entering Stage 1</li>\n  <li>Keyed by <code>user_id:thread_ts:planned_date</code> to deduplicate concurrent calls</li>\n</ul>\n<div class=\"callout info\">This non-blocking pattern means Notion's network latency\ndoesn't delay the user's first response.</div>\n"}, {"tag": "Step 4 of 8", "title": "Building the query plan", "nodes": ["prefetch", "prefetch.query_plan", "prefetch.type_ids", "prefetch.mcp_server"], "body": "\n<p><b>ConstraintRetriever</b> builds a deterministic query plan from the current\nplanning context â€” no LLM involved.</p>\n<ul class=\"fact-list\">\n  <li>Derives which <b>event types</b> to request: immovables â†’ M, sleep â†’ R,\n      commutes â†’ C, habits â†’ H, gaps â†’ BU/BG</li>\n  <li>For stages beyond COLLECT, calls <code>query_types()</code> to get ranked\n      type_ids from Notion first</li>\n  <li>For Stage 1 (COLLECT), type_id lookup is skipped entirely â€” avoids extra\n      RPCs on the critical path</li>\n</ul>\n<div class=\"callout\">Gap-driven, not NLU. The retriever never interprets free-form text.</div>\n"}, {"tag": "Step 5 of 8", "title": "Server-side Notion filters", "nodes": ["filters", "filters.notion_store", "filters.filter_row", "filters.filter_row.date_filter", "filters.filter_row.scope_filter", "filters.filter_row.status_filter", "filters.filter_row.stage_filter", "filters.filter_row.event_filter"], "body": "\n<p><code>NotionConstraintStore.query_constraints()</code> applies several filters\n<b>in Notion</b> before any records come back.</p>\n<ul class=\"fact-list\">\n  <li><b>Date range</b>: <code>start_date â‰¤ today â‰¤ end_date</code> â€” empty fields mean\n      unbounded (the constraint always applies)</li>\n  <li><b>Scope</b>: <code>profile</code> always applies; <code>datespan</code> is\n      date-bounded; session-scoped stays in SQLite</li>\n  <li><b>Status</b>: only <code>locked</code> and <code>proposed</code> â€” declined excluded</li>\n  <li><b>Applies Stages</b>: each constraint declares which stages it is relevant to</li>\n  <li><b>Event Types</b>: each constraint declares which event types it governs (M, DW, SW, H, Râ€¦)</li>\n</ul>\n"}, {"tag": "Step 6 of 8", "title": "The startup_prefetch special case", "nodes": ["filters", "filters.startup_tag"], "body": "\n<p>Stage 1 (COLLECT_CONSTRAINTS) gets a special <b>first-pass query</b> before the main one.</p>\n<ul class=\"fact-list\">\n  <li>Tag filter <code>startup_prefetch</code> is applied</li>\n  <li>Scope is restricted to <code>profile</code> and <code>datespan</code> only</li>\n  <li>Pulls the user's always-on preferences <em>before</em> any LLM has seen the session</li>\n  <li>If this first pass returns results, those are returned and the main query is skipped</li>\n</ul>\n<div class=\"callout\">Goal: load the most important \"always applies\" constraints onto the\nLLM's context as fast as possible, using a deterministic tag rather than a semantic search.</div>\n"}, {"tag": "Step 7 of 8", "title": "Post-retrieval processing", "nodes": ["postprocess", "postprocess.dedup", "postprocess.suppress", "postprocess.dow"], "body": "\n<p>After records come back from Notion, three things happen client-side.</p>\n<ul class=\"fact-list\">\n  <li><b>Deduplicate by UID</b>: startup pass + main pass may return the same record;\n      first-seen wins</li>\n  <li><b>Filter suppressed UIDs</b>: if the user declined a constraint this session,\n      it's excluded even if Notion still has it as <em>proposed</em></li>\n  <li><b>days_of_week metadata</b>: the <code>days_of_week</code> field (MOâ€“SU) is\n      <em>not</em> filtered server-side â€” it's surfaced as metadata to the planning\n      LLM, which must respect it when filling the skeleton</li>\n</ul>\n<div class=\"callout info\">Weekend/holiday constraints are modelled as\n<code>scope=datespan</code> with explicit date bounds, or as\n<code>days_of_week=[SA,SU]</code> constraints the LLM reasons about.</div>\n"}, {"tag": "Step 8 of 8", "title": "Merge into active_constraints", "nodes": ["collect", "active", "stores.sqlite_db"], "body": "\n<p><code>_collect_constraints()</code> is the final assembly point, called at the\nstart of every stage.</p>\n<ul class=\"fact-list\">\n  <li>Reads <b>durable constraints by stage</b> from\n      <code>session.durable_constraints_by_stage</code> (populated by the prefetch)</li>\n  <li>Reads <b>session-local constraints</b> from SQLite for the current thread</li>\n  <li>Deduplicates the combined list and removes any with <code>status=DECLINED</code></li>\n  <li>Result stored on <code>session.active_constraints</code> and injected into every\n      subsequent LLM planning prompt</li>\n</ul>\n<div class=\"callout\">Every stage gate, skeleton draft, refine, and review call starts\nfrom this same merged list â€” one consistent view of constraints throughout the session.</div>\n"}];
export const NODE_IDS = ["extraction.slack", "extraction.llm_agent", "extraction.notion_extractor", "stores.notion_db", "stores.sqlite_db", "prefetch.date_commit", "prefetch.retriever", "prefetch.query_plan", "prefetch.type_ids", "prefetch.mcp_server", "filters.notion_store", "filters.filter_row.date_filter", "filters.filter_row.scope_filter", "filters.filter_row.status_filter", "filters.filter_row.stage_filter", "filters.filter_row.event_filter", "filters.startup_tag", "postprocess.dedup", "postprocess.suppress", "postprocess.dow", "collect", "active", "extraction", "stores", "prefetch", "filters", "filters.filter_row", "postprocess"];
export const DETAIL_PANELS = {"stores": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ—„</span> Constraint Stores â€” Overview</div>\n<p>Two stores, two roles. Notion is the durable cross-session source of truth; SQLite is the fast session-scoped workspace written to immediately on extraction so the Slack UI can display constraints without waiting for Notion round-trips.</p>\n<table class=\"er-table\"><thead><tr><th>Store</th><th>Scope</th><th>Survives session?</th><th>Written by</th></tr></thead>\n<tbody>\n  <tr><td class=\"pk\">Notion TB Constraints DB</td><td>profile / datespan</td><td>âœ… Yes</td><td>NotionConstraintExtractor (via MCP upsert)</td></tr>\n  <tr><td class=\"pk\">SQLite timeboxing_constraints</td><td>session (thread_ts)</td><td>âŒ No</td><td>ConstraintStore.add_constraints() immediately on extraction</td></tr>\n</tbody></table>\n<p style=\"margin-top:8px\">At each stage boundary, <code>_collect_constraints()</code> merges both stores, deduplicates by UID, removes DECLINED records, and caches the result on <code>session.active_constraints</code>.</p>\n<p>Click <b>stores.notion_db</b> or <b>stores.sqlite_db</b> individually for full schemas.</p>\n", "stores.notion_db": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ“‹</span> Notion â€” TB Constraints DB Schema</div>\n<p style=\"margin-bottom:8px\">Populated by <code>_queue_durable_prefetch_stage()</code> â†’ stored in <code>session.durable_constraints_by_stage[stage]</code>. On a date change, the entire dict is reset and re-fetched.</p>\n<table class=\"er-table\">\n<thead><tr><th>Field</th><th>Type</th><th>Notes</th></tr></thead>\n<tbody>\n<tr><td class=\"pk\">uid</td><td>Title</td><td>Idempotency key â€” e.g. <code>user:no-calls-after-5pm</code>. Upsert key.</td></tr>\n<tr><td>name</td><td>Rich Text</td><td>Short human-scannable label</td></tr>\n<tr><td>description</td><td>Rich Text</td><td>One-sentence operational meaning</td></tr>\n<tr><td>necessity</td><td>Select</td><td><code>must</code> | <code>should</code></td></tr>\n<tr><td>status</td><td>Select</td><td><code>proposed</code> | <code>locked</code> | <code>declined</code></td></tr>\n<tr><td>scope</td><td>Select</td><td><code>profile</code> = always applies Â· <code>datespan</code> = date-bounded Â· <code>session</code> = SQLite only</td></tr>\n<tr><td>source</td><td>Select</td><td><code>user</code> | <code>calendar</code> | <code>system</code> | <code>feedback</code></td></tr>\n<tr><td>start_date / end_date</td><td>Date</td><td>Null = unbounded. Server-side filter: <code>start â‰¤ today â‰¤ end</code>.</td></tr>\n<tr><td>applies_stages</td><td>Multi-select</td><td>CollectConstraints Â· CaptureInputs Â· Skeleton Â· Refine Â· ReviewCommit</td></tr>\n<tr><td>applies_event_types</td><td>Multi-select</td><td>M Â· C Â· DW Â· SW Â· H Â· R Â· BU Â· BG Â· PR</td></tr>\n<tr><td>days_of_week</td><td>Multi-select</td><td>MOâ€“SU. <em>Not filtered server-side</em> â€” surfaced as metadata to the planning LLM.</td></tr>\n<tr><td>tags</td><td>Multi-select</td><td>Routing tags, e.g. <code>startup_prefetch</code></td></tr>\n<tr><td>payload</td><td>JSON (Text)</td><td><code>rule_kind</code> Â· <code>windows[]</code> Â· <code>scalar_params</code></td></tr>\n<tr><td>topics</td><td>Multi-select</td><td>Routing/grouping tags assigned by the extractor agent</td></tr>\n</tbody></table>\n<div class=\"dp-file\">src/fateforger/adapters/notion/timeboxing_preferences.py</div>\n", "stores.sqlite_db": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ—„</span> SQLite â€” <code>timeboxing_constraints</code></div>\n<p>Session-scoped store. Written immediately on extraction so the Slack UI can display constraints without waiting for Notion.</p>\n<p style=\"margin-bottom:8px\">Also receives a mirrored copy of durable constraints via <code>_sync_durable_constraints_to_store()</code> after the prefetch completes â€” this lets the Slack UI show all active constraints in one place without separate Notion queries.</p>\n<table class=\"er-table\">\n<thead><tr><th>Column</th><th>Type</th><th>Notes</th></tr></thead>\n<tbody>\n<tr><td class=\"pk\">id</td><td>Integer PK</td><td>Auto-increment</td></tr>\n<tr><td>user_id</td><td>String</td><td>Slack user ID</td></tr>\n<tr><td>channel_id / thread_ts</td><td>String?</td><td>Session key â€” queries always filter by <code>thread_ts</code></td></tr>\n<tr><td>name / description</td><td>String</td><td></td></tr>\n<tr><td>necessity</td><td>Enum</td><td><code>must</code> | <code>should</code></td></tr>\n<tr><td>status</td><td>Enum</td><td><code>proposed</code> | <code>locked</code> | <code>declined</code></td></tr>\n<tr><td>scope</td><td>Enum</td><td><code>session</code> | <code>profile</code> | <code>datespan</code></td></tr>\n<tr><td>source</td><td>Enum</td><td><code>user</code> | <code>calendar</code> | <code>system</code> | <code>feedback</code></td></tr>\n<tr><td>confidence</td><td>Float 0â€“1</td><td>LLM confidence score on extraction</td></tr>\n<tr><td>start_date / end_date</td><td>Date?</td><td>Optional date bounds</td></tr>\n<tr><td>days_of_week</td><td>JSON</td><td>e.g. <code>[\"SA\", \"SU\"]</code></td></tr>\n<tr><td>tags / hints / selector</td><td>JSON</td><td>Routing metadata + event-type selector</td></tr>\n<tr><td>supersedes</td><td>JSON</td><td>List of UIDs this overrides</td></tr>\n<tr><td>created_at / updated_at</td><td>DateTime</td><td>Auto-managed by SQLAlchemy</td></tr>\n</tbody></table>\n<div class=\"dp-code\"># Queried by _collect_constraints():\nawait store.list_constraints(\n    user_id=session.user_id,\n    channel_id=session.channel_id,\n    thread_ts=session.thread_ts,\n)</div>\n<div class=\"dp-file\">src/fateforger/agents/timeboxing/preferences.py â€” class Constraint(ConstraintBase, table=True)</div>\n", "extraction": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ”µ</span> Phase 1 â€” Live Extraction Pipeline</div>\n<p>Every Slack message fires a concurrent background extraction. The user is never blocked â€” the main response is sent immediately while extraction runs in the background.</p>\n<div class=\"dp-flow\">\n  <div class=\"dp-flow-step\">ğŸ’¬ Message arrives â†’ <code>_queue_constraint_extraction(session, user_message)</code></div>\n  <div class=\"dp-flow-arrow\">â†“ dedup by <code>user_id:thread_ts:hash(message)</code></div>\n  <div class=\"dp-flow-step\">Async task: LLM reads conversation â†’ outputs <code>ConstraintBatch</code></div>\n  <div class=\"dp-flow-arrow\">â†“ parallel writes</div>\n  <div class=\"dp-flow-step\">â‘  SQLite write (immediate display) â€” via <code>ConstraintStore.add_constraints()</code></div>\n  <div class=\"dp-flow-step\">â‘¡ Notion upsert (durable) â€” via <code>_queue_durable_constraint_upsert()</code></div>\n  <div class=\"dp-flow-arrow\">â†“ on task complete</div>\n  <div class=\"dp-flow-step\"><code>pending_constraint_extractions.discard(task_key)</code></div>\n  <div class=\"dp-flow-step\"><code>_collect_constraints(session)</code> â€” refresh <code>active_constraints</code></div>\n</div>\n<p style=\"margin-top:8px\"><b>At stage boundaries</b> (e.g. entering Stage 1), <code>_await_pending_constraint_extractions()</code> waits for all in-flight extraction tasks before the stage gating LLM runs â€” so the gate always sees all extracted constraints.</p>\n<div class=\"dp-file\">src/fateforger/agents/timeboxing/agent.py â€” _queue_constraint_extraction()</div>\n", "extraction.slack": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ’¬</span> Slack Thread â€” How Extraction Is Triggered</div>\n<p>Incoming Slack messages are routed via <code>handlers.py</code> as <code>TimeboxingUserReply</code> messages. On every user reply, the session node calls <code>_queue_constraint_extraction()</code> before processing the main timeboxing flow.</p>\n<div class=\"dp-code\"># In the session message-handling node:\nself._orchestrator._queue_constraint_extraction(\n    session, user_message=msg.text\n)\n# â†’ doesn't block; launches background asyncio task\n# â†’ task_key = f\"{user_id}:{thread_ts}:{hash(text)}\"\n# â†’ deduplicated: same message won't spawn two tasks</div>\n<p>The <code>pending_constraint_extractions</code> set on the session object tracks all in-flight task keys. Before stage gating runs, the orchestrator awaits all pending tasks (20s timeout per task).</p>\n<div class=\"dp-file\">src/fateforger/agents/timeboxing/nodes/nodes.py Â· handlers.py</div>\n", "extraction.llm_agent": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ¤–</span> LLM Constraint Agent â€” Prompt + Input</div>\n<p><b>Input payload: <code>ConstraintHandoff</code></b></p>\n<div class=\"dp-code\">{\n  \"planned_date\": \"2026-02-24\",\n  \"timezone\": \"Europe/Amsterdam\",\n  \"stage_id\": \"CollectConstraints\",\n  \"user_utterance\": \"I don't want any meetings before 9am\",\n  \"triggering_suggestion\": null,\n  \"impacted_event_types\": [\"M\"],\n  \"suggested_tags\": [\"no-early-meetings\"],\n  \"decision_scope\": \"profile\"\n}</div>\n<p><b>System prompt key rules:</b></p>\n<ul style=\"font-size:12px;line-height:1.7;margin-left:16px;\">\n  <li>Default <code>status=proposed</code> unless user explicitly confirms/locks</li>\n  <li>Default <code>scope=profile</code> for \"usually / I prefer / in general\" statements</li>\n  <li>Use <code>scope=datespan</code> for \"this week / today / on Fridays\"</li>\n  <li>Use <code>scope=session</code> only for one-off overrides</li>\n  <li>Records must be MECE: governance Â· applicability Â· routing Â· rule_payload Â· lifecycle</li>\n  <li>If ambiguity remains: conservative defaults + single <code>clarifying_question</code></li>\n  <li><b>Never extract</b> generic timeboxing definitions â€” only concrete stated preferences</li>\n</ul>\n<div class=\"dp-code\">Allowed enums:\n- necessity:    must | should\n- status:       proposed | locked\n- scope:        session | profile | datespan\n- rule_kind:    prefer_window | avoid_window | fixed_bedtime\n                min_sleep | buffer | sequencing | capacity\n- days_of_week: MO | TU | WE | TH | FR | SA | SU\n- applies_stages: CollectConstraints | CaptureInputs\n                  Skeleton | Refine | ReviewCommit\n- applies_event_types: M | C | DW | SW | H | R | BU | BG | PR</div>\n<div class=\"dp-file\">src/fateforger/agents/timeboxing/notion_constraint_extractor.py â€” CONSTRAINT_EXTRACTOR_SYSTEM_PROMPT</div>\n", "extraction.notion_extractor": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ”—</span> NotionConstraintExtractor â€” Full Flow</div>\n<div class=\"dp-flow\">\n  <div class=\"dp-flow-step\"><code>extract_and_upsert(handoff: ConstraintHandoff)</code></div>\n  <div class=\"dp-flow-arrow\">â†“ AutoGen AssistantAgent (20s timeout)</div>\n  <div class=\"dp-flow-step\">1. LLM calls <code>constraint_query_types(stage, event_types)</code> â€” shortlist types</div>\n  <div class=\"dp-flow-step\">2. LLM calls <code>constraint_query_constraints(...)</code> â€” check for duplicates</div>\n  <div class=\"dp-flow-step\">3. LLM calls <code>constraint_upsert_constraint(record, event)</code> â€” write to Notion</div>\n  <div class=\"dp-flow-arrow\">â†“ returns JSON parsed to</div>\n  <div class=\"dp-flow-step\"><code>ConstraintExtractionOutput(uid, constraint_record, event_record)</code></div>\n</div>\n<p><b>On timeout or LLM failure:</b> returns <code>None</code>. The SQLite optimistic write already happened, so the Slack UI still has the constraint â€” only Notion durability is lost until the next extraction attempt.</p>\n<p><b>Output is also logged</b> via <code>constraint_log_event()</code> with event type <code>extracted</code>.</p>\n<div class=\"dp-file\">src/fateforger/agents/timeboxing/notion_constraint_extractor.py â€” class NotionConstraintExtractor</div>\n", "prefetch": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸŸ£</span> Phase 2 â€” Background Prefetch</div>\n<p>When the user commits to a planning date (Stage 0 / CaptureInputs), <code>_queue_durable_constraint_prefetch()</code> fires an async background task per stage.</p>\n<div class=\"dp-flow\">\n  <div class=\"dp-flow-step\">Date committed â†’ <code>_queue_durable_constraint_prefetch(user_id, thread_ts, date)</code></div>\n  <div class=\"dp-flow-arrow\">â†“ one background task per stage (CollectConstraints + others)</div>\n  <div class=\"dp-flow-step\"><code>_queue_durable_prefetch_stage(session, stage, planned_date)</code></div>\n  <div class=\"dp-flow-arrow\">â†“ on success</div>\n  <div class=\"dp-flow-step\"><code>session.durable_constraints_by_stage[stage] = constraints</code></div>\n  <div class=\"dp-flow-step\"><code>_sync_durable_constraints_to_store()</code> â€” mirror to SQLite</div>\n  <div class=\"dp-flow-step\"><code>_collect_constraints(session)</code> â€” refresh active set</div>\n</div>\n<p><b>Date change reset:</b> if the user changes the planning date, <code>durable_constraints_by_stage = {}</code> and all loaded-stage markers are cleared. The prefetch restarts for the new date.</p>\n<p><b>Stage-entry wait:</b> <code>_await_pending_durable_constraint_prefetch()</code> waits (20s) before Stage 1 gating so the LLM always sees loaded constraints.</p>\n<div class=\"dp-file\">src/fateforger/agents/timeboxing/agent.py</div>\n", "prefetch.date_commit": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ“…</span> Stage 0: Date Commit â€” Prefetch Trigger</div>\n<p>Stage 0 (<code>CaptureInputs</code>) is when the user settles on the planning date. This event triggers the prefetch <em>and</em> resets any stale prefetch if the date changed.</p>\n<div class=\"dp-code\"># If date changed from a previous session:\nif session.durable_constraints_date != planned_date:\n    session.durable_constraints_by_stage = {}\n    session.durable_constraints_loaded_stages = set()\n    session.pending_durable_constraints = False\n    session.durable_constraints_failed_stages = {}\n    session.durable_constraints_date = None\n\n# Then queue fresh prefetch:\n_queue_durable_constraint_prefetch(\n    session, planned_date=planned_date\n)</div>\n<p>Deduplication: if <code>durable_constraints_date == planned_date</code> and the stage is already in <code>durable_constraints_loaded_stages</code>, the task is skipped â€” no double-fetch.</p>\n", "prefetch.retriever": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ”</span> ConstraintRetriever.retrieve()</div>\n<p>Pure deterministic orchestration â€” no LLM involved. Translates the current planning context into a Notion MCP query.</p>\n<div class=\"dp-flow\">\n  <div class=\"dp-flow-step\">1. <code>_build_query_plan(stage, planned_date, event_types)</code></div>\n  <div class=\"dp-flow-arrow\">â†“ if stage â‰  COLLECT_CONSTRAINTS</div>\n  <div class=\"dp-flow-step\">2. <code>query_types(stage, event_types)</code> â†’ ranked <code>type_ids[]</code></div>\n  <div class=\"dp-flow-arrow\">â†“ always</div>\n  <div class=\"dp-flow-step\">3. <code>query_constraints(filters, type_ids, tags)</code> via MCP</div>\n  <div class=\"dp-flow-arrow\">â†“ returns</div>\n  <div class=\"dp-flow-step\"><code>List[ConstraintRecord]</code> (already server-filtered)</div>\n</div>\n<p>For Stage 1 (COLLECT_CONSTRAINTS), step 2 is entirely skipped to avoid the extra Notion RPC on the critical path. type_ids are not needed because Stage 1 uses coarse scope + date + status filters only.</p>\n<div class=\"dp-file\">src/fateforger/agents/timeboxing/ â€” ConstraintRetriever</div>\n", "prefetch.query_plan": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ“</span> Build Query Plan â€” Gap-Driven Event Types</div>\n<p>The query plan is derived from the current <b>planning stage</b> and a <b>gap analysis</b> of the skeleton â€” which event types are still unplaced. This is deterministic; no LLM needed.</p>\n<table class=\"er-table\">\n<thead><tr><th>Gap / context</th><th>Event types requested</th><th>Why</th></tr></thead>\n<tbody>\n<tr><td>No plan yet / Stage 1</td><td>all types</td><td>Collect all profile defaults</td></tr>\n<tr><td>Immovable anchors missing</td><td>M (Meeting)</td><td>Fixed-time commitments</td></tr>\n<tr><td>Sleep anchor missing</td><td>R (Rest)</td><td>Bedtime / wake constraints</td></tr>\n<tr><td>Commute missing</td><td>C (Commute)</td><td>Transit time constraints</td></tr>\n<tr><td>Daily habits</td><td>H (Habit)</td><td>Recurring rituals</td></tr>\n<tr><td>Focus blocks missing</td><td>DW, SW</td><td>Deep / Shallow Work windows</td></tr>\n<tr><td>Buffer gaps</td><td>BU, BG</td><td>Unstructured / general buffers</td></tr>\n</tbody></table>\n<p style=\"margin-top:6px\">The plan is pure Python logic â€” no LLM call. This keeps the critical path deterministic and fast.</p>\n", "prefetch.type_ids": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ·</span> query_types() â€” Type ID Lookup</div>\n<p>Skipped entirely at Stage 1 (COLLECT_CONSTRAINTS) to avoid extra RPCs. Used at Skeleton/Refine/ReviewCommit to get ranked type IDs from the Notion constraint-type catalog, which allows more targeted queries.</p>\n<div class=\"dp-code\">constraint_query_types(\n  stage=\"Skeleton\",\n  event_types=[\"M\", \"DW\", \"SW\"]\n)\n# â†’ [type_id_1, type_id_2, ...]\n# These are passed as type_ids= to query_constraints()</div>\n<p>Type IDs are Notion page IDs for rows in the constraint-type catalog. Passing them narrows the constraint query to only constraints that governance rules say apply to those types at that stage.</p>\n", "prefetch.mcp_server": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ”Œ</span> Constraint Memory MCP â€” Tool Interface</div>\n<table class=\"er-table\">\n<thead><tr><th>Tool</th><th>Signature</th><th>Purpose</th></tr></thead>\n<tbody>\n<tr><td class=\"pk\">constraint_query_types</td><td><code>(stage, event_types)</code></td><td>List/rank constraint types relevant to stage+event</td></tr>\n<tr><td class=\"pk\">constraint_query_constraints</td><td><code>(filters, type_ids, tags, sort, limit)</code></td><td>Query with compound server-side filters</td></tr>\n<tr><td class=\"pk\">constraint_upsert_constraint</td><td><code>(record, event)</code></td><td>Create or update by UID (idempotent)</td></tr>\n<tr><td class=\"pk\">constraint_log_event</td><td><code>(event)</code></td><td>Log lifecycle event: extracted / confirmed / declined</td></tr>\n</tbody></table>\n<p style=\"margin-top:6px\">All tools are exposed via the <b>constraint-memory</b> MCP server. The extraction LLM agent and the retriever both call these tools â€” the agent via AutoGen tool-calling, the retriever via direct async MCP client calls.</p>\n<div class=\"dp-file\">scripts/constraint_mcp_server.py</div>\n", "filters": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸŸ </span> Phase 3 â€” Notion Query + Compound Filters</div>\n<p><code>NotionConstraintStore.query_constraints()</code> translates a <code>ConstraintQuery</code> object into a Notion compound filter and executes it server-side â€” no post-hoc filtering in Python for the main selection.</p>\n<p>Filters compose as: <code>AND(scope_filter, status_filter, date_filter, stage_filter, event_type_filter)</code>. Each sub-filter is a Notion property filter. The startup_prefetch pass adds a tags filter and runs separately before the main query.</p>\n<p>Click individual filter nodes for exact filter expressions.</p>\n", "filters.notion_store": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ“–</span> NotionConstraintStore.query_constraints()</div>\n<p>Full entry point. Runs two queries for Stage 1, one for all other stages.</p>\n<div class=\"dp-code\"># Stage 1 (CollectConstraints) flow:\n# 1. startup_prefetch first-pass\nresults = query(tags=[\"startup_prefetch\"],\n                scope=[\"profile\",\"datespan\"],\n                status=[\"proposed\",\"locked\"])\nif results:\n    return results  # skip main query\n\n# 2. Main query (fallback or non-Stage-1)\nresults = query(\n    scope=[\"profile\",\"datespan\"],\n    status=[\"proposed\",\"locked\"],\n    start_date__lte=planned_date,\n    end_date__gte=planned_date,\n    applies_stages__contains=stage,\n    applies_event_types__intersects=event_types,\n    type_ids=type_ids,\n)</div>\n<div class=\"dp-file\">src/fateforger/adapters/notion/timeboxing_preferences.py</div>\n", "filters.filter_row.date_filter": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ“…</span> Date Range Filter â€” Server-Side</div>\n<p>Applied in Notion as two separate property filter conditions, combined with AND:</p>\n<div class=\"dp-code\">AND(\n  OR(start_date IS EMPTY, start_date &lt;= planned_date),\n  OR(end_date   IS EMPTY, end_date   &gt;= planned_date)\n)</div>\n<p><b>Empty = unbounded:</b> a constraint with no <code>start_date</code> or <code>end_date</code> in Notion must evaluate as always-in-range. Both cells must be empty <em>or</em> within bounds.</p>\n<p><b>Example:</b> a constraint valid \"this week only\" has <code>start_date=Mon, end_date=Sun</code>. A permanent profile preference has both cells empty.</p>\n", "filters.filter_row.scope_filter": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ”­</span> Scope Filter</div>\n<p>Only <code>profile</code> and <code>datespan</code> constraints are fetched from Notion. Session-scoped constraints live only in SQLite and are merged later by <code>_collect_constraints()</code>.</p>\n<div class=\"dp-code\">scope IN [\"profile\", \"datespan\"]</div>\n<table class=\"er-table\" style=\"margin-top:8px\">\n<thead><tr><th>Scope</th><th>Meaning</th><th>Store</th></tr></thead>\n<tbody>\n<tr><td class=\"pk\">profile</td><td>Permanent user preference, always applies</td><td>Notion</td></tr>\n<tr><td class=\"pk\">datespan</td><td>Applies for a specific date range</td><td>Notion</td></tr>\n<tr><td class=\"pk\">session</td><td>One-off override for this thread only</td><td>SQLite only</td></tr>\n</tbody></table>\n", "filters.filter_row.status_filter": "\n<div class=\"dp-header\"><span class=\"dp-icon\">âœ…</span> Status Filter</div>\n<p>Only active constraints are returned from Notion. Declined constraints are excluded server-side.</p>\n<div class=\"dp-code\">status IN [\"proposed\", \"locked\"]\n# \"declined\" is excluded server-side</div>\n<p><b>Important nuance:</b> a constraint the user declined <em>in the current session</em> may still be <code>proposed</code> in Notion (user hasn't explicitly declined it durably). Those are handled post-retrieval by the <b>suppress step</b> using <code>session.suppressed_durable_uids</code>.</p>\n<p>Only when the user explicitly calls \"decline\" via the Slack UI does the MCP update Notion status to <code>declined</code>.</p>\n", "filters.filter_row.stage_filter": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ¯</span> Applies-Stages Filter</div>\n<p>Each constraint in Notion declares which planning stages it is relevant to. Only constraints that match the current stage are fetched â€” preventing irrelevant constraints from crowding the LLM context.</p>\n<div class=\"dp-code\">applies_stages CONTAINS current_stage_id\n# e.g. \"CollectConstraints\" | \"Skeleton\" | \"Refine\"\n# Multi-select in Notion â€” each tag is a stage name</div>\n<table class=\"er-table\" style=\"margin-top:8px\">\n<thead><tr><th>Stage</th><th>What's relevant</th></tr></thead>\n<tbody>\n<tr><td>CollectConstraints</td><td>All profile defaults / startup prefs</td></tr>\n<tr><td>Skeleton</td><td>Time-windows, work blocks, sleep rules</td></tr>\n<tr><td>Refine</td><td>Buffer rules, sequencing, capacity limits</td></tr>\n<tr><td>ReviewCommit</td><td>Commitment rules, finality constraints</td></tr>\n</tbody></table>\n", "filters.filter_row.event_filter": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ“‹</span> Event-Type Filter</div>\n<p>Each constraint declares which event categories it governs. Only constraints applicable to the event types in the current query plan are fetched.</p>\n<div class=\"dp-code\">applies_event_types INTERSECTS query_event_types</div>\n<table class=\"er-table\" style=\"margin-top:8px\">\n<thead><tr><th>Code</th><th>Event type</th></tr></thead>\n<tbody>\n<tr><td class=\"pk\">M</td><td>Meeting (fixed-time)</td></tr>\n<tr><td class=\"pk\">C</td><td>Commute</td></tr>\n<tr><td class=\"pk\">DW</td><td>Deep Work block</td></tr>\n<tr><td class=\"pk\">SW</td><td>Shallow Work block</td></tr>\n<tr><td class=\"pk\">H</td><td>Habit / ritual</td></tr>\n<tr><td class=\"pk\">R</td><td>Rest / sleep</td></tr>\n<tr><td class=\"pk\">BU / BG</td><td>Buffer (unstructured / general)</td></tr>\n<tr><td class=\"pk\">PR</td><td>Personal / other</td></tr>\n</tbody></table>\n", "filters.startup_tag": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ·</span> startup_prefetch Tag â€” Stage 1 Fast Path</div>\n<p>At Stage 1 (CollectConstraints) <em>only</em>, a first-pass query using a deterministic tag filter runs before the main query.</p>\n<div class=\"dp-flow\">\n  <div class=\"dp-flow-step\">Query: <code>tags CONTAINS \"startup_prefetch\"</code> AND <code>scope âˆˆ [profile, datespan]</code> AND <code>status âˆˆ [proposed, locked]</code></div>\n  <div class=\"dp-flow-arrow\">â†“ if results found</div>\n  <div class=\"dp-flow-step\">Return those results immediately â€” <b>skip main query entirely</b></div>\n  <div class=\"dp-flow-arrow\">â†“ if empty (no tagged constraints)</div>\n  <div class=\"dp-flow-step\">Fall through to full main query with all stage/event-type filters</div>\n</div>\n<p><b>Why this exists:</b> the startup_prefetch pass uses a simple tag filter rather than the full compound event-type + stage filter. It's faster and loads the user's always-on \"this is who I am\" preferences (<em>no early meetings, I exercise at 7am, I don't work after 6pm</em>) onto LLM context before any LLM has seen the session.</p>\n<p>Users add the <code>startup_prefetch</code> tag to their permanent profile constraints in Notion to mark them as \"always load first.\"</p>\n", "postprocess": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸŸ¢</span> Phase 4 â€” Post-Retrieval Processing</div>\n<p>After records come back from Notion (via the MCP server), three sequential client-side passes run before the constraints reach the active set.</p>\n<ol style=\"margin-left:18px;font-size:12.5px;line-height:1.9\">\n  <li><b>Deduplicate</b> â€” startup first-pass and main query may overlap. <code>_dedupe_constraints()</code> keeps the first-seen copy by identity key.</li>\n  <li><b>Suppress session overrides</b> â€” if the user's current-session inputs conflict with a loaded default, that default's UID is added to <code>session.suppressed_durable_uids</code> and filtered out. Detected by <code>_normalize_collect_constraints_gate()</code> comparing gate facts to constraint defaults.</li>\n  <li><b>days_of_week metadata</b> â€” <em>not</em> filtered; passed through as metadata. The planning LLM must respect it (e.g., \"this habit only on MOâ€“FR\").</li>\n</ol>\n<p>These three passes happen inside <code>_collect_constraints()</code> and also incrementally as the prefetch loads stages.</p>\n", "postprocess.dedup": "\n<div class=\"dp-header\"><span class=\"dp-icon\">â™»ï¸</span> Deduplicate â€” _dedupe_constraints()</div>\n<p>The startup first-pass and main query may return the same records. Deduplication uses an identity key (not just UID, since not all records have UIDs).</p>\n<div class=\"dp-code\">def _constraint_identity_key(c: Constraint) -> str:\n    # Prefer explicit UID if set\n    uid = _constraint_uid(c)\n    if uid:\n        return f\"uid:{uid}\"\n    # Fall back to name + scope + source\n    name = (c.name or \"\").strip().lower()\n    scope = (c.scope.value if c.scope else \"\")\n    source = (c.source.value if c.source else \"\")\n    return f\"name:{name}:{scope}:{source}\"\n\ndef _dedupe_constraints(constraints):\n    seen, result = set(), []\n    for c in constraints:\n        key = _constraint_identity_key(c)\n        if key not in seen:\n            seen.add(key)\n            result.append(c)\n    return result</div>\n<p>Dedup is applied on the combined <code>durable_constraints (all stages) + local_constraints (SQLite)</code> list, so a constraint extracted live in this session and also loaded from Notion won't appear twice.</p>\n<div class=\"dp-file\">src/fateforger/agents/timeboxing/agent.py</div>\n", "postprocess.suppress": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸš«</span> Suppress â€” Session Override Detection</div>\n<p>Durable defaults loaded from Notion may conflict with explicit inputs the user provides in the current session. When a conflict is detected, the constraint's UID is added to <code>session.suppressed_durable_uids</code> and hidden for the rest of the session â€” <em>without</em> writing a decline to Notion.</p>\n<div class=\"dp-code\"># In _normalize_collect_constraints_gate():\nfor domain, default_value in defaults[\"domain_values\"].items():\n    current_value = facts.get(domain)  # from Stage 1 gate output\n    if _facts_conflict_with_default(domain, current_value, default_value):\n        for uid in defaults[\"domain_uids\"].get(domain, []):\n            session.suppressed_durable_uids.add(uid)\n            suppressed_domains.append(domain)\n\n# On next _collect_stage_durable_constraints():\ndurable = [\n    c for c in session.durable_constraints_by_stage[stage]\n    if _constraint_uid(c) not in session.suppressed_durable_uids\n]</div>\n<p><b>Example:</b> Notion has a default \"work starts at 9am\". User says \"I'm starting at 7am today.\" The gate detects the conflict â†’ suppresses the <code>work-start-9am</code> UID for this session â†’ gate re-derives defaults without it â†’ uses 7am instead.</p>\n<p>A summary line is appended to the gate output: <em>\"Session override applied for work_window; matching saved defaults were hidden for this session.\"</em></p>\n<div class=\"dp-file\">src/fateforger/agents/timeboxing/agent.py â€” _normalize_collect_constraints_gate()</div>\n", "postprocess.dow": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ“†</span> days_of_week Metadata â€” Pass-Through</div>\n<p>The <code>days_of_week</code> field on each constraint (<code>MOâ€“SU</code> values) is <em>deliberately not filtered</em> server-side in Notion or post-retrieval in Python. Instead, it is surfaced as metadata in the TOON-encoded constraint block injected into the LLM system prompt.</p>\n<p>The planning LLM is responsible for checking: <em>\"Does this constraint's <code>days_of_week</code> cover today's day of week before applying it?\"</em></p>\n<div class=\"dp-code\"># In the skeleton prompt, the constraint row includes:\n# constraints[N]{name,necessity,scope,status,source,description}:\n# no-sa-su-meetings,must,profile,locked,user,No meetings on weekends\n# days_of_week=SA|SU is visible as description metadata\n\n# LLM reasoning: planning date is Monday â†’ SA|SU constraint\n# does not apply today â†’ skip it when placing M events</div>\n<p><b>Why not filter it?</b> Filtering requires knowing today's day of week at query time. The Notion filter API handles dates well but not day-of-week logic. Pushing this to the LLM is simpler and lets the LLM explain its reasoning in the plan.</p>\n", "collect": "\n<div class=\"dp-header\"><span class=\"dp-icon\">ğŸ”´</span> _collect_constraints() â€” Assembly Point</div>\n<p>Called at the start of every planning stage. Merges durable (Notion) + local (SQLite) constraints, deduplicates, strips suppressed UIDs and DECLINED records.</p>\n<div class=\"dp-code\">async def _collect_constraints(self, session: Session):\n    # 1. SQLite session-local constraints\n    local = await self._constraint_store.list_constraints(\n        user_id=session.user_id,\n        channel_id=session.channel_id,\n        thread_ts=session.thread_ts,\n    )\n\n    # 2. Durable constraints (all stages), suppressed filtered out\n    durable = [\n        c\n        for stage_constraints in\n            session.durable_constraints_by_stage.values()\n        for c in (stage_constraints or [])\n        if (uid := _constraint_uid(c)) is None\n           or uid not in session.suppressed_durable_uids\n    ]\n\n    # 3. Merge, deduplicate, strip DECLINED\n    combined = _dedupe_constraints(durable + list(local or []))\n    session.active_constraints = [\n        c for c in combined\n        if c.status != ConstraintStatus.DECLINED\n    ]\n    return list(session.active_constraints)</div>\n<p><b>When it is called:</b></p>\n<ul style=\"font-size:12px;line-height:1.75;margin-left:16px\">\n  <li>After each background extraction task completes</li>\n  <li>After the durable prefetch loads a stage</li>\n  <li>Explicitly before Stage 1 gating (after awaiting pending extractions)</li>\n  <li>After durable constraint upsert from the extractor</li>\n</ul>\n<div class=\"dp-file\">src/fateforger/agents/timeboxing/agent.py:3713</div>\n", "active": "\n<div class=\"dp-header\"><span class=\"dp-icon\">âš¡</span> session.active_constraints â€” Injection into LLM</div>\n<p>The final merged, filtered list. Injected into LLM prompts in two different formats depending on context:</p>\n\n<p><b>1. Skeleton/Refine system prompt â€” TOON-encoded table</b></p>\n<div class=\"dp-code\"># render_skeleton_draft_system_prompt() builds:\ntoon_encode(\n    name=\"constraints\",\n    rows=constraints_rows(context.constraints_snapshot),\n    fields=[\"name\",\"necessity\",\"scope\",\"status\",\"source\",\"description\"],\n)\n\n# Output in the LLM system prompt:\nconstraints[3]{name,necessity,scope,status,source,description}:\nno-early-meetings,must,profile,locked,user,No meetings before 9am\nexercise-morning,should,profile,proposed,user,Exercise block in morning\nno-work-after-6,must,profile,locked,user,Stop work by 6pm</div>\n<p>The TOON format is compact and token-efficient â€” it encodes structured tables without JSON verbosity. The LLM parses it as a typed record set.</p>\n\n<p style=\"margin-top:10px\"><b>2. Slack stage messages â€” plain text summary</b></p>\n<div class=\"dp-code\"># _format_constraints_section(constraints, limit=6):\n# â†’ [\"No meetings before 9am â€” must\",\n#    \"Exercise in the morning â€” should\",\n#    \"No work after 6pm â€” must\"]\n# Appended to the stage message as:\n# Constraints:\n# - No meetings before 9am â€” must\n# - Exercise in the morning â€” should\n# - No work after 6pm â€” must\n# ...and 2 more  (if > 6 constraints)</div>\n\n<p style=\"margin-top:10px\"><b>Stage usage:</b></p>\n<table class=\"er-table\">\n<thead><tr><th>Stage</th><th>Where constraints appear</th></tr></thead>\n<tbody>\n<tr><td>CollectConstraints</td><td>Stage 1 gate Slack message (up to 6, plain text)</td></tr>\n<tr><td>Skeleton</td><td>TOON block in <code>skeleton_draft_system_prompt.j2</code></td></tr>\n<tr><td>Refine</td><td>TOON block in refine system prompt</td></tr>\n<tr><td>ReviewCommit</td><td>Plain text summary in user-facing message</td></tr>\n</tbody></table>\n<div class=\"dp-file\">src/fateforger/agents/timeboxing/prompt_rendering.py Â· agent.py:3000</div>\n"};
export const EDGE_TOOLTIPS = {"user message": "\n<b>user message</b><br>\nVerbatim Slack text passed as <code>user_utterance</code> in the\n<code>ConstraintHandoff</code> JSON payload.<br>\nAlso includes: <code>planned_date</code>, <code>timezone</code>,\n<code>stage_id</code>, optional <code>impacted_event_types</code>\nand <code>suggested_tags</code>.\n", "proposed constraints": "\n<b>proposed constraints â†’ ConstraintBatch</b><br>\nOutput of the LLM extraction agent.<br>\nContains a list of <code>ConstraintBase</code> objects, each with:<br>\n<code>name, description, necessity, status=proposed,<br>\nscope, source, tags, selector, days_of_week, payload</code><br>\nStatus defaults to <code>proposed</code> unless the user\nexplicitly confirmed/locked it in the same message.\n", "upsert (deduped by UID)": "\n<b>upsert (deduped by UID)</b><br>\nThe extractor calls <code>constraint_upsert_constraint(record)</code>\nvia MCP. Records are keyed by <code>uid</code>.<br>\nIf a constraint with that UID already exists in Notion,\nit is <em>updated in-place</em> (fields merged) rather than\ncreating a duplicate. New UIDs are created as new Notion pages.\n", "session write": "\n<b>session write â€” optimistic SQLite copy</b><br>\nWritten <em>before</em> the Notion upsert completes, so the\nSlack UI can show the new constraint immediately.<br>\nKey: <code>(user_id, channel_id, thread_ts)</code><br>\nThis copy is always present; the Notion copy may lag\nby up to 20s (extractor timeout).\n", "fire async task": "\n<b>fire async task â€” non-blocking prefetch</b><br>\n<code>_queue_durable_constraint_prefetch()</code> schedules\nan asyncio task. The Slack response is not blocked.<br>\nDedup key: <code>user_id:thread_ts:planned_date:stage</code><br>\nIf <code>durable_constraints_date == planned_date</code> and\nthe stage is already in <code>durable_constraints_loaded_stages</code>,\nthe task is skipped entirely.\n", "stage != COLLECT": "\n<b>stage != COLLECT â€” type_id lookup path</b><br>\nFor Skeleton / Refine / ReviewCommit, the retriever calls\n<code>query_types(stage, event_types)</code> first to get\na ranked list of type IDs from the Notion constraint-type\ncatalog. These IDs narrow the <code>query_constraints()</code>\ncall to only semantically relevant types.\n", "COLLECT: direct": "\n<b>COLLECT: direct â€” no type_id lookup</b><br>\nAt Stage 1 (CollectConstraints), <code>query_types()</code>\nis skipped entirely to avoid extra Notion RPCs on the critical\npath. The MCP query uses only scope + status + date filters\n(plus the startup_prefetch first-pass tag).\n", "Stage 1 first-pass": "\n<b>Stage 1 first-pass â€” startup_prefetch tag</b><br>\nBefore the main query at Stage 1, a fast tag-filter query runs:\n<code>tags CONTAINS \"startup_prefetch\"</code><br>\nIf it returns results, the main query is skipped.<br>\nIf empty, the main compound query runs.<br>\nGoal: load always-on profile preferences onto LLM context\nas fast as possible without the full compound filter cost.\n", "durable constraints": "\n<b>durable constraints</b><br>\nComes from <code>session.durable_constraints_by_stage[stage]</code>\nâ€” populated by the background prefetch task.<br>\nAll stage values are flattened in <code>_collect_constraints()</code>.\nSuppressed UIDs (session overrides) are filtered out before merge.\n", "session-local constraints": "\n<b>session-local constraints</b><br>\nRead from SQLite: <code>SELECT * FROM timeboxing_constraints\nWHERE thread_ts = :current_thread AND user_id = :user_id</code><br>\nContains constraints extracted live in this conversation,\nplus any durable constraints mirrored via\n<code>_sync_durable_constraints_to_store()</code>.\n"};
