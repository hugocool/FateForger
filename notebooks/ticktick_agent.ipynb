{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88f9133",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "model_info is required when model name is not a valid OpenAI model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 64\u001b[0m\n\u001b[1;32m     26\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124mYou are TickTick-GPT, an autonomous productivity coach.\u001b[39m\n\u001b[1;32m     28\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124mYour first reply should greet the user and ask what they’d like to get done today.\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# List the tools\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# for i, tool in enumerate(tools[:10], 1):\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#     tool_name = getattr(tool, 'name', str(tool))\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#     tool_desc = getattr(tool, 'description', 'No description')\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#     print(f\"   {i}. {tool_name}: {tool_desc[:50]}...\")\u001b[39;00m\n\u001b[1;32m     62\u001b[0m agent \u001b[38;5;241m=\u001b[39m AssistantAgent(\n\u001b[1;32m     63\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticktick_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 64\u001b[0m     model_client\u001b[38;5;241m=\u001b[39m\u001b[43mOpenAIChatCompletionClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-5-2025-08-07\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOPENAI_API_KEY\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     68\u001b[0m     system_message\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     69\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools\n\u001b[1;32m     70\u001b[0m )\n",
      "File \u001b[0;32m~/VScode-projects/admonish-1/.venv/lib/python3.10/site-packages/autogen_ext/models/openai/_openai_client.py:1474\u001b[0m, in \u001b[0;36mOpenAIChatCompletionClient.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m client \u001b[38;5;241m=\u001b[39m _openai_client_from_config(copied_args)\n\u001b[1;32m   1472\u001b[0m create_args \u001b[38;5;241m=\u001b[39m _create_args_from_config(copied_args)\n\u001b[0;32m-> 1474\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_capabilities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_capabilities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_name_prefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_name_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_name_in_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_name_in_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VScode-projects/admonish-1/.venv/lib/python3.10/site-packages/autogen_ext/models/openai/_openai_client.py:435\u001b[0m, in \u001b[0;36mBaseOpenAIChatCompletionClient.__init__\u001b[0;34m(self, client, create_args, model_capabilities, model_info, add_name_prefixes, include_name_in_message)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_capabilities \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m model_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_info \u001b[38;5;241m=\u001b[39m \u001b[43m_model_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_info is required when model name is not a valid OpenAI model\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/VScode-projects/admonish-1/.venv/lib/python3.10/site-packages/autogen_ext/models/openai/_model_info.py:491\u001b[0m, in \u001b[0;36mget_info\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    480\u001b[0m model_info: ModelInfo \u001b[38;5;241m=\u001b[39m _MODEL_INFO\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    481\u001b[0m     resolved_model,\n\u001b[1;32m    482\u001b[0m     {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m     },\n\u001b[1;32m    489\u001b[0m )\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFAILED\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_info is required when model name is not a valid OpenAI model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m ModelFamily\u001b[38;5;241m.\u001b[39mUNKNOWN:\n\u001b[1;32m    493\u001b[0m     trace_logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel info not found for model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: model_info is required when model name is not a valid OpenAI model"
     ]
    }
   ],
   "source": [
    "\n",
    "from autogen_ext.tools.mcp import mcp_server_tools, StreamableHttpServerParams\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "# The issue might be that we need to configure the client properly for SSE\n",
    "# Let's try using the MCP client directly with the right configuration\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "params = StreamableHttpServerParams(\n",
    "    url=\"http://localhost:8002/mcp\",\n",
    "    timeout=10.0,\n",
    "#     headers={\n",
    "#         \"Accept\": \"application/json, text/event-stream\",\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    ")\n",
    "\n",
    "# TODO: write good prompts\n",
    "tools = await mcp_server_tools(params)\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are TickTick-GPT, an autonomous productivity coach.\n",
    "\n",
    "**Mission**\n",
    "1. Help the user clarify goals, break them into concrete, bite-sized tasks and projects.\n",
    "2. Manipulate the user’s TickTick workspace through the MCP tools you’ve been given\n",
    "   (create / update / search / complete tasks and projects).\n",
    "3. Apply a lightweight *Getting-Things-Done* mindset:\n",
    "   • “Engaged” list   ↔ high-priority, overdue, or due-today tasks  \n",
    "   • “Next actions”  ↔ medium-priority or due-tomorrow tasks  \n",
    "   • Everything else goes to the appropriate project / someday list.\n",
    "4. Always suggest the **next smallest action** the user can take.\n",
    "\n",
    "**When you respond**\n",
    "▪ Think step-by-step (but do not reveal chain-of-thought).  \n",
    "▪ Decide whether you need a tool call; if so, emit a JSON block exactly as the\n",
    "  Autogen tooling expects.  \n",
    "▪ Otherwise answer in plain English.  \n",
    "▪ Be brief, structured, and actionable (bullet lists & check-boxes welcome).  \n",
    "▪ Confirm destructive operations (“delete”, “batch_create”) before executing.\n",
    "\n",
    "**Examples**\n",
    "User : “What should I do next?”  \n",
    "Assistant : (1) call `get_engaged_tasks`; (2) summarise; (3) propose next action.  \n",
    "\n",
    "User : “Break down ‘Launch website’ into 4 tasks.”  \n",
    "Assistant : create 4 tasks via `batch_create_tasks` and then show a numbered list.\n",
    "\n",
    "Your first reply should greet the user and ask what they’d like to get done today.\n",
    "\"\"\"\n",
    "# List the tools\n",
    "# for i, tool in enumerate(tools[:10], 1):\n",
    "#     tool_name = getattr(tool, 'name', str(tool))\n",
    "#     tool_desc = getattr(tool, 'description', 'No description')\n",
    "#     print(f\"   {i}. {tool_name}: {tool_desc[:50]}...\")\n",
    "            \n",
    "agent = AssistantAgent(\n",
    "    name=\"ticktick_agent\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-5-2025-08-07\", \n",
    "        api_key=OPENAI_API_KEY\n",
    "    ),\n",
    "    system_message=prompt,\n",
    "    tools=tools\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270fa4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "result = await agent.run(task=\"What should I focus on today?\")\n",
    "print(result.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd63fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fateforger-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
