{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2c1f821b",
      "metadata": {},
      "source": [
        "# Goal\n",
        "\n",
        "to fetch the events from the calendar and edit them as a timebox given prompt and then write them back.\n",
        "\n",
        "That way we can give this as a tool to the schedular agent as well, so it can change a single event, but also reschedule the day as a whole if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ff203a39",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datetime.date(2026, 2, 3)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datetime import datetime, timedelta\n",
        "work_start_hour = 8 # TODO: move to settings\n",
        "is_before_work_start = datetime.now().time() < datetime.now().replace(hour=work_start_hour, minute=0, second=0, microsecond=0).time()\n",
        "# is_before_work_start = True\n",
        "today = datetime.now().date()\n",
        "day_to_plan = today if is_before_work_start else today + timedelta(days=1)\n",
        "day_to_plan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc76f68d",
      "metadata": {},
      "source": [
        "# now pull events from calendar for that date as a timebox object\n",
        "\n",
        "```mermaid\n",
        "\n",
        "flowchart TB\n",
        "  node_1(\"CalendarEvent\")\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "81bc3eff",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from datetime import datetime, date as date_type, time as time_type, timedelta, timezone\n",
        "from typing import Any, Iterable\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "from dateutil import parser as date_parser\n",
        "\n",
        "from fateforger.agents.schedular.models.calendar import CalendarEvent, EventType\n",
        "from fateforger.agents.timeboxing.timebox import Timebox\n",
        "\n",
        "\n",
        "from autogen_ext.tools.mcp import McpWorkbench, StreamableHttpServerParams\n",
        "\n",
        "from fateforger.core.config import settings\n",
        "\n",
        "\n",
        "# TODO: wrao this in a nice function\n",
        "\n",
        "def calendar_workbench() -> McpWorkbench:\n",
        "\n",
        "    return McpWorkbench(\n",
        "        StreamableHttpServerParams(url=settings.mcp_calendar_server_url, timeout=10.0)\n",
        "    )\n",
        "workbench = calendar_workbench()\n",
        "\n",
        "# query the workbench\n",
        "result = await workbench.call_tool(\n",
        "    \"list-events\", # TODO: what are all the args we can pass here?\n",
        "    arguments={\n",
        "        \"calendarId\": \"primary\",\n",
        "        \"timeMin\": \"2026-01-27T00:00:00Z\",\n",
        "        \"timeMax\": \"2026-01-28T00:00:00Z\",\n",
        "        \"singleEvents\": True,\n",
        "        \"orderBy\": \"startTime\",\n",
        "    },\n",
        ")\n",
        "\n",
        "raw_json_string = result.result[0].content\n",
        "\n",
        "# def get_timebox_for_day(day: date_type, timezone_str: str) -> Timebox:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6295882f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"events\":[{\"id\":\"30287b8c333b44c18b3bfbd52f357d4f\",\"summary\":\"morning review\",\"start\":{\"dateTime\":\"2026-01-27T13:00:00+01:00\",\"timeZone\":\"Europe/Amsterdam\"},\"end\":{\"dateTime\":\"2026-01-27T13:15:00+01:00\",\"timeZone\":\"Europe/Amsterdam\"},\"status\":\"confirmed\",\"htmlLink\":\"https://www.google.com/calendar/event?eid=MzAyODdiOGMzMzNiNDRjMThiM2JmYmQ1MmYzNTdkNGYgaHVnby5ldmVyc0Bt\",\"created\":\"2026-01-26T21:07:30.000Z\",\"updated\":\"2026-01-27T10:54:23.636Z\",\"colorId\":\"10\",\"creator\":{\"email\":\"hugo.evers@gmail.com\",\"self\":true},\"organizer\":{\"email\":\"hugo.evers@gmail.com\",\"self\":true},\"iCalUID\":\"30287b8c333b44c18b3bfbd52f357d4f@google.com\",\"sequence\":1,\"reminders\":{\"useDefault\":true},\"eventType\":\"default\",\"guestsCanModify\":true,\"calendarId\":\"primary\",\"accountId\":\"normal\"}],\"totalCount\":1}'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.result[0].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8c7c2648",
      "metadata": {},
      "outputs": [],
      "source": [
        "from fateforger.adapters.calendar.models import GCalEventsResponse\n",
        "\n",
        "gcal_events = GCalEventsResponse.model_validate_json(result.result[0].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0dcc011d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GCalEventsResponse(events=[GCalEvent(id='30287b8c333b44c18b3bfbd52f357d4f', summary='morning review', start=GCalEventDateTime(date_time='2026-01-27T13:00:00+01:00', date=None, time_zone='Europe/Amsterdam'), end=GCalEventDateTime(date_time='2026-01-27T13:15:00+01:00', date=None, time_zone='Europe/Amsterdam'), status='confirmed', html_link='https://www.google.com/calendar/event?eid=MzAyODdiOGMzMzNiNDRjMThiM2JmYmQ1MmYzNTdkNGYgaHVnby5ldmVyc0Bt', created='2026-01-26T21:07:30.000Z', updated='2026-01-27T10:54:23.636Z', creator=GCalPerson(email='hugo.evers@gmail.com', self_=True), organizer=GCalPerson(email='hugo.evers@gmail.com', self_=True), ical_uid='30287b8c333b44c18b3bfbd52f357d4f@google.com', sequence=1, reminders=GCalReminders(use_default=True, overrides=None), event_type='default', guests_can_modify=True, calendar_id='primary', account_id='normal', colorId='10')], total_count=1)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gcal_events"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a125f8f",
      "metadata": {},
      "source": [
        "what is the goal here?\n",
        "we want to give the agent a tool so it can pull the timebox for a given day.\n",
        "\n",
        "we want to take that json object and turn it into a pydantic object.\n",
        "\n",
        "# TODO: link to code\n",
        "\n",
        "now we want to have a model that we use for timeboxing, so we convert it into a timebox object, l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "288cf421",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import from src/fateforger/adapters/calendar/models.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "080e206e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from fateforger.agents.schedular.models.calendar import CalendarEvent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dc22bcca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# now let the agent do it\n",
        "# agent needs to know which day to fetch and the timezone, it can default to users.info for the timezone.\n",
        "# and assume the user wants to plan for the next work day if before work start hour, unless the user specifies otherwise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abd91a65",
      "metadata": {},
      "source": [
        "# Inspecting the timebox object\n",
        "\n",
        "does it have all the properties/aliases to match the calendar event objects so we can mix and match directly?\n",
        "Does the timebox object have the serialisation methods to inject it into the agents' context?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e15ed6e",
      "metadata": {},
      "source": [
        "# now apply json patches\n",
        "\n",
        "for this part we must determine what to prompt the model, so its going to generate json patches, but in which model? it needs to use the minimized schema, it will need to know about the current timebox object, it needs instructions, the inputs.\n",
        "\n",
        "initially we dont want it to use issue json patches to create a timebox, instead it should print in markdown a rough draft of the timebox, which we can then convert to json patches to create the timebox object.\n",
        "the question is if we assume the user agreees with the rought draft whether we can create the first real timebox."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "81a8dfe4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# the timeboxing agent should have as it memory the timebox object, the inputs, and the last user message"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "587ce490",
      "metadata": {},
      "source": [
        "# stage 3: rough draft of timebox\n",
        "\n",
        "## TODO: \n",
        "* make sure the constraints and inputs are passed correctly to the rough draft agent, this means also injecting the current timebox events as fixed events.\n",
        "* parametrize the planning rules and draft algorithm\n",
        "* validate the markdown output and the planning trace output\n",
        "* make sure we can insert this is toon input into the stage 4 timebox json patching agent\n",
        "\n",
        "```xml\n",
        "<SystemPrompt>\n",
        "  <Role>Rough-Draft Day Planner Agent</Role>\n",
        "\n",
        "  <Objective>\n",
        "    Generate a bird’s-eye, glanceable rough draft of a day plan from user constraints and inputs.\n",
        "    The output is meant to be refined in later stages; prioritize clarity, order, and approximate durations.\n",
        "  </Objective>\n",
        "\n",
        "  <Inputs>\n",
        "    <Constraints>\n",
        "      Fixed events with exact start/end (sleep, meetings, travel).\n",
        "      Day start time (e.g., work starts 08:00).\n",
        "      Preferred block sizes (e.g., DW=2h, half-DW=1h, quarter-DW=30m).\n",
        "      Preferences (e.g., gym early, stimulant window ~4h).\n",
        "    </Constraints>\n",
        "    <Tasks>\n",
        "      DailyOneThing (single most important outcome).\n",
        "      Supporting tasks (meal prep, chores, fun/creative time).\n",
        "      Optional constraints about stimulant timing, energy, or sequencing.\n",
        "    </Tasks>\n",
        "  </Inputs>\n",
        "\n",
        "  <PlanningRules>\n",
        "    <Rule id=\"R1\">Honor all fixed-time constraints exactly; do not overlap events.</Rule>\n",
        "    <Rule id=\"R2\">Place DailyOneThing into 2–3 Deep Work blocks early-to-midday unless constraints prevent it.</Rule>\n",
        "    <Rule id=\"R3\">Default DW blocks to the user’s standard duration; allow 1h or 30m “partial DW” if specified.</Rule>\n",
        "    <Rule id=\"R4\">Insert buffers where risk is high: after DW (10–15m), after gym (30–45m reset), after meals (10–20m).</Rule>\n",
        "    <Rule id=\"R5\">Keep Shallow Work ≤30% of waking hours; cluster it later in the day when possible.</Rule>\n",
        "    <Rule id=\"R6\">Protect recovery and fun/creative blocks as first-class events; do not label them “optional” unless user did.</Rule>\n",
        "    <Rule id=\"R7\">If stimulants are mentioned: align demanding DW within the effective window; avoid back-to-back dosing unless user insists.</Rule>\n",
        "    <Rule id=\"R8\">Prefer simple sequencing over precision. This is a rough draft for later refinement.</Rule>\n",
        "  </PlanningRules>\n",
        "\n",
        "  <DraftAlgorithm>\n",
        "    <Step>Lock fixed anchors (sleep, immovable meetings, hard start time).</Step>\n",
        "    <Step>Place Morning Routine immediately after sleep end (15–45m, per user preference).</Step>\n",
        "    <Step>Schedule DW blocks for DailyOneThing: hardest block first, then execution/polish blocks.</Step>\n",
        "    <Step>Place gym in the user’s preferred slot (e.g., early) and add a reset buffer after.</Step>\n",
        "    <Step>Place a fun/unstructured block (1–2h) if requested, ideally between stimulant windows or after a major block.</Step>\n",
        "    <Step>Place shallow work (chores/admin) later; keep it bounded.</Step>\n",
        "    <Step>Place meal prep + dinner in the evening; then creative time if requested.</Step>\n",
        "    <Step>End with shutdown ritual + reading in bed + sleep anchor.</Step>\n",
        "  </DraftAlgorithm>\n",
        "\n",
        "  <OutputSpec>\n",
        "    <PrimaryOutput format=\"markdown\">\n",
        "      <![CDATA[\n",
        "      Produce a short, glanceable summary with:\n",
        "      - A few headings (Night/Morning/Midday/Afternoon/Evening) OR emojis (optional).\n",
        "      - ONE line per major chunk (not per micro-event).\n",
        "      - Each line: **Label** — rough duration (e.g., \"Deep Work (primary) — 2h\").\n",
        "      - Do not include exact timestamps unless the user explicitly asked for times.\n",
        "      - Keep total output under ~12–15 lines.\n",
        "      ]]>\n",
        "    </PrimaryOutput>\n",
        "\n",
        "    <PlanningTrace format=\"xml\">\n",
        "      <TraceRules>\n",
        "        <Rule>Do NOT include chain-of-thought or detailed internal reasoning.</Rule>\n",
        "        <Rule>Include only: assumptions, placements, durations, and checks.</Rule>\n",
        "      </TraceRules>\n",
        "      <TraceTemplate>\n",
        "        <![CDATA[\n",
        "        <PlanTrace>\n",
        "          <Assumptions>\n",
        "            <Assumption id=\"A1\">...</Assumption>\n",
        "          </Assumptions>\n",
        "          <Placements>\n",
        "            <Placement type=\"DW\" label=\"DailyOneThing\" duration=\"PT2H\" rationale=\"hardest first\"/>\n",
        "            <Placement type=\"H\" label=\"Gym\" duration=\"PT1H30M\" rationale=\"early preference\"/>\n",
        "          </Placements>\n",
        "          <Checks>\n",
        "            <Check name=\"NoOverlaps\" status=\"pass\"/>\n",
        "            <Check name=\"ShallowWorkRatio\" status=\"pass|warn\" value=\"...\"/>\n",
        "            <Check name=\"DWCount\" status=\"pass|warn\" value=\"...\"/>\n",
        "          </Checks>\n",
        "        </PlanTrace>\n",
        "        ]]>\n",
        "      </TraceTemplate>\n",
        "    </PlanningTrace>\n",
        "\n",
        "    <Tone>\n",
        "      Crisp, minimal, readable at a glance. No motivational speeches.\n",
        "    </Tone>\n",
        "  </OutputSpec>\n",
        "\n",
        "  <FailureModes>\n",
        "    <Mode id=\"F1\">Missing fixed anchors: infer a reasonable sleep block only if user provided sleep duration + bedtime; otherwise ask one question.</Mode>\n",
        "    <Mode id=\"F2\">Too many tasks: prioritize DailyOneThing and cap DW at 3 blocks; push the rest to shallow work or mark as overflow.</Mode>\n",
        "    <Mode id=\"F3\">Timing conflict: preserve fixed events, then reflow flexible blocks; keep buffers if possible.</Mode>\n",
        "  </FailureModes>\n",
        "</SystemPrompt>\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07c15678",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c5f7e2a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.tools.artifact_editor import (\n",
        "    ArtifactEditorToolSpec,\n",
        "    ArtifactMemoryBlock,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "93e9551e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "try:\n",
        "    load_dotenv()\n",
        "except AssertionError:\n",
        "    load_dotenv(dotenv_path=\".env\")\n",
        "\n",
        "\n",
        "token = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "open_router_base_url = os.getenv(\"OPENROUTER_BASE_URL\")\n",
        "client = OpenAI(api_key=token, base_url=open_router_base_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "17115fc2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PizzaOrder(size='large', toppings=['pepperoni', 'mushrooms'], address='123 Main St.')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import Literal, Optional\n",
        "\n",
        "class PizzaOrder(BaseModel):\n",
        "    size: Literal[\"small\", \"medium\", \"large\", \"extra-large\"]\n",
        "    toppings: list[str]\n",
        "    address: str\n",
        "\n",
        "\n",
        "schema = PizzaOrder.model_json_schema()\n",
        "\n",
        "prompt = lambda order: f\"\"\"\n",
        "You are an expert pizza ordering agent. You need to order a pizza for the user based on their preferences.\n",
        "you respond with json and list the size, toppings and address to deliver to.\n",
        "Here is the order:\n",
        "{order}\n",
        "\"\"\"\n",
        "\n",
        "order = \"I want a large pizza with pepperoni and mushrooms, deliver to 123 Main St.\"\n",
        "model=\"google/gemini-3-flash-preview\"\n",
        "response = client.responses.create(\n",
        "  model=model,\n",
        "  input=[{\"role\": \"user\", \"content\": prompt(order)}],\n",
        "  text={\n",
        "    \"format\": {\n",
        "      \"type\": \"json_schema\",\n",
        "      \"name\": \"shopping_list\",\n",
        "      \"strict\": True,\n",
        "      \"schema\": schema\n",
        "    }\n",
        "  }\n",
        ")\n",
        "pizza_order = PizzaOrder.model_validate_json(response.output_text)\n",
        "pizza_order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f8aa952e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Annotated, Generic, Literal, Optional, Type, TypeVar, Union, get_args, get_origin\n",
        "\n",
        "from pydantic import BaseModel, Field, create_model, model_validator\n",
        "from llama_index.tools.artifact_editor import ArtifactEditorToolSpec\n",
        "from llama_index.tools.artifact_editor.base import JsonPatch\n",
        "from jinja2 import Template\n",
        "\n",
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.messages import TextMessage\n",
        "from autogen_core import CancellationToken\n",
        "from autogen_core.tools import FunctionTool\n",
        "\n",
        "from fateforger.llm import build_autogen_chat_client\n",
        "\n",
        "\n",
        "Style = Literal[\"napoletana\", \"new-york\", \"sicilian\", \"detroit\", \"roman\"]\n",
        "Size = Literal[\"s\", \"m\", \"l\", \"xl\"]\n",
        "\n",
        "\n",
        "class Pizza(BaseModel):\n",
        "    style: Style\n",
        "    toppings: str\n",
        "    size: Size\n",
        "    quantity: int = Field(ge=1)\n",
        "\n",
        "\n",
        "class PizzaOrder(BaseModel):\n",
        "    pizzas: list[Pizza] = Field(default_factory=list)\n",
        "\n",
        "\n",
        "T = TypeVar(\"T\", bound=BaseModel)\n",
        "\n",
        "\n",
        "ErrorCategory = Literal[\n",
        "    \"invalid_path\",\n",
        "    \"invalid_index\",\n",
        "    \"invalid_enum\",\n",
        "    \"missing_field\",\n",
        "    \"schema_validation\",\n",
        "    \"tool_call_failure\",\n",
        "    \"patch_of_patch_missing\",\n",
        "    \"unknown\",\n",
        "]\n",
        "\n",
        "\n",
        "class ErrorInfo(BaseModel):\n",
        "    category: ErrorCategory\n",
        "    message: str\n",
        "    op: dict | None = None\n",
        "    op_index: int | None = None\n",
        "\n",
        "\n",
        "class PatchResult(BaseModel, Generic[T]):\n",
        "    ok: bool\n",
        "    result: T\n",
        "    current_artifact: T\n",
        "    applied: list[dict] = Field(default_factory=list)\n",
        "    error: str | None = None\n",
        "    summary: str | None = None\n",
        "    error_info: ErrorInfo | None = None\n",
        "\n",
        "\n",
        "def _unwrap_optional(annotation: Type) -> Type:\n",
        "    origin = get_origin(annotation)\n",
        "    if origin is Union:\n",
        "        args = [arg for arg in get_args(annotation) if arg is not type(None)]\n",
        "        if len(args) == 1:\n",
        "            return args[0]\n",
        "    return annotation\n",
        "\n",
        "\n",
        "def _infer_list_field(model_cls: Type[BaseModel]) -> str:\n",
        "    # General-purpose: expect exactly one list field unless overridden.\n",
        "    fields = getattr(model_cls, \"model_fields\", None) or getattr(model_cls, \"__fields__\", {})\n",
        "    list_fields = []\n",
        "    for name, field in fields.items():\n",
        "        annotation = getattr(field, \"annotation\", None) or getattr(field, \"outer_type_\", None)\n",
        "        annotation = _unwrap_optional(annotation)\n",
        "        if get_origin(annotation) is list:\n",
        "            list_fields.append(name)\n",
        "    if len(list_fields) != 1:\n",
        "        raise ValueError(f\"Expected exactly one list field, found: {list_fields}\")\n",
        "    return list_fields[0]\n",
        "\n",
        "\n",
        "def _infer_item_model(model_cls: Type[T], list_field: str) -> Type:\n",
        "    field = (getattr(model_cls, \"model_fields\", None) or getattr(model_cls, \"__fields__\", {}))[list_field]\n",
        "    annotation = getattr(field, \"annotation\", None) or getattr(field, \"outer_type_\", None)\n",
        "    annotation = _unwrap_optional(annotation)\n",
        "    args = get_args(annotation)\n",
        "    if not args:\n",
        "        raise ValueError(f\"List field {list_field} is missing item type\")\n",
        "    return args[0]\n",
        "\n",
        "\n",
        "def make_patch_schema(item_model: Type) -> Type[BaseModel]:\n",
        "    # Typed patch schema: add/replace values MUST be valid item objects.\n",
        "    add_op = create_model(\n",
        "        \"AddOp\",\n",
        "        op=(Literal[\"add\"], \"add\"),\n",
        "        path=(str, Field(..., description=\"JSON pointer path\")),\n",
        "        value=(item_model, Field(..., description=\"Item to add\")),\n",
        "    )\n",
        "    replace_op = create_model(\n",
        "        \"ReplaceOp\",\n",
        "        op=(Literal[\"replace\"], \"replace\"),\n",
        "        path=(str, Field(..., description=\"JSON pointer path\")),\n",
        "        value=(item_model, Field(..., description=\"Full item replacement\")),\n",
        "    )\n",
        "    remove_op = create_model(\n",
        "        \"RemoveOp\",\n",
        "        op=(Literal[\"remove\"], \"remove\"),\n",
        "        path=(str, Field(..., description=\"JSON pointer path\")),\n",
        "    )\n",
        "    move_op = create_model(\n",
        "        \"MoveOp\",\n",
        "        op=(Literal[\"move\"], \"move\"),\n",
        "        from_path=(str, Field(..., description=\"Source path (use from_path)\")),\n",
        "        path=(str, Field(..., description=\"Target path\")),\n",
        "    )\n",
        "    copy_op = create_model(\n",
        "        \"CopyOp\",\n",
        "        op=(Literal[\"copy\"], \"copy\"),\n",
        "        from_path=(str, Field(..., description=\"Source path (use from_path)\")),\n",
        "        path=(str, Field(..., description=\"Target path\")),\n",
        "    )\n",
        "    patch_op = Annotated[\n",
        "        Union[add_op, replace_op, remove_op, move_op, copy_op],\n",
        "        Field(discriminator=\"op\"),\n",
        "    ]\n",
        "    patch_plan = create_model(\n",
        "        \"PatchPlan\",\n",
        "        operations=(list[patch_op], Field(..., description=\"RFC6902 ops\")),\n",
        "    )\n",
        "    return patch_plan\n",
        "\n",
        "\n",
        "def make_request_model(patch_plan: Type[BaseModel]) -> Type[BaseModel]:\n",
        "    class PatchRequest(BaseModel):\n",
        "        mode: Literal[\"new\", \"patch_of_patch\"]\n",
        "        patch: patch_plan | JsonPatch\n",
        "\n",
        "        @model_validator(mode=\"after\")\n",
        "        def _validate_mode(self):\n",
        "            if self.mode == \"new\" and not isinstance(self.patch, patch_plan):\n",
        "                raise ValueError(\"mode=new requires a full patch plan\")\n",
        "            if self.mode == \"patch_of_patch\" and not isinstance(self.patch, JsonPatch):\n",
        "                raise ValueError(\"mode=patch_of_patch requires a JsonPatch\")\n",
        "            return self\n",
        "\n",
        "    return PatchRequest\n",
        "\n",
        "\n",
        "def _classify_error(exc: Exception, *, op: dict | None = None, op_index: int | None = None) -> ErrorInfo:\n",
        "    message = str(exc)\n",
        "    lower = message.lower()\n",
        "\n",
        "    if \"no previous patch\" in lower:\n",
        "        category = \"patch_of_patch_missing\"\n",
        "    elif isinstance(exc, IndexError) or \"out of range\" in lower:\n",
        "        category = \"invalid_index\"\n",
        "    elif isinstance(exc, KeyError) or \"invalid field\" in lower or \"cannot access nested field\" in lower or \"path\" in lower:\n",
        "        category = \"invalid_path\"\n",
        "    elif \"field required\" in lower:\n",
        "        category = \"missing_field\"\n",
        "    elif \"input should be\" in lower or \"literal\" in lower or \"enum\" in lower:\n",
        "        category = \"invalid_enum\"\n",
        "    elif \"patch resulted in invalid\" in lower or \"validation\" in lower:\n",
        "        category = \"schema_validation\"\n",
        "    else:\n",
        "        category = \"unknown\"\n",
        "\n",
        "    return ErrorInfo(category=category, message=message, op=op, op_index=op_index)\n",
        "\n",
        "\n",
        "class ObjectPatcher(Generic[T]):\n",
        "    # General-purpose patcher for \"model with one list field\" using AutoGen tool calling.\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_cls: Type[T],\n",
        "        *,\n",
        "        model_client,\n",
        "        initial_state: BaseModel | dict | None = None,\n",
        "        list_field: str | None = None,\n",
        "    ) -> None:\n",
        "        self.model_cls = model_cls\n",
        "        self.list_field = list_field or _infer_list_field(model_cls)\n",
        "        self.item_model = _infer_item_model(model_cls, self.list_field)\n",
        "        self.patch_plan = make_patch_schema(self.item_model)\n",
        "        self.PatchRequest = make_request_model(self.patch_plan)\n",
        "        self.patch_request_schema = self.PatchRequest.model_json_schema()\n",
        "        self.ResultModel = PatchResult[model_cls]\n",
        "        self.spec = ArtifactEditorToolSpec(model_cls)\n",
        "        self._set_initial_state(initial_state)\n",
        "        self._initial_snapshot = self._artifact()\n",
        "        self._last_patch: BaseModel | None = None\n",
        "        self._last_success: BaseModel | None = None\n",
        "\n",
        "        self._agent = AssistantAgent(\n",
        "            name=\"PatchAgent\",\n",
        "            model_client=model_client,\n",
        "            tools=[self._build_tool()],\n",
        "            max_tool_iterations=1,\n",
        "            tool_call_summary_format=\"{result}\",\n",
        "            system_message=PATCH_SYSTEM_MESSAGE,\n",
        "        )\n",
        "        self._summarizer = AssistantAgent(\n",
        "            name=\"PatchSummarizer\",\n",
        "            model_client=model_client,\n",
        "            system_message=SUMMARY_SYSTEM_MESSAGE,\n",
        "        )\n",
        "\n",
        "    def _build_tool(self) -> FunctionTool:\n",
        "        async def apply_patch(request: self.PatchRequest) -> PatchResult[T]:  # type: ignore[name-defined]\n",
        "            return self._handle_request(request)\n",
        "\n",
        "        return FunctionTool(\n",
        "            apply_patch,\n",
        "            description=\"Apply a patch request to the current artifact.\",\n",
        "            strict=True,\n",
        "        )\n",
        "\n",
        "    def _set_initial_state(self, initial_state: BaseModel | dict | None) -> None:\n",
        "        if initial_state is None:\n",
        "            data = {self.list_field: []}\n",
        "        elif isinstance(initial_state, BaseModel):\n",
        "            data = initial_state.model_dump()\n",
        "        else:\n",
        "            data = dict(initial_state)\n",
        "        if self.list_field not in data:\n",
        "            data[self.list_field] = []\n",
        "\n",
        "        # Allow invalid inputs by constructing items without validation; patcher fixes them.\n",
        "        if isinstance(self.item_model, type) and issubclass(self.item_model, BaseModel):\n",
        "            items = []\n",
        "            for item in data[self.list_field]:\n",
        "                if isinstance(item, BaseModel):\n",
        "                    items.append(item)\n",
        "                else:\n",
        "                    items.append(self.item_model.model_construct(**dict(item)))\n",
        "            data[self.list_field] = items\n",
        "\n",
        "        try:\n",
        "            self.spec.current_artifact = self.model_cls.model_validate(data)\n",
        "        except Exception:\n",
        "            self.spec.current_artifact = self.model_cls.model_construct(**data)\n",
        "\n",
        "    def _artifact(self) -> dict:\n",
        "        return self.spec.get_current_artifact() or {self.list_field: []}\n",
        "\n",
        "    def _handle_request(self, request: BaseModel) -> BaseModel:\n",
        "        patch = request.patch\n",
        "        if request.mode == \"patch_of_patch\":\n",
        "            try:\n",
        "                patch = self._apply_patch_to_patch(request.patch)\n",
        "            except Exception as exc:\n",
        "                error_info = _classify_error(exc)\n",
        "                return self.ResultModel.model_validate(\n",
        "                    {\n",
        "                        \"ok\": False,\n",
        "                        \"result\": self.model_cls.model_construct(**self._artifact()),\n",
        "                        \"current_artifact\": self.model_cls.model_construct(**self._artifact()),\n",
        "                        \"applied\": [],\n",
        "                        \"error\": str(exc),\n",
        "                        \"summary\": None,\n",
        "                        \"error_info\": error_info,\n",
        "                    }\n",
        "                )\n",
        "        self._last_patch = patch\n",
        "        return self._apply_patch_sequential(patch)\n",
        "\n",
        "    def _apply_patch_to_patch(self, patch_delta: JsonPatch) -> BaseModel:\n",
        "        if self._last_patch is None:\n",
        "            raise ValueError(\"No previous patch to repair.\")\n",
        "        editor = ArtifactEditorToolSpec(self.patch_plan)\n",
        "        editor.current_artifact = self._last_patch\n",
        "        updated = editor.apply_patch(patch_delta)\n",
        "        return self.patch_plan.model_validate(updated)\n",
        "\n",
        "    def _apply_patch_sequential(self, patch: BaseModel) -> PatchResult[T]:\n",
        "        # Apply op-by-op so we can recover at the last successful patch.\n",
        "        applied: list[dict] = []\n",
        "        for op_index, op in enumerate(patch.operations):\n",
        "            op_dict = op.model_dump(exclude_none=True)\n",
        "            try:\n",
        "                self.spec.apply_patch(JsonPatch.model_validate({\"operations\": [op_dict]}))\n",
        "                applied.append(op_dict)\n",
        "            except Exception as exc:\n",
        "                error_info = _classify_error(exc, op=op_dict, op_index=op_index)\n",
        "                return self.ResultModel.model_validate(\n",
        "                    {\n",
        "                        \"ok\": False,\n",
        "                        \"result\": self.model_cls.model_construct(**self._artifact()),\n",
        "                        \"current_artifact\": self.model_cls.model_construct(**self._artifact()),\n",
        "                        \"applied\": applied,\n",
        "                        \"error\": str(exc),\n",
        "                        \"summary\": None,\n",
        "                        \"error_info\": error_info,\n",
        "                    }\n",
        "                )\n",
        "        result_model = self.model_cls.model_validate(self._artifact())\n",
        "        self._last_success = result_model\n",
        "        return self.ResultModel.model_validate(\n",
        "            {\n",
        "                \"ok\": True,\n",
        "                \"result\": result_model,\n",
        "                \"current_artifact\": result_model,\n",
        "                \"applied\": applied,\n",
        "                \"error\": None,\n",
        "                \"summary\": None,\n",
        "                \"error_info\": None,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    def _render_prompt(self, instruction: str, error: str | None, error_info: ErrorInfo | None) -> str:\n",
        "        template = Template(PATCH_TEMPLATE)\n",
        "        return template.render(\n",
        "            list_field=self.list_field,\n",
        "            artifact=json.dumps(self._artifact(), indent=2),\n",
        "            instruction=instruction,\n",
        "            item_schema=json.dumps(self.item_model.model_json_schema(), indent=2)\n",
        "            if hasattr(self.item_model, \"model_json_schema\")\n",
        "            else json.dumps({}, indent=2),\n",
        "            patch_schema=json.dumps(self.patch_plan.model_json_schema(), indent=2),\n",
        "            request_schema=json.dumps(self.patch_request_schema, indent=2),\n",
        "            last_patch=json.dumps(self._last_patch.model_dump(), indent=2) if self._last_patch else \"null\",\n",
        "            error_block=(f\"Previous error: {error}\" if error else \"\"),\n",
        "            error_info=json.dumps(error_info.model_dump(), indent=2) if error_info else \"null\",\n",
        "        )\n",
        "\n",
        "    async def run(self, instruction: str, max_attempts: int = 3) -> PatchResult[T]:\n",
        "        last_error: str | None = None\n",
        "        last_error_info: ErrorInfo | None = None\n",
        "        for _ in range(max_attempts):\n",
        "            prompt = self._render_prompt(instruction, last_error, last_error_info)\n",
        "            response = await self._agent.on_messages([TextMessage(content=prompt, source=\"user\")], CancellationToken())\n",
        "            try:\n",
        "                outcome = self.ResultModel.model_validate_json(response.chat_message.content)\n",
        "            except Exception as exc:\n",
        "                last_error = f\"Invalid tool result: {exc}\"\n",
        "                continue\n",
        "            if outcome.ok:\n",
        "                return outcome\n",
        "            last_error = outcome.error\n",
        "            last_error_info = outcome.error_info\n",
        "\n",
        "        summary = await self._summarize_failure(last_error or \"unknown\", last_error_info)\n",
        "        return self.ResultModel.model_validate(\n",
        "            {\n",
        "                \"ok\": False,\n",
        "                \"result\": self.model_cls.model_construct(**self._artifact()),\n",
        "                \"current_artifact\": self.model_cls.model_construct(**self._artifact()),\n",
        "                \"applied\": [],\n",
        "                \"error\": last_error,\n",
        "                \"summary\": summary,\n",
        "                \"error_info\": last_error_info,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    async def _summarize_failure(self, error: str, error_info: ErrorInfo | None) -> str:\n",
        "        summary_prompt = Template(SUMMARY_TEMPLATE).render(\n",
        "            error=error,\n",
        "            error_info=json.dumps(error_info.model_dump(), indent=2) if error_info else \"null\",\n",
        "            artifact=json.dumps(self._artifact(), indent=2),\n",
        "            last_patch=json.dumps(self._last_patch.model_dump(), indent=2) if self._last_patch else \"null\",\n",
        "        )\n",
        "        response = await self._summarizer.on_messages([TextMessage(content=summary_prompt, source=\"user\")], CancellationToken())\n",
        "        return response.chat_message.content.strip()\n",
        "\n",
        "    def restart_from(self, state: Literal[\"initial\", \"last_success\"]) -> None:\n",
        "        if state == \"last_success\" and self._last_success is not None:\n",
        "            self._set_initial_state(self._last_success)\n",
        "        else:\n",
        "            self._set_initial_state(self._initial_snapshot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "03c20a91",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = globals().get(\"model\") or \"google/gemini-3-flash-preview\"\n",
        "\n",
        "PATCH_SYSTEM_MESSAGE = \"\"\"\n",
        "You are a patching agent. Your job is to call the apply_patch tool with a PatchRequest.\n",
        "Do not answer with prose. Always call the tool.\n",
        "\"\"\".strip()\n",
        "\n",
        "PATCH_TEMPLATE = \"\"\"\n",
        "You are editing a list in a JSON artifact.\n",
        "Goal: make the list match the user's instruction.\n",
        "\n",
        "Rules:\n",
        "- Use ONLY the apply_patch tool.\n",
        "- Choose mode = \"new\" for a fresh patch plan.\n",
        "- Choose mode = \"patch_of_patch\" to repair the last patch plan.\n",
        "- Operations are applied sequentially; indices refer to the current state.\n",
        "- For add/replace, value MUST be a full item matching the item schema.\n",
        "- Allowed ops: add, replace, remove, move, copy.\n",
        "- Use from_path (not from) for move/copy.\n",
        "- Prefer small, minimal patches.\n",
        "- Replace whole list items (use path like /{{list_field}}/0), not subfields.\n",
        "\n",
        "List field: /{{list_field}}\n",
        "\n",
        "Current artifact:\n",
        "{{artifact}}\n",
        "\n",
        "User instruction:\n",
        "{{instruction}}\n",
        "\n",
        "Item schema:\n",
        "{{item_schema}}\n",
        "\n",
        "Patch schema:\n",
        "{{patch_schema}}\n",
        "\n",
        "PatchRequest schema:\n",
        "{{request_schema}}\n",
        "\n",
        "Last patch (for patch_of_patch mode):\n",
        "{{last_patch}}\n",
        "\n",
        "Error info (structured):\n",
        "{{error_info}}\n",
        "\n",
        "{{error_block}}\n",
        "\"\"\".strip()\n",
        "\n",
        "SUMMARY_SYSTEM_MESSAGE = \"\"\"\n",
        "You are a concise failure summarizer. Respond with 2-3 bullets.\n",
        "\"\"\".strip()\n",
        "\n",
        "SUMMARY_TEMPLATE = \"\"\"\n",
        "Summarize the patch failure in 2-3 bullets and suggest next steps.\n",
        "\n",
        "Error: {{error}}\n",
        "Error info: {{error_info}}\n",
        "Current artifact: {{artifact}}\n",
        "Last patch: {{last_patch}}\n",
        "\"\"\".strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99c31a4a",
      "metadata": {},
      "source": [
        "# Patch walkthrough (AutoGen + ArtifactEditor)\n",
        "\n",
        "**Purpose:** Patch an *incorrect* list-based object into the desired state using **AutoGen tool calling** + **typed JSON Patch**.\n",
        "\n",
        "## Steps (mapped to code)\n",
        "1. **Infer list + item types**: `_infer_list_field` + `_infer_item_model` find the list field and its item type.  \n",
        "2. **Typed patch schema**: `make_patch_schema(item_model)` forces `add/replace.value` to be valid items.  \n",
        "3. **PatchRequest schema**: `make_request_schema` lets the agent choose **new** patch or **patch_of_patch**.  \n",
        "4. **Tool call**: `ObjectPatcher._build_tool` exposes `apply_patch(request)` as an AutoGen tool (strict schema).  \n",
        "5. **Sequential apply**: `_apply_patch_sequential` applies op-by-op for recoverability.  \n",
        "6. **Repair loop**: `run` retries; on failure, summarize and allow restart options.\n",
        "\n",
        "## Trade-offs\n",
        "- **Pros:** schema enforcement *before* patching, AutoGen tool loop, recoverable failures.\n",
        "- **Cons:** assumes one list field per model; sequential patching is slower but safer for index shifts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c17202",
      "metadata": {},
      "source": [
        "# Mermaid diagrams\n",
        "\n",
        "```mermaid\n",
        "flowchart TD\n",
        "  A[User instruction] --> B[ObjectPatcher.run]\n",
        "  B --> C[_render_prompt]\n",
        "  C --> D[AutoGen AssistantAgent]\n",
        "  D --> E[apply_patch tool]\n",
        "  E --> F[ArtifactEditorToolSpec.apply_patch]\n",
        "  F --> G[Updated artifact]\n",
        "```\n",
        "\n",
        "```mermaid\n",
        "sequenceDiagram\n",
        "  participant U as User\n",
        "  participant P as ObjectPatcher\n",
        "  participant A as AutoGen Agent\n",
        "  participant T as apply_patch tool\n",
        "  participant E as ArtifactEditor\n",
        "\n",
        "  U->>P: instruction + initial_state\n",
        "  P->>A: prompt (artifact + schemas)\n",
        "  A->>T: PatchRequest(mode=new|patch_of_patch)\n",
        "  T->>E: apply patch ops sequentially\n",
        "  E-->>T: updated artifact or error\n",
        "  T-->>A: PatchOutcome (JSON)\n",
        "  A-->>P: tool summary (JSON)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50548c39",
      "metadata": {},
      "source": [
        "# TODOs\n",
        "- [ ] Allow models with multiple list fields (explicit list_field required).\n",
        "- [ ] Add a small \"patch preview\" mode (no apply, just diff).\n",
        "- [ ] Expand repair prompts with structured error categories.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c7751c17",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PatchResult[PizzaOrder](ok=True, result=PizzaOrder(pizzas=[Pizza(style='napoletana', toppings='pepperoni and mushrooms', size='l', quantity=2), Pizza(style='sicilian', toppings='olives', size='s', quantity=1)]), current_artifact=PizzaOrder(pizzas=[Pizza(style='napoletana', toppings='pepperoni and mushrooms', size='l', quantity=2), Pizza(style='sicilian', toppings='olives', size='s', quantity=1)]), applied=[{'op': 'replace', 'path': '/pizzas/0', 'value': {'style': 'napoletana', 'toppings': 'pepperoni and mushrooms', 'size': 'l', 'quantity': 2}}, {'op': 'add', 'path': '/pizzas/1', 'value': {'style': 'sicilian', 'toppings': 'olives', 'size': 's', 'quantity': 1}}], error=None, summary=None, error_info=None)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wrong_pizza_order = {\n",
        "    \"pizzas\": [\n",
        "        {\"style\": \"napolitaon\", \"toppings\": \"ananas\", \"size\": \"m\", \"quantity\": 1}\n",
        "    ]\n",
        "}\n",
        "\n",
        "model_client = build_autogen_chat_client(\"patch_agent\", model=model)\n",
        "patcher = ObjectPatcher(PizzaOrder, model_client=model_client, initial_state=wrong_pizza_order)\n",
        "\n",
        "instruction = (\n",
        "    \"Make it a napoletana, size l, toppings pepperoni and mushrooms, quantity 2. \"\n",
        "    \"Add a second pizza: sicilian, size s, toppings olives, quantity 1.\"\n",
        ")\n",
        "\n",
        "result = await patcher.run(instruction, max_attempts=3)\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ac9c500c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PatchResult[PizzaOrder](ok=True, result=PizzaOrder(pizzas=[Pizza(style='napoletana', toppings='pepperoni and mushrooms', size='l', quantity=2), Pizza(style='sicilian', toppings='olives', size='s', quantity=1)]), current_artifact=PizzaOrder(pizzas=[Pizza(style='napoletana', toppings='pepperoni and mushrooms', size='l', quantity=2), Pizza(style='sicilian', toppings='olives', size='s', quantity=1)]), applied=[{'op': 'replace', 'path': '/pizzas/0', 'value': {'style': 'napoletana', 'toppings': 'pepperoni and mushrooms', 'size': 'l', 'quantity': 2}}, {'op': 'add', 'path': '/pizzas/1', 'value': {'style': 'sicilian', 'toppings': 'olives', 'size': 's', 'quantity': 1}}], error=None, summary=None, error_info=None)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fateforger-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
