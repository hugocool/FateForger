{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1f821b",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "to fetch the events from the calendar and edit them as a timebox given prompt and then write them back.\n",
    "\n",
    "That way we can give this as a tool to the schedular agent as well, so it can change a single event, but also reschedule the day as a whole if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff203a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2026, 2, 4)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "work_start_hour = 8 # TODO: move to settings\n",
    "is_before_work_start = datetime.now().time() < datetime.now().replace(hour=work_start_hour, minute=0, second=0, microsecond=0).time()\n",
    "# is_before_work_start = True\n",
    "today = datetime.now().date()\n",
    "day_to_plan = today if is_before_work_start else today + timedelta(days=1)\n",
    "day_to_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76f68d",
   "metadata": {},
   "source": [
    "# now pull events from calendar for that date as a timebox object\n",
    "\n",
    "```mermaid\n",
    "\n",
    "flowchart TB\n",
    "  node_1(\"CalendarEvent\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bc3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime, date as date_type, time as time_type, timedelta, timezone\n",
    "from typing import Any, Iterable\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "from dateutil import parser as date_parser\n",
    "\n",
    "from fateforger.agents.schedular.models.calendar import CalendarEvent, EventType\n",
    "from fateforger.agents.timeboxing.timebox import Timebox\n",
    "\n",
    "\n",
    "from autogen_ext.tools.mcp import McpWorkbench, StreamableHttpServerParams\n",
    "\n",
    "from fateforger.core.config import settings\n",
    "\n",
    "\n",
    "# TODO: wrao this in a nice function\n",
    "\n",
    "def calendar_workbench() -> McpWorkbench:\n",
    "\n",
    "    return McpWorkbench(\n",
    "        StreamableHttpServerParams(url=settings.mcp_calendar_server_url, timeout=10.0)\n",
    "    )\n",
    "workbench = calendar_workbench()\n",
    "\n",
    "# query the workbench\n",
    "result = await workbench.call_tool(\n",
    "    \"list-events\", # TODO: what are all the args we can pass here?\n",
    "    arguments={\n",
    "        \"calendarId\": \"primary\",\n",
    "        \"timeMin\": \"2026-01-27T00:00:00Z\",\n",
    "        \"timeMax\": \"2026-01-28T00:00:00Z\",\n",
    "        \"singleEvents\": True,\n",
    "        \"orderBy\": \"startTime\",\n",
    "    },\n",
    ")\n",
    "\n",
    "raw_json_string = result.result[0].content\n",
    "\n",
    "# def get_timebox_for_day(day: date_type, timezone_str: str) -> Timebox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6295882f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"events\":[{\"id\":\"30287b8c333b44c18b3bfbd52f357d4f\",\"summary\":\"morning review\",\"start\":{\"dateTime\":\"2026-01-27T13:00:00+01:00\",\"timeZone\":\"Europe/Amsterdam\"},\"end\":{\"dateTime\":\"2026-01-27T13:15:00+01:00\",\"timeZone\":\"Europe/Amsterdam\"},\"status\":\"confirmed\",\"htmlLink\":\"https://www.google.com/calendar/event?eid=MzAyODdiOGMzMzNiNDRjMThiM2JmYmQ1MmYzNTdkNGYgaHVnby5ldmVyc0Bt\",\"created\":\"2026-01-26T21:07:30.000Z\",\"updated\":\"2026-01-27T10:54:23.636Z\",\"colorId\":\"10\",\"creator\":{\"email\":\"hugo.evers@gmail.com\",\"self\":true},\"organizer\":{\"email\":\"hugo.evers@gmail.com\",\"self\":true},\"iCalUID\":\"30287b8c333b44c18b3bfbd52f357d4f@google.com\",\"sequence\":1,\"reminders\":{\"useDefault\":true},\"eventType\":\"default\",\"guestsCanModify\":true,\"calendarId\":\"primary\",\"accountId\":\"normal\"}],\"totalCount\":1}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.result[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c7c2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fateforger.adapters.calendar.models import GCalEventsResponse\n",
    "\n",
    "gcal_events = GCalEventsResponse.model_validate_json(result.result[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dcc011d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCalEventsResponse(events=[GCalEvent(id='30287b8c333b44c18b3bfbd52f357d4f', summary='morning review', start=GCalEventDateTime(date_time='2026-01-27T13:00:00+01:00', date=None, time_zone='Europe/Amsterdam'), end=GCalEventDateTime(date_time='2026-01-27T13:15:00+01:00', date=None, time_zone='Europe/Amsterdam'), status='confirmed', html_link='https://www.google.com/calendar/event?eid=MzAyODdiOGMzMzNiNDRjMThiM2JmYmQ1MmYzNTdkNGYgaHVnby5ldmVyc0Bt', created='2026-01-26T21:07:30.000Z', updated='2026-01-27T10:54:23.636Z', creator=GCalPerson(email='hugo.evers@gmail.com', self_=True), organizer=GCalPerson(email='hugo.evers@gmail.com', self_=True), ical_uid='30287b8c333b44c18b3bfbd52f357d4f@google.com', sequence=1, reminders=GCalReminders(use_default=True, overrides=None), event_type='default', guests_can_modify=True, calendar_id='primary', account_id='normal', colorId='10')], total_count=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcal_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3dde7c",
   "metadata": {},
   "source": [
    "# convert that to Timebox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a125f8f",
   "metadata": {},
   "source": [
    "what is the goal here?\n",
    "we want to give the agent a tool so it can pull the timebox for a given day.\n",
    "\n",
    "we want to take that json object and turn it into a pydantic object.\n",
    "\n",
    "# TODO: link to code\n",
    "\n",
    "now we want to have a model that we use for timeboxing, so we convert it into a timebox object, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288cf421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from src/fateforger/adapters/calendar/models.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "080e206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fateforger.agents.schedular.models.calendar import CalendarEvent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc22bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let the agent do it\n",
    "# agent needs to know which day to fetch and the timezone, it can default to users.info for the timezone.\n",
    "# and assume the user wants to plan for the next work day if before work start hour, unless the user specifies otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd91a65",
   "metadata": {},
   "source": [
    "# Inspecting the timebox object\n",
    "\n",
    "does it have all the properties/aliases to match the calendar event objects so we can mix and match directly?\n",
    "Does the timebox object have the serialisation methods to inject it into the agents' context?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b60721",
   "metadata": {},
   "source": [
    "Proposal: Productionize ObjectPatcher and Replace Timeboxing Agent Patching\n",
    "1) Where the code should live (module ownership)\n",
    "Primary module:\n",
    "patcher.py\n",
    "Reason: this is timeboxing‑specific behavior (LLM patching of list‑based “event specs”), and keeps the scheduling domain clean.\n",
    "\n",
    "Supporting types (if needed):\n",
    "patching.py\n",
    "Reason: holds PatchResult, ErrorInfo, and shared schemas to avoid circular imports.\n",
    "\n",
    "Public entry point:\n",
    "__init__.py should export ObjectPatcher (or renamed TimeboxingPatcher) so other agents can import it.\n",
    "\n",
    "2) Replace/modify existing flow\n",
    "Current likely patching code:\n",
    "patching.py (open in tabs earlier).\n",
    "Plan: either replace with the new patcher or move it into patcher.py and keep old file as a thin wrapper (if any call sites rely on it).\n",
    "\n",
    "Replace where patching is invoked:\n",
    "Likely in:\n",
    "\n",
    "agent.py\n",
    "flow.py or flow_graph.py\n",
    "We will route the patching step to the new AutoGen tool‑calling patcher using build_autogen_chat_client.\n",
    "\n",
    "3) The patcher API in production\n",
    "Production class (renaming optional):\n",
    "ObjectPatcher[T] with:\n",
    "\n",
    "run(instruction: str, max_attempts: int) -> PatchResult[T]\n",
    "restart_from(\"initial\" | \"last_success\")\n",
    "PatchResult includes:\n",
    "ok: bool\n",
    "result: T (always present)\n",
    "current_artifact: T\n",
    "applied: list[dict]\n",
    "error: str | None\n",
    "summary: str | None\n",
    "error_info: ErrorInfo | None (category + message + failing op)\n",
    "This mirrors the notebook logic.\n",
    "\n",
    "4) AutoGen integration\n",
    "Use AssistantAgent + FunctionTool(strict=True) with tool schema derived from PatchRequest.\n",
    "Use build_autogen_chat_client(\"timeboxing_patcher\", model=<env override>).\n",
    "The tool returns a typed PatchResult (not raw dict).\n",
    "Agent will be used in the timeboxing stage, not as a separate long‑lived agent.\n",
    "5) Docs changes\n",
    "README updates\n",
    "\n",
    "README.md\n",
    "Add a Status section (Implemented/Documented/Tested/etc).\n",
    "Add “Patching” subsection describing tool‑calling patcher and error repair.\n",
    "Docs (MkDocs)\n",
    "\n",
    "Add page in docs/ (e.g., patching.md).\n",
    "Update mkdocs.yml nav to include it.\n",
    "AGENTS.md\n",
    "\n",
    "AGENTS.md\n",
    "Add note that patching uses AutoGen tool‑calling + strict schema; no deterministic NLU.\n",
    "Mention the new patcher module and its ownership boundary.\n",
    "6) Tests\n",
    "Add tests in tests/timeboxing/ (or nearest existing timeboxing tests):\n",
    "\n",
    "Success path: valid patch that adds/updates items.\n",
    "Failure path: invalid patch (bad index) → error_info.category == \"invalid_index\".\n",
    "Repair path: patch_of_patch when last patch exists.\n",
    "Missing last patch: patch_of_patch when no last patch → patch_of_patch_missing.\n",
    "These tests should not hit the live LLM; use a mocked AutoGen model client or a fake agent with deterministic tool calls.\n",
    "\n",
    "7) Migration plan\n",
    "Extract notebook code into patcher.py.\n",
    "Wire patcher into timeboxing flow (agent.py / flow.py).\n",
    "Update docs + AGENTS.\n",
    "Add tests + run targeted pytest subset.\n",
    "Questions I need answered before coding\n",
    "Exact replacement target: Which file/function is the patching stage today?\n",
    "Naming: keep ObjectPatcher, or rename to TimeboxingPatcher?\n",
    "What should be the model in production? (Probably your timeboxing event spec model).\n",
    "If this proposal is aligned, say “approved” and answer the three questions, and I’ll draft the formal ticket and start the implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15ed6e",
   "metadata": {},
   "source": [
    "# now apply json patches\n",
    "\n",
    "for this part we must determine what to prompt the model, so its going to generate json patches, but in which model? it needs to use the minimized schema, it will need to know about the current timebox object, it needs instructions, the inputs.\n",
    "\n",
    "initially we dont want it to use issue json patches to create a timebox, instead it should print in markdown a rough draft of the timebox, which we can then convert to json patches to create the timebox object.\n",
    "the question is if we assume the user agreees with the rought draft whether we can create the first real timebox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81a8dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the timeboxing agent should have as it memory the timebox object, the inputs, and the last user message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ce490",
   "metadata": {},
   "source": [
    "# stage 3: rough draft of timebox\n",
    "\n",
    "## TODO: \n",
    "* make sure the constraints and inputs are passed correctly to the rough draft agent, this means also injecting the current timebox events as fixed events.\n",
    "* parametrize the planning rules and draft algorithm\n",
    "* validate the markdown output and the planning trace output\n",
    "* make sure we can insert this is toon input into the stage 4 timebox json patching agent\n",
    "\n",
    "```xml\n",
    "<SystemPrompt>\n",
    "  <Role>Rough-Draft Day Planner Agent</Role>\n",
    "\n",
    "  <Objective>\n",
    "    Generate a bird’s-eye, glanceable rough draft of a day plan from user constraints and inputs.\n",
    "    The output is meant to be refined in later stages; prioritize clarity, order, and approximate durations.\n",
    "  </Objective>\n",
    "\n",
    "  <Inputs>\n",
    "    <Constraints>\n",
    "      Fixed events with exact start/end (sleep, meetings, travel).\n",
    "      Day start time (e.g., work starts 08:00).\n",
    "      Preferred block sizes (e.g., DW=2h, half-DW=1h, quarter-DW=30m).\n",
    "      Preferences (e.g., gym early, stimulant window ~4h).\n",
    "    </Constraints>\n",
    "    <Tasks>\n",
    "      DailyOneThing (single most important outcome).\n",
    "      Supporting tasks (meal prep, chores, fun/creative time).\n",
    "      Optional constraints about stimulant timing, energy, or sequencing.\n",
    "    </Tasks>\n",
    "  </Inputs>\n",
    "\n",
    "  <PlanningRules>\n",
    "    <Rule id=\"R1\">Honor all fixed-time constraints exactly; do not overlap events.</Rule>\n",
    "    <Rule id=\"R2\">Place DailyOneThing into 2–3 Deep Work blocks early-to-midday unless constraints prevent it.</Rule>\n",
    "    <Rule id=\"R3\">Default DW blocks to the user’s standard duration; allow 1h or 30m “partial DW” if specified.</Rule>\n",
    "    <Rule id=\"R4\">Insert buffers where risk is high: after DW (10–15m), after gym (30–45m reset), after meals (10–20m).</Rule>\n",
    "    <Rule id=\"R5\">Keep Shallow Work ≤30% of waking hours; cluster it later in the day when possible.</Rule>\n",
    "    <Rule id=\"R6\">Protect recovery and fun/creative blocks as first-class events; do not label them “optional” unless user did.</Rule>\n",
    "    <Rule id=\"R7\">If stimulants are mentioned: align demanding DW within the effective window; avoid back-to-back dosing unless user insists.</Rule>\n",
    "    <Rule id=\"R8\">Prefer simple sequencing over precision. This is a rough draft for later refinement.</Rule>\n",
    "  </PlanningRules>\n",
    "\n",
    "  <DraftAlgorithm>\n",
    "    <Step>Lock fixed anchors (sleep, immovable meetings, hard start time).</Step>\n",
    "    <Step>Place Morning Routine immediately after sleep end (15–45m, per user preference).</Step>\n",
    "    <Step>Schedule DW blocks for DailyOneThing: hardest block first, then execution/polish blocks.</Step>\n",
    "    <Step>Place gym in the user’s preferred slot (e.g., early) and add a reset buffer after.</Step>\n",
    "    <Step>Place a fun/unstructured block (1–2h) if requested, ideally between stimulant windows or after a major block.</Step>\n",
    "    <Step>Place shallow work (chores/admin) later; keep it bounded.</Step>\n",
    "    <Step>Place meal prep + dinner in the evening; then creative time if requested.</Step>\n",
    "    <Step>End with shutdown ritual + reading in bed + sleep anchor.</Step>\n",
    "  </DraftAlgorithm>\n",
    "\n",
    "  <OutputSpec>\n",
    "    <PrimaryOutput format=\"markdown\">\n",
    "      <![CDATA[\n",
    "      Produce a short, glanceable summary with:\n",
    "      - A few headings (Night/Morning/Midday/Afternoon/Evening) OR emojis (optional).\n",
    "      - ONE line per major chunk (not per micro-event).\n",
    "      - Each line: **Label** — rough duration(or start-end if fixed) (e.g., \"Deep Work (primary) — 2h\").\n",
    "      - Do not include exact timestamps unless the user explicitly asked for times.\n",
    "      - Keep total output under ~12–15 lines.\n",
    "      ]]>\n",
    "    </PrimaryOutput>\n",
    "\n",
    "    <PlanningTrace format=\"xml\">\n",
    "      <TraceRules>\n",
    "        <Rule>Do NOT include chain-of-thought or detailed internal reasoning.</Rule>\n",
    "        <Rule>Include only: assumptions, placements, durations, and checks.</Rule>\n",
    "      </TraceRules>\n",
    "      <TraceTemplate>\n",
    "        <![CDATA[\n",
    "        <PlanTrace>\n",
    "          <Assumptions>\n",
    "            <Assumption id=\"A1\">...</Assumption>\n",
    "          </Assumptions>\n",
    "          <Placements>\n",
    "            <Placement type=\"DW\" label=\"DailyOneThing\" duration=\"PT2H\" rationale=\"hardest first\"/>\n",
    "            <Placement type=\"H\" label=\"Gym\" duration=\"PT1H30M\" rationale=\"early preference\"/>\n",
    "          </Placements>\n",
    "          <Checks>\n",
    "            <Check name=\"NoOverlaps\" status=\"pass\"/>\n",
    "            <Check name=\"ShallowWorkRatio\" status=\"pass|warn\" value=\"...\"/>\n",
    "            <Check name=\"DWCount\" status=\"pass|warn\" value=\"...\"/>\n",
    "          </Checks>\n",
    "        </PlanTrace>\n",
    "        ]]>\n",
    "      </TraceTemplate>\n",
    "    </PlanningTrace>\n",
    "\n",
    "    <Tone>\n",
    "      Crisp, minimal, readable at a glance. No motivational speeches.\n",
    "    </Tone>\n",
    "  </OutputSpec>\n",
    "\n",
    "  <FailureModes>\n",
    "    <Mode id=\"F1\">Missing fixed anchors: infer a reasonable sleep block only if user provided sleep duration + bedtime; otherwise ask one question.</Mode>\n",
    "    <Mode id=\"F2\">Too many tasks: prioritize DailyOneThing and cap DW at 3 blocks; push the rest to shallow work or mark as overflow.</Mode>\n",
    "    <Mode id=\"F3\">Timing conflict: preserve fixed events, then reflow flexible blocks; keep buffers if possible.</Mode>\n",
    "  </FailureModes>\n",
    "</SystemPrompt>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c15678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5f7e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.artifact_editor import (\n",
    "    ArtifactEditorToolSpec,\n",
    "    ArtifactMemoryBlock,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e9551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "try:\n",
    "    load_dotenv()\n",
    "except AssertionError:\n",
    "    load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "\n",
    "token = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "open_router_base_url = os.getenv(\"OPENROUTER_BASE_URL\")\n",
    "client = OpenAI(api_key=token, base_url=open_router_base_url)\n",
    "model=\"google/gemini-3-flash-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17115fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PizzaOrder(size='large', toppings=['pepperoni', 'mushrooms'], address='123 Main St.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal, Optional\n",
    "\n",
    "class PizzaOrder(BaseModel):\n",
    "    size: Literal[\"small\", \"medium\", \"large\", \"extra-large\"]\n",
    "    toppings: list[str]\n",
    "    address: str\n",
    "\n",
    "\n",
    "schema = PizzaOrder.model_json_schema()\n",
    "\n",
    "prompt = lambda order: f\"\"\"\n",
    "You are an expert pizza ordering agent. You need to order a pizza for the user based on their preferences.\n",
    "you respond with json and list the size, toppings and address to deliver to.\n",
    "Here is the order:\n",
    "{order}\n",
    "\"\"\"\n",
    "\n",
    "order = \"I want a large pizza with pepperoni and mushrooms, deliver to 123 Main St.\"\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=model,\n",
    "  input=[{\"role\": \"user\", \"content\": prompt(order)}],\n",
    "  text={\n",
    "    \"format\": {\n",
    "      \"type\": \"json_schema\",\n",
    "      \"name\": \"shopping_list\",\n",
    "      \"strict\": True,\n",
    "      \"schema\": schema\n",
    "    }\n",
    "  }\n",
    ")\n",
    "pizza_order = PizzaOrder.model_validate_json(response.output_text)\n",
    "pizza_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60abe4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Style = Literal[\"napoletana\", \"new-york\", \"sicilian\", \"detroit\", \"roman\"]\n",
    "Size = Literal[\"s\", \"m\", \"l\", \"xl\"]\n",
    "\n",
    "\n",
    "class Pizza(BaseModel):\n",
    "    style: Style\n",
    "    toppings: str\n",
    "    size: Size\n",
    "    quantity: int = Field(ge=1)\n",
    "\n",
    "\n",
    "class PizzaOrder(BaseModel):\n",
    "    pizzas: list[Pizza] = Field(default_factory=list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Annotated, Generic, Literal, Optional, Type, TypeVar, Union, get_args, get_origin\n",
    "\n",
    "from pydantic import BaseModel, Field, create_model, model_validator\n",
    "from llama_index.tools.artifact_editor import ArtifactEditorToolSpec\n",
    "from llama_index.tools.artifact_editor.base import JsonPatch\n",
    "from jinja2 import Template\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_core.tools import FunctionTool\n",
    "\n",
    "from fateforger.llm import build_autogen_chat_client\n",
    "\n",
    "\n",
    "\n",
    "T = TypeVar(\"T\", bound=BaseModel)\n",
    "\n",
    "\n",
    "ErrorCategory = Literal[\n",
    "    \"invalid_path\",\n",
    "    \"invalid_index\",\n",
    "    \"invalid_enum\",\n",
    "    \"missing_field\",\n",
    "    \"schema_validation\",\n",
    "    \"tool_call_failure\",\n",
    "    \"patch_of_patch_missing\",\n",
    "    \"unknown\",\n",
    "]\n",
    "\n",
    "\n",
    "class ErrorInfo(BaseModel):\n",
    "    category: ErrorCategory\n",
    "    message: str\n",
    "    op: dict | None = None\n",
    "    op_index: int | None = None\n",
    "\n",
    "\n",
    "class PatchResult(BaseModel, Generic[T]):\n",
    "    ok: bool\n",
    "    result: T\n",
    "    current_artifact: T\n",
    "    applied: list[dict] = Field(default_factory=list)\n",
    "    error: str | None = None\n",
    "    summary: str | None = None\n",
    "    error_info: ErrorInfo | None = None\n",
    "\n",
    "\n",
    "def _unwrap_optional(annotation: Type) -> Type:\n",
    "    origin = get_origin(annotation)\n",
    "    if origin is Union:\n",
    "        args = [arg for arg in get_args(annotation) if arg is not type(None)]\n",
    "        if len(args) == 1:\n",
    "            return args[0]\n",
    "    return annotation\n",
    "\n",
    "\n",
    "def _infer_list_field(model_cls: Type[BaseModel]) -> str:\n",
    "    # General-purpose: expect exactly one list field unless overridden.\n",
    "    fields = getattr(model_cls, \"model_fields\", None) or getattr(model_cls, \"__fields__\", {})\n",
    "    list_fields = []\n",
    "    for name, field in fields.items():\n",
    "        annotation = getattr(field, \"annotation\", None) or getattr(field, \"outer_type_\", None)\n",
    "        annotation = _unwrap_optional(annotation)\n",
    "        if get_origin(annotation) is list:\n",
    "            list_fields.append(name)\n",
    "    if len(list_fields) != 1:\n",
    "        raise ValueError(f\"Expected exactly one list field, found: {list_fields}\")\n",
    "    return list_fields[0]\n",
    "\n",
    "\n",
    "def _infer_item_model(model_cls: Type[T], list_field: str) -> Type:\n",
    "    field = (getattr(model_cls, \"model_fields\", None) or getattr(model_cls, \"__fields__\", {}))[list_field]\n",
    "    annotation = getattr(field, \"annotation\", None) or getattr(field, \"outer_type_\", None)\n",
    "    annotation = _unwrap_optional(annotation)\n",
    "    args = get_args(annotation)\n",
    "    if not args:\n",
    "        raise ValueError(f\"List field {list_field} is missing item type\")\n",
    "    return args[0]\n",
    "\n",
    "\n",
    "def make_patch_schema(item_model: Type) -> Type[BaseModel]:\n",
    "    # Typed patch schema: add/replace values MUST be valid item objects.\n",
    "    add_op = create_model(\n",
    "        \"AddOp\",\n",
    "        op=(Literal[\"add\"], \"add\"),\n",
    "        path=(str, Field(..., description=\"JSON pointer path\")),\n",
    "        value=(item_model, Field(..., description=\"Item to add\")),\n",
    "    )\n",
    "    replace_op = create_model(\n",
    "        \"ReplaceOp\",\n",
    "        op=(Literal[\"replace\"], \"replace\"),\n",
    "        path=(str, Field(..., description=\"JSON pointer path\")),\n",
    "        value=(item_model, Field(..., description=\"Full item replacement\")),\n",
    "    )\n",
    "    remove_op = create_model(\n",
    "        \"RemoveOp\",\n",
    "        op=(Literal[\"remove\"], \"remove\"),\n",
    "        path=(str, Field(..., description=\"JSON pointer path\")),\n",
    "    )\n",
    "    move_op = create_model(\n",
    "        \"MoveOp\",\n",
    "        op=(Literal[\"move\"], \"move\"),\n",
    "        from_path=(str, Field(..., description=\"Source path (use from_path)\")),\n",
    "        path=(str, Field(..., description=\"Target path\")),\n",
    "    )\n",
    "    copy_op = create_model(\n",
    "        \"CopyOp\",\n",
    "        op=(Literal[\"copy\"], \"copy\"),\n",
    "        from_path=(str, Field(..., description=\"Source path (use from_path)\")),\n",
    "        path=(str, Field(..., description=\"Target path\")),\n",
    "    )\n",
    "    patch_op = Annotated[\n",
    "        Union[add_op, replace_op, remove_op, move_op, copy_op],\n",
    "        Field(discriminator=\"op\"),\n",
    "    ]\n",
    "    patch_plan = create_model(\n",
    "        \"PatchPlan\",\n",
    "        operations=(list[patch_op], Field(..., description=\"RFC6902 ops\")),\n",
    "    )\n",
    "    return patch_plan\n",
    "\n",
    "\n",
    "def make_request_model(patch_plan: Type[BaseModel]) -> Type[BaseModel]:\n",
    "    class PatchRequest(BaseModel):\n",
    "        mode: Literal[\"new\", \"patch_of_patch\"]\n",
    "        patch: patch_plan | JsonPatch\n",
    "\n",
    "        @model_validator(mode=\"after\")\n",
    "        def _validate_mode(self):\n",
    "            if self.mode == \"new\" and not isinstance(self.patch, patch_plan):\n",
    "                raise ValueError(\"mode=new requires a full patch plan\")\n",
    "            if self.mode == \"patch_of_patch\" and not isinstance(self.patch, JsonPatch):\n",
    "                raise ValueError(\"mode=patch_of_patch requires a JsonPatch\")\n",
    "            return self\n",
    "\n",
    "    return PatchRequest\n",
    "\n",
    "\n",
    "def _classify_error(exc: Exception, *, op: dict | None = None, op_index: int | None = None) -> ErrorInfo:\n",
    "    message = str(exc)\n",
    "    lower = message.lower()\n",
    "\n",
    "    if \"no previous patch\" in lower:\n",
    "        category = \"patch_of_patch_missing\"\n",
    "    elif isinstance(exc, IndexError) or \"out of range\" in lower:\n",
    "        category = \"invalid_index\"\n",
    "    elif isinstance(exc, KeyError) or \"invalid field\" in lower or \"cannot access nested field\" in lower or \"path\" in lower:\n",
    "        category = \"invalid_path\"\n",
    "    elif \"field required\" in lower:\n",
    "        category = \"missing_field\"\n",
    "    elif \"input should be\" in lower or \"literal\" in lower or \"enum\" in lower:\n",
    "        category = \"invalid_enum\"\n",
    "    elif \"patch resulted in invalid\" in lower or \"validation\" in lower:\n",
    "        category = \"schema_validation\"\n",
    "    else:\n",
    "        category = \"unknown\"\n",
    "\n",
    "    return ErrorInfo(category=category, message=message, op=op, op_index=op_index)\n",
    "\n",
    "\n",
    "class ObjectPatcher(Generic[T]):\n",
    "    # General-purpose patcher for \"model with one list field\" using AutoGen tool calling.\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_cls: Type[T],\n",
    "        *,\n",
    "        model_client,\n",
    "        schema_by_alias: bool = False,\n",
    "        initial_state: BaseModel | dict | None = None,\n",
    "        list_field: str | None = None,\n",
    "    ) -> None:\n",
    "        self.model_cls = model_cls\n",
    "        self.schema_by_alias = schema_by_alias\n",
    "        self.list_field = list_field or _infer_list_field(model_cls)\n",
    "        self.item_model = _infer_item_model(model_cls, self.list_field)\n",
    "        self.patch_plan = make_patch_schema(self.item_model)\n",
    "        self.PatchRequest = make_request_model(self.patch_plan)\n",
    "        self.patch_request_schema = self.PatchRequest.model_json_schema(by_alias=self.schema_by_alias)\n",
    "        self.ResultModel = PatchResult[model_cls]\n",
    "        self.spec = ArtifactEditorToolSpec(model_cls)\n",
    "        self._set_initial_state(initial_state)\n",
    "        self._initial_snapshot = self._artifact()\n",
    "        self._last_patch: BaseModel | None = None\n",
    "        self._last_success: BaseModel | None = None\n",
    "\n",
    "        self._agent = AssistantAgent(\n",
    "            name=\"PatchAgent\",\n",
    "            model_client=model_client,\n",
    "            tools=[self._build_tool()],\n",
    "            max_tool_iterations=1,\n",
    "            tool_call_summary_format=\"{result}\",\n",
    "            system_message=PATCH_SYSTEM_MESSAGE,\n",
    "        )\n",
    "        self._summarizer = AssistantAgent(\n",
    "            name=\"PatchSummarizer\",\n",
    "            model_client=model_client,\n",
    "            system_message=SUMMARY_SYSTEM_MESSAGE,\n",
    "        )\n",
    "\n",
    "    def _build_tool(self) -> FunctionTool:\n",
    "        async def apply_patch(request: self.PatchRequest) -> PatchResult[T]:  # type: ignore[name-defined]\n",
    "            return self._handle_request(request)\n",
    "\n",
    "        return FunctionTool(\n",
    "            apply_patch,\n",
    "            description=\"Apply a patch request to the current artifact.\",\n",
    "            strict=True,\n",
    "        )\n",
    "\n",
    "    def _set_initial_state(self, initial_state: BaseModel | dict | None) -> None:\n",
    "        if initial_state is None:\n",
    "            data = {self.list_field: []}\n",
    "        elif isinstance(initial_state, BaseModel):\n",
    "            data = initial_state.model_dump()\n",
    "        else:\n",
    "            data = dict(initial_state)\n",
    "        if self.list_field not in data:\n",
    "            data[self.list_field] = []\n",
    "\n",
    "        # Allow invalid inputs by constructing items without validation; patcher fixes them.\n",
    "        if isinstance(self.item_model, type) and issubclass(self.item_model, BaseModel):\n",
    "            items = []\n",
    "            for item in data[self.list_field]:\n",
    "                if isinstance(item, BaseModel):\n",
    "                    items.append(item)\n",
    "                else:\n",
    "                    items.append(self.item_model.model_construct(**dict(item)))\n",
    "            data[self.list_field] = items\n",
    "\n",
    "        try:\n",
    "            self.spec.current_artifact = self.model_cls.model_validate(data)\n",
    "        except Exception:\n",
    "            self.spec.current_artifact = self.model_cls.model_construct(**data)\n",
    "\n",
    "    def _artifact(self) -> dict:\n",
    "        return self.spec.get_current_artifact() or {self.list_field: []}\n",
    "\n",
    "    def _handle_request(self, request: BaseModel) -> BaseModel:\n",
    "        patch = request.patch\n",
    "        if request.mode == \"patch_of_patch\":\n",
    "            try:\n",
    "                patch = self._apply_patch_to_patch(request.patch)\n",
    "            except Exception as exc:\n",
    "                error_info = _classify_error(exc)\n",
    "                return self.ResultModel.model_validate(\n",
    "                    {\n",
    "                        \"ok\": False,\n",
    "                        \"result\": self.model_cls.model_construct(**self._artifact()),\n",
    "                        \"current_artifact\": self.model_cls.model_construct(**self._artifact()),\n",
    "                        \"applied\": [],\n",
    "                        \"error\": str(exc),\n",
    "                        \"summary\": None,\n",
    "                        \"error_info\": error_info,\n",
    "                    }\n",
    "                )\n",
    "        self._last_patch = patch\n",
    "        return self._apply_patch_sequential(patch)\n",
    "\n",
    "    def _apply_patch_to_patch(self, patch_delta: JsonPatch) -> BaseModel:\n",
    "        if self._last_patch is None:\n",
    "            raise ValueError(\"No previous patch to repair.\")\n",
    "        editor = ArtifactEditorToolSpec(self.patch_plan)\n",
    "        editor.current_artifact = self._last_patch\n",
    "        updated = editor.apply_patch(patch_delta)\n",
    "        return self.patch_plan.model_validate(updated)\n",
    "\n",
    "    def _apply_patch_sequential(self, patch: BaseModel) -> PatchResult[T]:\n",
    "        # Apply op-by-op so we can recover at the last successful patch.\n",
    "        applied: list[dict] = []\n",
    "        for op_index, op in enumerate(patch.operations):\n",
    "            op_dict = op.model_dump(exclude_none=True)\n",
    "            try:\n",
    "                self.spec.apply_patch(JsonPatch.model_validate({\"operations\": [op_dict]}))\n",
    "                applied.append(op_dict)\n",
    "            except Exception as exc:\n",
    "                error_info = _classify_error(exc, op=op_dict, op_index=op_index)\n",
    "                return self.ResultModel.model_validate(\n",
    "                    {\n",
    "                        \"ok\": False,\n",
    "                        \"result\": self.model_cls.model_construct(**self._artifact()),\n",
    "                        \"current_artifact\": self.model_cls.model_construct(**self._artifact()),\n",
    "                        \"applied\": applied,\n",
    "                        \"error\": str(exc),\n",
    "                        \"summary\": None,\n",
    "                        \"error_info\": error_info,\n",
    "                    }\n",
    "                )\n",
    "        result_model = self.model_cls.model_validate(self._artifact())\n",
    "        self._last_success = result_model\n",
    "        return self.ResultModel.model_validate(\n",
    "            {\n",
    "                \"ok\": True,\n",
    "                \"result\": result_model,\n",
    "                \"current_artifact\": result_model,\n",
    "                \"applied\": applied,\n",
    "                \"error\": None,\n",
    "                \"summary\": None,\n",
    "                \"error_info\": None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def _render_prompt(self, instruction: str, error: str | None, error_info: ErrorInfo | None) -> str:\n",
    "        template = Template(PATCH_TEMPLATE)\n",
    "        return template.render(\n",
    "            list_field=self.list_field,\n",
    "            artifact=json.dumps(self._artifact(), indent=2),\n",
    "            instruction=instruction,\n",
    "            item_schema=json.dumps(self.item_model.model_json_schema(by_alias=self.schema_by_alias), indent=2)\n",
    "            if hasattr(self.item_model, \"model_json_schema\")\n",
    "            else json.dumps({}, indent=2),\n",
    "            patch_schema=json.dumps(self.patch_plan.model_json_schema(), indent=2),\n",
    "            request_schema=json.dumps(self.patch_request_schema, indent=2),\n",
    "            last_patch=json.dumps(self._last_patch.model_dump(), indent=2) if self._last_patch else \"null\",\n",
    "            error_block=(f\"Previous error: {error}\" if error else \"\"),\n",
    "            error_info=json.dumps(error_info.model_dump(), indent=2) if error_info else \"null\",\n",
    "        )\n",
    "\n",
    "    async def run(self, instruction: str, max_attempts: int = 3) -> PatchResult[T]:\n",
    "        last_error: str | None = None\n",
    "        last_error_info: ErrorInfo | None = None\n",
    "        for _ in range(max_attempts):\n",
    "            prompt = self._render_prompt(instruction, last_error, last_error_info)\n",
    "            response = await self._agent.on_messages([TextMessage(content=prompt, source=\"user\")], CancellationToken())\n",
    "            try:\n",
    "                outcome = self.ResultModel.model_validate_json(response.chat_message.content)\n",
    "            except Exception as exc:\n",
    "                last_error = f\"Invalid tool result: {exc}\"\n",
    "                continue\n",
    "            if outcome.ok:\n",
    "                return outcome\n",
    "            last_error = outcome.error\n",
    "            last_error_info = outcome.error_info\n",
    "\n",
    "        summary = await self._summarize_failure(last_error or \"unknown\", last_error_info)\n",
    "        return self.ResultModel.model_validate(\n",
    "            {\n",
    "                \"ok\": False,\n",
    "                \"result\": self.model_cls.model_construct(**self._artifact()),\n",
    "                \"current_artifact\": self.model_cls.model_construct(**self._artifact()),\n",
    "                \"applied\": [],\n",
    "                \"error\": last_error,\n",
    "                \"summary\": summary,\n",
    "                \"error_info\": last_error_info,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    async def _summarize_failure(self, error: str, error_info: ErrorInfo | None) -> str:\n",
    "        summary_prompt = Template(SUMMARY_TEMPLATE).render(\n",
    "            error=error,\n",
    "            error_info=json.dumps(error_info.model_dump(), indent=2) if error_info else \"null\",\n",
    "            artifact=json.dumps(self._artifact(), indent=2),\n",
    "            last_patch=json.dumps(self._last_patch.model_dump(), indent=2) if self._last_patch else \"null\",\n",
    "        )\n",
    "        response = await self._summarizer.on_messages([TextMessage(content=summary_prompt, source=\"user\")], CancellationToken())\n",
    "        return response.chat_message.content.strip()\n",
    "\n",
    "    def restart_from(self, state: Literal[\"initial\", \"last_success\"]) -> None:\n",
    "        if state == \"last_success\" and self._last_success is not None:\n",
    "            self._set_initial_state(self._last_success)\n",
    "        else:\n",
    "            self._set_initial_state(self._initial_snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c20a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = globals().get(\"model\") or \"google/gemini-3-flash-preview\"\n",
    "\n",
    "PATCH_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a patching agent. Your job is to call the apply_patch tool with a PatchRequest.\n",
    "Do not answer with prose. Always call the tool.\n",
    "\"\"\".strip()\n",
    "\n",
    "PATCH_TEMPLATE = \"\"\"\n",
    "You are editing a list in a JSON artifact.\n",
    "Goal: make the list match the user's instruction.\n",
    "\n",
    "Rules:\n",
    "- Use ONLY the apply_patch tool.\n",
    "- Choose mode = \"new\" for a fresh patch plan.\n",
    "- Choose mode = \"patch_of_patch\" to repair the last patch plan.\n",
    "- Operations are applied sequentially; indices refer to the current state.\n",
    "- For add/replace, value MUST be a full item matching the item schema.\n",
    "- Allowed ops: add, replace, remove, move, copy.\n",
    "- Use from_path (not from) for move/copy.\n",
    "- Prefer small, minimal patches.\n",
    "- Replace whole list items (use path like /{{list_field}}/0), not subfields.\n",
    "\n",
    "List field: /{{list_field}}\n",
    "\n",
    "Current artifact:\n",
    "{{artifact}}\n",
    "\n",
    "User instruction:\n",
    "{{instruction}}\n",
    "\n",
    "Item schema:\n",
    "{{item_schema}}\n",
    "\n",
    "Patch schema:\n",
    "{{patch_schema}}\n",
    "\n",
    "PatchRequest schema:\n",
    "{{request_schema}}\n",
    "\n",
    "Last patch (for patch_of_patch mode):\n",
    "{{last_patch}}\n",
    "\n",
    "Error info (structured):\n",
    "{{error_info}}\n",
    "\n",
    "{{error_block}}\n",
    "\"\"\".strip()\n",
    "\n",
    "SUMMARY_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a concise failure summarizer. Respond with 2-3 bullets.\n",
    "\"\"\".strip()\n",
    "\n",
    "SUMMARY_TEMPLATE = \"\"\"\n",
    "Summarize the patch failure in 2-3 bullets and suggest next steps.\n",
    "\n",
    "Error: {{error}}\n",
    "Error info: {{error_info}}\n",
    "Current artifact: {{artifact}}\n",
    "Last patch: {{last_patch}}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c31a4a",
   "metadata": {},
   "source": [
    "# Patch walkthrough (AutoGen + ArtifactEditor)\n",
    "\n",
    "**Purpose:** Patch an *incorrect* list-based object into the desired state using **AutoGen tool calling** + **typed JSON Patch**.\n",
    "\n",
    "## Steps (mapped to code)\n",
    "1. **Infer list + item types**: `_infer_list_field` + `_infer_item_model` find the list field and its item type.  \n",
    "2. **Typed patch schema**: `make_patch_schema(item_model)` forces `add/replace.value` to be valid items.  \n",
    "3. **PatchRequest schema**: `make_request_schema` lets the agent choose **new** patch or **patch_of_patch**.  \n",
    "4. **Tool call**: `ObjectPatcher._build_tool` exposes `apply_patch(request)` as an AutoGen tool (strict schema).  \n",
    "5. **Sequential apply**: `_apply_patch_sequential` applies op-by-op for recoverability.  \n",
    "6. **Repair loop**: `run` retries; on failure, summarize and allow restart options.\n",
    "\n",
    "## Trade-offs\n",
    "- **Pros:** schema enforcement *before* patching, AutoGen tool loop, recoverable failures.\n",
    "- **Cons:** assumes one list field per model; sequential patching is slower but safer for index shifts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c17202",
   "metadata": {},
   "source": [
    "# Mermaid diagrams\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "  A[User instruction] --> B[ObjectPatcher.run]\n",
    "  B --> C[_render_prompt]\n",
    "  C --> D[AutoGen AssistantAgent]\n",
    "  D --> E[apply_patch tool]\n",
    "  E --> F[ArtifactEditorToolSpec.apply_patch]\n",
    "  F --> G[Updated artifact]\n",
    "```\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "  participant U as User\n",
    "  participant P as ObjectPatcher\n",
    "  participant A as AutoGen Agent\n",
    "  participant T as apply_patch tool\n",
    "  participant E as ArtifactEditor\n",
    "\n",
    "  U->>P: instruction + initial_state\n",
    "  P->>A: prompt (artifact + schemas)\n",
    "  A->>T: PatchRequest(mode=new|patch_of_patch)\n",
    "  T->>E: apply patch ops sequentially\n",
    "  E-->>T: updated artifact or error\n",
    "  T-->>A: PatchOutcome (JSON)\n",
    "  A-->>P: tool summary (JSON)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50548c39",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "- [ ] Allow models with multiple list fields (explicit list_field required).\n",
    "- [ ] Add a small \"patch preview\" mode (no apply, just diff).\n",
    "- [ ] Expand repair prompts with structured error categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7751c17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_autogen_chat_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m wrong_pizza_order = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpizzas\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      3\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mstyle\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mnapolitaon\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtoppings\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mananas\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mm\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquantity\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m}\n\u001b[32m      4\u001b[39m     ]\n\u001b[32m      5\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model_client = \u001b[43mbuild_autogen_chat_client\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mpatch_agent\u001b[39m\u001b[33m\"\u001b[39m, model=model)\n\u001b[32m      8\u001b[39m patcher = ObjectPatcher(PizzaOrder, model_client=model_client, initial_state=wrong_pizza_order)\n\u001b[32m     10\u001b[39m instruction = (\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMake it a napoletana, size l, toppings pepperoni and mushrooms, quantity 2. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAdd a second pizza: sicilian, size s, toppings olives, quantity 1.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'build_autogen_chat_client' is not defined"
     ]
    }
   ],
   "source": [
    "wrong_pizza_order = {\n",
    "    \"pizzas\": [\n",
    "        {\"style\": \"napolitaon\", \"toppings\": \"ananas\", \"size\": \"m\", \"quantity\": 1}\n",
    "    ]\n",
    "}\n",
    "\n",
    "model_client = build_autogen_chat_client(\"patch_agent\", model=model)\n",
    "patcher = ObjectPatcher(PizzaOrder, model_client=model_client, initial_state=wrong_pizza_order)\n",
    "\n",
    "instruction = (\n",
    "    \"Make it a napoletana, size l, toppings pepperoni and mushrooms, quantity 2. \"\n",
    "    \"Add a second pizza: sicilian, size s, toppings olives, quantity 1.\"\n",
    ")\n",
    "\n",
    "result = await patcher.run(instruction, max_attempts=3)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c500c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchResult[PizzaOrder](ok=True, result=PizzaOrder(pizzas=[Pizza(style='napoletana', toppings='pepperoni and mushrooms', size='l', quantity=2), Pizza(style='sicilian', toppings='olives', size='s', quantity=1)]), current_artifact=PizzaOrder(pizzas=[Pizza(style='napoletana', toppings='pepperoni and mushrooms', size='l', quantity=2), Pizza(style='sicilian', toppings='olives', size='s', quantity=1)]), applied=[{'op': 'replace', 'path': '/pizzas/0', 'value': {'style': 'napoletana', 'toppings': 'pepperoni and mushrooms', 'size': 'l', 'quantity': 2}}, {'op': 'add', 'path': '/pizzas/1', 'value': {'style': 'sicilian', 'toppings': 'olives', 'size': 's', 'quantity': 1}}], error=None, summary=None, error_info=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba871b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_session = \n",
    "\n",
    "\n",
    "def make_planning_session(start_time: datetime=None, end_time: datetime=None,duration:TimeDelta=None) -> CalendarEvent:\n",
    "    time_details = {}\n",
    "    return CalendarEvent(\n",
    "        summary=\"Planning Session for Timeboxing\",\n",
    "        **time_details\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fateforger.agents.timeboxing.timebox import Timebox,CalendarEvent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e3898",
   "metadata": {},
   "source": [
    "# Lightweight Timebox Generation Models\n",
    "\n",
    "## Design goals\n",
    "1. **Token-efficient** — short aliases for every field so the LLM generates less JSON\n",
    "2. **Discriminated timing** — 4 anchoring variants instead of 3 optional fields + boolean\n",
    "3. **Domain ops** — typed operations instead of generic JSON Patch\n",
    "4. **Convertible** — deterministic `resolve_times()` → `GCalEvent` for the MCP tool\n",
    "\n",
    "## Alias map\n",
    "| Model field | Alias | Meaning |\n",
    "|---|---|---|\n",
    "| `TBEvent.n` | — | name / summary |\n",
    "| `TBEvent.d` | — | description |\n",
    "| `TBEvent.t` | — | event type (`DW`, `H`, `R`, …) |\n",
    "| `TBEvent.p` | — | placement / timing |\n",
    "| `Timing.a` | — | anchor kind (`ap`, `bn`, `fs`, `fw`) |\n",
    "| `dur` | — | duration (ISO 8601) |\n",
    "| `st` | — | start time (HH:MM) |\n",
    "| `et` | — | end time (HH:MM) |\n",
    "\n",
    "## Anchor types\n",
    "- `ap` — **after previous**: starts when previous ends (default, most events)\n",
    "- `bn` — **before next**: ends when next event starts\n",
    "- `fs` — **fixed start**: pinned start + duration\n",
    "- `fw` — **fixed window**: pinned start + end\n",
    "\n",
    "## Token comparison (5-event timebox)\n",
    "```\n",
    "CalendarEvent (full):  ~180 tokens per event → ~900 total\n",
    "TBEvent (aliased):     ~40 tokens per event  → ~200 total\n",
    "                       ~4.5× fewer tokens\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331602cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TBEvent JSON Schema ===\n",
      "{\n",
      "  \"$defs\": {\n",
      "    \"AfterPrev\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Starts immediately after the previous event ends. Default.\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"const\": \"ap\",\n",
      "          \"default\": \"ap\",\n",
      "          \"title\": \"A\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"dur\": {\n",
      "          \"description\": \"Duration (ISO 8601, e.g. PT30M)\",\n",
      "          \"format\": \"duration\",\n",
      "          \"title\": \"Dur\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"dur\"\n",
      "      ],\n",
      "      \"title\": \"AfterPrev\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"BeforeNext\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Ends immediately when the next event starts.\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"const\": \"bn\",\n",
      "          \"default\": \"bn\",\n",
      "          \"title\": \"A\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"dur\": {\n",
      "          \"description\": \"Duration (ISO 8601)\",\n",
      "          \"format\": \"duration\",\n",
      "          \"title\": \"Dur\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"dur\"\n",
      "      ],\n",
      "      \"title\": \"BeforeNext\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"ET\": {\n",
      "      \"description\": \"Event type \\u2014 compact codes for LLM generation.\",\n",
      "      \"enum\": [\n",
      "        \"M\",\n",
      "        \"C\",\n",
      "        \"DW\",\n",
      "        \"SW\",\n",
      "        \"PR\",\n",
      "        \"H\",\n",
      "        \"R\",\n",
      "        \"BU\",\n",
      "        \"BG\"\n",
      "      ],\n",
      "      \"title\": \"ET\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"FixedStart\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Pinned to a specific start time.\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"const\": \"fs\",\n",
      "          \"default\": \"fs\",\n",
      "          \"title\": \"A\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"st\": {\n",
      "          \"description\": \"Start time (HH:MM)\",\n",
      "          \"format\": \"time\",\n",
      "          \"title\": \"St\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"dur\": {\n",
      "          \"description\": \"Duration (ISO 8601)\",\n",
      "          \"format\": \"duration\",\n",
      "          \"title\": \"Dur\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"st\",\n",
      "        \"dur\"\n",
      "      ],\n",
      "      \"title\": \"FixedStart\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"FixedWindow\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Pinned start and end \\u2014 for meetings, background events, etc.\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"const\": \"fw\",\n",
      "          \"default\": \"fw\",\n",
      "          \"title\": \"A\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"st\": {\n",
      "          \"description\": \"Start time (HH:MM)\",\n",
      "          \"format\": \"time\",\n",
      "          \"title\": \"St\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"et\": {\n",
      "          \"description\": \"End time (HH:MM)\",\n",
      "          \"format\": \"time\",\n",
      "          \"title\": \"Et\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"st\",\n",
      "        \"et\"\n",
      "      ],\n",
      "      \"title\": \"FixedWindow\",\n",
      "      \"type\": \"object\"\n",
      "    }\n",
      "  },\n",
      "  \"additionalProperties\": false,\n",
      "  \"description\": \"A single timeboxed event \\u2014 minimal fields for LLM generation.\",\n",
      "  \"properties\": {\n",
      "    \"n\": {\n",
      "      \"description\": \"Event name / summary\",\n",
      "      \"title\": \"N\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"d\": {\n",
      "      \"default\": \"\",\n",
      "      \"description\": \"Short description\",\n",
      "      \"title\": \"D\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"t\": {\n",
      "      \"$ref\": \"#/$defs/ET\",\n",
      "      \"description\": \"Event type code\"\n",
      "    },\n",
      "    \"p\": {\n",
      "      \"description\": \"Time placement\",\n",
      "      \"discriminator\": {\n",
      "        \"mapping\": {\n",
      "          \"ap\": \"#/$defs/AfterPrev\",\n",
      "          \"bn\": \"#/$defs/BeforeNext\",\n",
      "          \"fs\": \"#/$defs/FixedStart\",\n",
      "          \"fw\": \"#/$defs/FixedWindow\"\n",
      "        },\n",
      "        \"propertyName\": \"a\"\n",
      "      },\n",
      "      \"oneOf\": [\n",
      "        {\n",
      "          \"$ref\": \"#/$defs/AfterPrev\"\n",
      "        },\n",
      "        {\n",
      "          \"$ref\": \"#/$defs/BeforeNext\"\n",
      "        },\n",
      "        {\n",
      "          \"$ref\": \"#/$defs/FixedStart\"\n",
      "        },\n",
      "        {\n",
      "          \"$ref\": \"#/$defs/FixedWindow\"\n",
      "        }\n",
      "      ],\n",
      "      \"title\": \"P\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"n\",\n",
      "    \"t\",\n",
      "    \"p\"\n",
      "  ],\n",
      "  \"title\": \"TBEvent\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Lightweight timebox models for token-efficient LLM generation.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from datetime import date as date_type, datetime, time, timedelta\n",
    "from enum import Enum\n",
    "from typing import Annotated, Literal, Union\n",
    "\n",
    "from isodate import parse_duration as _parse_dur\n",
    "from pydantic import BaseModel, ConfigDict, Field, field_validator, model_validator\n",
    "\n",
    "\n",
    "# ── EventType (reuse existing short codes) ────────────────────────────────\n",
    "# We mirror the production EventType values but as a plain str enum\n",
    "# so we avoid SQLAlchemy/ChoiceEnum machinery in the generation path.\n",
    "\n",
    "class ET(str, Enum):\n",
    "    \"\"\"Event type — compact codes for LLM generation.\"\"\"\n",
    "    M  = \"M\"    # meeting\n",
    "    C  = \"C\"    # commute\n",
    "    DW = \"DW\"   # deep work\n",
    "    SW = \"SW\"   # shallow work\n",
    "    PR = \"PR\"   # plan & review\n",
    "    H  = \"H\"    # habit / routine\n",
    "    R  = \"R\"    # regeneration (meals, sleep, rest)\n",
    "    BU = \"BU\"   # buffer\n",
    "    BG = \"BG\"   # background (must have fixed timing)\n",
    "\n",
    "\n",
    "# ── Time anchoring (discriminated union) ──────────────────────────────────\n",
    "\n",
    "class AfterPrev(BaseModel):\n",
    "    \"\"\"Starts immediately after the previous event ends. Default.\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    a: Literal[\"ap\"] = \"ap\"\n",
    "    dur: timedelta = Field(..., description=\"Duration (ISO 8601, e.g. PT30M)\")\n",
    "\n",
    "    _parse = field_validator(\"dur\", mode=\"before\")(lambda cls, v: _parse_dur(v) if isinstance(v, str) else v)\n",
    "\n",
    "\n",
    "class BeforeNext(BaseModel):\n",
    "    \"\"\"Ends immediately when the next event starts.\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    a: Literal[\"bn\"] = \"bn\"\n",
    "    dur: timedelta = Field(..., description=\"Duration (ISO 8601)\")\n",
    "\n",
    "    _parse = field_validator(\"dur\", mode=\"before\")(lambda cls, v: _parse_dur(v) if isinstance(v, str) else v)\n",
    "\n",
    "\n",
    "class FixedStart(BaseModel):\n",
    "    \"\"\"Pinned to a specific start time.\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    a: Literal[\"fs\"] = \"fs\"\n",
    "    st: time = Field(..., description=\"Start time (HH:MM)\")\n",
    "    dur: timedelta = Field(..., description=\"Duration (ISO 8601)\")\n",
    "\n",
    "    _parse_t = field_validator(\"st\", mode=\"before\")(lambda cls, v: time.fromisoformat(v) if isinstance(v, str) else v)\n",
    "    _parse_d = field_validator(\"dur\", mode=\"before\")(lambda cls, v: _parse_dur(v) if isinstance(v, str) else v)\n",
    "\n",
    "\n",
    "class FixedWindow(BaseModel):\n",
    "    \"\"\"Pinned start and end — for meetings, background events, etc.\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    a: Literal[\"fw\"] = \"fw\"\n",
    "    st: time = Field(..., description=\"Start time (HH:MM)\")\n",
    "    et: time = Field(..., description=\"End time (HH:MM)\")\n",
    "\n",
    "    _parse_st = field_validator(\"st\", mode=\"before\")(lambda cls, v: time.fromisoformat(v) if isinstance(v, str) else v)\n",
    "    _parse_et = field_validator(\"et\", mode=\"before\")(lambda cls, v: time.fromisoformat(v) if isinstance(v, str) else v)\n",
    "\n",
    "\n",
    "Timing = Annotated[\n",
    "    Union[AfterPrev, BeforeNext, FixedStart, FixedWindow],\n",
    "    Field(discriminator=\"a\"),\n",
    "]\n",
    "\n",
    "\n",
    "# ── TBEvent (the generation-time event model) ────────────────────────────\n",
    "\n",
    "class TBEvent(BaseModel):\n",
    "    \"\"\"A single timeboxed event — minimal fields for LLM generation.\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "    n: str = Field(..., description=\"Event name / summary\")\n",
    "    d: str = Field(\"\", description=\"Short description\")\n",
    "    t: ET = Field(..., description=\"Event type code\")\n",
    "    p: Timing = Field(..., description=\"Time placement\")\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def bg_needs_fixed(self) -> \"TBEvent\":\n",
    "        \"\"\"Background events must have a fixed window or fixed start.\"\"\"\n",
    "        if self.t == ET.BG and self.p.a not in (\"fs\", \"fw\"):\n",
    "            raise ValueError(\"Background events (BG) require fixed_start or fixed_window timing\")\n",
    "        return self\n",
    "\n",
    "\n",
    "# ── TBPlan (the generation-time timebox) ──────────────────────────────────\n",
    "\n",
    "class TBPlan(BaseModel):\n",
    "    \"\"\"A day's timebox plan — lightweight container for LLM generation.\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "    events: list[TBEvent] = Field(default_factory=list)\n",
    "    date: date_type = Field(default_factory=date_type.today)\n",
    "    tz: str = Field(default=\"Europe/Amsterdam\", description=\"IANA timezone\")\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def chain_must_be_anchored(self) -> \"TBPlan\":\n",
    "        \"\"\"At least one non-BG event must have a fixed time to anchor the chain.\"\"\"\n",
    "        chain = [e for e in self.events if e.t != ET.BG]\n",
    "        if chain and not any(e.p.a in (\"fs\", \"fw\") for e in chain):\n",
    "            raise ValueError(\n",
    "                \"Event chain needs at least one fixed_start or fixed_window anchor\"\n",
    "            )\n",
    "        return self\n",
    "\n",
    "    def resolve_times(self) -> list[dict]:\n",
    "        \"\"\"\n",
    "        Deterministically compute concrete start/end for every event.\n",
    "        Returns list of dicts: [{n, d, t, start_time, end_time, duration}, ...]\n",
    "        \"\"\"\n",
    "        planning_date = self.date\n",
    "        resolved: list[dict] = []\n",
    "\n",
    "        # ── Forward pass: resolve after_previous and fixed_start/fixed_window ──\n",
    "        last_end_dt: datetime | None = None\n",
    "        for i, ev in enumerate(self.events):\n",
    "            r = {\"n\": ev.n, \"d\": ev.d, \"t\": ev.t.value, \"index\": i}\n",
    "            p = ev.p\n",
    "\n",
    "            if p.a == \"ap\":  # after_previous\n",
    "                if last_end_dt is None:\n",
    "                    raise ValueError(f\"Event '{ev.n}' (after_previous) has no preceding event to anchor to\")\n",
    "                start_dt = last_end_dt\n",
    "                end_dt = start_dt + p.dur\n",
    "                r.update(start_time=start_dt.time(), end_time=end_dt.time(), duration=p.dur)\n",
    "\n",
    "            elif p.a == \"fs\":  # fixed_start\n",
    "                start_dt = datetime.combine(planning_date, p.st)\n",
    "                end_dt = start_dt + p.dur\n",
    "                r.update(start_time=p.st, end_time=end_dt.time(), duration=p.dur)\n",
    "\n",
    "            elif p.a == \"fw\":  # fixed_window\n",
    "                start_dt = datetime.combine(planning_date, p.st)\n",
    "                end_dt = datetime.combine(planning_date, p.et)\n",
    "                r.update(start_time=p.st, end_time=p.et, duration=end_dt - start_dt)\n",
    "\n",
    "            elif p.a == \"bn\":  # before_next — placeholder, resolved in backward pass\n",
    "                r.update(duration=p.dur, _pending=\"bn\")\n",
    "                resolved.append(r)\n",
    "                continue  # don't update last_end_dt yet\n",
    "\n",
    "            last_end_dt = datetime.combine(planning_date, r[\"end_time\"])\n",
    "            resolved.append(r)\n",
    "\n",
    "        # ── Backward pass: resolve before_next ──\n",
    "        next_start_dt: datetime | None = None\n",
    "        for r in reversed(resolved):\n",
    "            if r.get(\"_pending\") == \"bn\":\n",
    "                if next_start_dt is None:\n",
    "                    raise ValueError(f\"Event '{r['n']}' (before_next) has no following event to anchor to\")\n",
    "                end_dt = next_start_dt\n",
    "                start_dt = end_dt - r[\"duration\"]\n",
    "                r.update(start_time=start_dt.time(), end_time=end_dt.time())\n",
    "                del r[\"_pending\"]\n",
    "            if \"start_time\" in r:\n",
    "                next_start_dt = datetime.combine(planning_date, r[\"start_time\"])\n",
    "\n",
    "        # ── Overlap check (non-BG only) ──\n",
    "        chain = [r for r in resolved if r[\"t\"] != \"BG\"]\n",
    "        for a, b in zip(chain, chain[1:]):\n",
    "            a_end = datetime.combine(planning_date, a[\"end_time\"])\n",
    "            b_start = datetime.combine(planning_date, b[\"start_time\"])\n",
    "            if a_end > b_start:\n",
    "                raise ValueError(f\"Overlap: '{a['n']}' ends {a['end_time']} but '{b['n']}' starts {b['start_time']}\")\n",
    "\n",
    "        return resolved\n",
    "\n",
    "\n",
    "# ── Quick schema preview ──────────────────────────────────────────────────\n",
    "print(\"=== TBEvent JSON Schema ===\")\n",
    "import json\n",
    "print(json.dumps(TBEvent.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c62ffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TBPatch JSON Schema ===\n",
      "{\n",
      "  \"$defs\": {\n",
      "    \"AddEvents\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Add one or more events. `after` = insert position (None \\u2192 append).\",\n",
      "      \"properties\": {\n",
      "        \"op\": {\n",
      "          \"const\": \"ae\",\n",
      "          \"default\": \"ae\",\n",
      "          \"title\": \"Op\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"events\": {\n",
      "          \"items\": {\n",
      "            \"$ref\": \"#/$defs/TBEvent\"\n",
      "          },\n",
      "          \"minItems\": 1,\n",
      "          \"title\": \"Events\",\n",
      "          \"type\": \"array\"\n",
      "        },\n",
      "        \"after\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"type\": \"integer\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null,\n",
      "          \"description\": \"Insert after this index (None=append)\",\n",
      "          \"title\": \"After\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"events\"\n",
      "      ],\n",
      "      \"title\": \"AddEvents\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"AfterPrev\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Starts immediately after the previous event ends. Default.\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"const\": \"ap\",\n",
      "          \"default\": \"ap\",\n",
      "          \"title\": \"A\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"dur\": {\n",
      "          \"description\": \"Duration (ISO 8601, e.g. PT30M)\",\n",
      "          \"format\": \"duration\",\n",
      "          \"title\": \"Dur\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"dur\"\n",
      "      ],\n",
      "      \"title\": \"AfterPrev\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"BeforeNext\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Ends immediately when the next event starts.\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"const\": \"bn\",\n",
      "          \"default\": \"bn\",\n",
      "          \"title\": \"A\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"dur\": {\n",
      "          \"description\": \"Duration (ISO 8601)\",\n",
      "          \"format\": \"duration\",\n",
      "          \"title\": \"Dur\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"dur\"\n",
      "      ],\n",
      "      \"title\": \"BeforeNext\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"ET\": {\n",
      "      \"description\": \"Event type \\u2014 compact codes for LLM generation.\",\n",
      "      \"enum\": [\n",
      "        \"M\",\n",
      "        \"C\",\n",
      "        \"DW\",\n",
      "        \"SW\",\n",
      "        \"PR\",\n",
      "        \"H\",\n",
      "        \"R\",\n",
      "        \"BU\",\n",
      "        \"BG\"\n",
      "      ],\n",
      "      \"title\": \"ET\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"FixedStart\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Pinned to a specific start time.\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"const\": \"fs\",\n",
      "          \"default\": \"fs\",\n",
      "          \"title\": \"A\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"st\": {\n",
      "          \"description\": \"Start time (HH:MM)\",\n",
      "          \"format\": \"time\",\n",
      "          \"title\": \"St\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"dur\": {\n",
      "          \"description\": \"Duration (ISO 8601)\",\n",
      "          \"format\": \"duration\",\n",
      "          \"title\": \"Dur\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"st\",\n",
      "        \"dur\"\n",
      "      ],\n",
      "      \"title\": \"FixedStart\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"FixedWindow\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Pinned start and end \\u2014 for meetings, background events, etc.\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"const\": \"fw\",\n",
      "          \"default\": \"fw\",\n",
      "          \"title\": \"A\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"st\": {\n",
      "          \"description\": \"Start time (HH:MM)\",\n",
      "          \"format\": \"time\",\n",
      "          \"title\": \"St\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"et\": {\n",
      "          \"description\": \"End time (HH:MM)\",\n",
      "          \"format\": \"time\",\n",
      "          \"title\": \"Et\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"st\",\n",
      "        \"et\"\n",
      "      ],\n",
      "      \"title\": \"FixedWindow\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"MoveEvent\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Move an event to a different position in the ordered list.\",\n",
      "      \"properties\": {\n",
      "        \"op\": {\n",
      "          \"const\": \"me\",\n",
      "          \"default\": \"me\",\n",
      "          \"title\": \"Op\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"fr\": {\n",
      "          \"description\": \"From index\",\n",
      "          \"title\": \"Fr\",\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        \"to\": {\n",
      "          \"description\": \"To index\",\n",
      "          \"title\": \"To\",\n",
      "          \"type\": \"integer\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"fr\",\n",
      "        \"to\"\n",
      "      ],\n",
      "      \"title\": \"MoveEvent\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"RemoveEvent\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Remove an event by index.\",\n",
      "      \"properties\": {\n",
      "        \"op\": {\n",
      "          \"const\": \"re\",\n",
      "          \"default\": \"re\",\n",
      "          \"title\": \"Op\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"i\": {\n",
      "          \"description\": \"Index of event to remove\",\n",
      "          \"title\": \"I\",\n",
      "          \"type\": \"integer\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"i\"\n",
      "      ],\n",
      "      \"title\": \"RemoveEvent\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"ReplaceAll\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Replace the entire event list (initial generation or full rebuild).\",\n",
      "      \"properties\": {\n",
      "        \"op\": {\n",
      "          \"const\": \"ra\",\n",
      "          \"default\": \"ra\",\n",
      "          \"title\": \"Op\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"events\": {\n",
      "          \"items\": {\n",
      "            \"$ref\": \"#/$defs/TBEvent\"\n",
      "          },\n",
      "          \"minItems\": 1,\n",
      "          \"title\": \"Events\",\n",
      "          \"type\": \"array\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"events\"\n",
      "      ],\n",
      "      \"title\": \"ReplaceAll\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"TBEvent\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"A single timeboxed event \\u2014 minimal fields for LLM generation.\",\n",
      "      \"properties\": {\n",
      "        \"n\": {\n",
      "          \"description\": \"Event name / summary\",\n",
      "          \"title\": \"N\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"d\": {\n",
      "          \"default\": \"\",\n",
      "          \"description\": \"Short description\",\n",
      "          \"title\": \"D\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"t\": {\n",
      "          \"$ref\": \"#/$defs/ET\",\n",
      "          \"description\": \"Event type code\"\n",
      "        },\n",
      "        \"p\": {\n",
      "          \"description\": \"Time placement\",\n",
      "          \"discriminator\": {\n",
      "            \"mapping\": {\n",
      "              \"ap\": \"#/$defs/AfterPrev\",\n",
      "              \"bn\": \"#/$defs/BeforeNext\",\n",
      "              \"fs\": \"#/$defs/FixedStart\",\n",
      "              \"fw\": \"#/$defs/FixedWindow\"\n",
      "            },\n",
      "            \"propertyName\": \"a\"\n",
      "          },\n",
      "          \"oneOf\": [\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/AfterPrev\"\n",
      "            },\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/BeforeNext\"\n",
      "            },\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/FixedStart\"\n",
      "            },\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/FixedWindow\"\n",
      "            }\n",
      "          ],\n",
      "          \"title\": \"P\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"n\",\n",
      "        \"t\",\n",
      "        \"p\"\n",
      "      ],\n",
      "      \"title\": \"TBEvent\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"UpdateEvent\": {\n",
      "      \"additionalProperties\": false,\n",
      "      \"description\": \"Update specific fields on an existing event. Only set fields are changed.\",\n",
      "      \"properties\": {\n",
      "        \"op\": {\n",
      "          \"const\": \"ue\",\n",
      "          \"default\": \"ue\",\n",
      "          \"title\": \"Op\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"i\": {\n",
      "          \"description\": \"Index of event to update\",\n",
      "          \"title\": \"I\",\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        \"n\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"type\": \"string\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null,\n",
      "          \"description\": \"New name\",\n",
      "          \"title\": \"N\"\n",
      "        },\n",
      "        \"d\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"type\": \"string\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null,\n",
      "          \"description\": \"New description\",\n",
      "          \"title\": \"D\"\n",
      "        },\n",
      "        \"t\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/ET\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null,\n",
      "          \"description\": \"New event type\"\n",
      "        },\n",
      "        \"p\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"discriminator\": {\n",
      "                \"mapping\": {\n",
      "                  \"ap\": \"#/$defs/AfterPrev\",\n",
      "                  \"bn\": \"#/$defs/BeforeNext\",\n",
      "                  \"fs\": \"#/$defs/FixedStart\",\n",
      "                  \"fw\": \"#/$defs/FixedWindow\"\n",
      "                },\n",
      "                \"propertyName\": \"a\"\n",
      "              },\n",
      "              \"oneOf\": [\n",
      "                {\n",
      "                  \"$ref\": \"#/$defs/AfterPrev\"\n",
      "                },\n",
      "                {\n",
      "                  \"$ref\": \"#/$defs/BeforeNext\"\n",
      "                },\n",
      "                {\n",
      "                  \"$ref\": \"#/$defs/FixedStart\"\n",
      "                },\n",
      "                {\n",
      "                  \"$ref\": \"#/$defs/FixedWindow\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null,\n",
      "          \"description\": \"New time placement\",\n",
      "          \"title\": \"P\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"i\"\n",
      "      ],\n",
      "      \"title\": \"UpdateEvent\",\n",
      "      \"type\": \"object\"\n",
      "    }\n",
      "  },\n",
      "  \"additionalProperties\": false,\n",
      "  \"description\": \"A batch of typed operations to apply to a TBPlan.\",\n",
      "  \"properties\": {\n",
      "    \"ops\": {\n",
      "      \"items\": {\n",
      "        \"discriminator\": {\n",
      "          \"mapping\": {\n",
      "            \"ae\": \"#/$defs/AddEvents\",\n",
      "            \"me\": \"#/$defs/MoveEvent\",\n",
      "            \"ra\": \"#/$defs/ReplaceAll\",\n",
      "            \"re\": \"#/$defs/RemoveEvent\",\n",
      "            \"ue\": \"#/$defs/UpdateEvent\"\n",
      "          },\n",
      "          \"propertyName\": \"op\"\n",
      "        },\n",
      "        \"oneOf\": [\n",
      "          {\n",
      "            \"$ref\": \"#/$defs/AddEvents\"\n",
      "          },\n",
      "          {\n",
      "            \"$ref\": \"#/$defs/RemoveEvent\"\n",
      "          },\n",
      "          {\n",
      "            \"$ref\": \"#/$defs/UpdateEvent\"\n",
      "          },\n",
      "          {\n",
      "            \"$ref\": \"#/$defs/MoveEvent\"\n",
      "          },\n",
      "          {\n",
      "            \"$ref\": \"#/$defs/ReplaceAll\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"minItems\": 1,\n",
      "      \"title\": \"Ops\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"ops\"\n",
      "  ],\n",
      "  \"title\": \"TBPatch\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Domain-specific operations for timebox patching.\"\"\"\n",
    "\n",
    "\n",
    "# ── Operations ────────────────────────────────────────────────────────────\n",
    "# Each op is a discriminated union member.  The LLM picks the op type\n",
    "# and gets a typed schema — no generic JSON Patch paths or `value: Any`.\n",
    "\n",
    "class AddEvents(BaseModel):\n",
    "    \"\"\"Add one or more events. `after` = insert position (None → append).\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    op: Literal[\"ae\"] = \"ae\"\n",
    "    events: list[TBEvent] = Field(..., min_length=1)\n",
    "    after: int | None = Field(None, description=\"Insert after this index (None=append)\")\n",
    "\n",
    "\n",
    "class RemoveEvent(BaseModel):\n",
    "    \"\"\"Remove an event by index.\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    op: Literal[\"re\"] = \"re\"\n",
    "    i: int = Field(..., description=\"Index of event to remove\")\n",
    "\n",
    "\n",
    "class UpdateEvent(BaseModel):\n",
    "    \"\"\"Update specific fields on an existing event. Only set fields are changed.\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    op: Literal[\"ue\"] = \"ue\"\n",
    "    i: int = Field(..., description=\"Index of event to update\")\n",
    "    n: str | None = Field(None, description=\"New name\")\n",
    "    d: str | None = Field(None, description=\"New description\")\n",
    "    t: ET | None = Field(None, description=\"New event type\")\n",
    "    p: Timing | None = Field(None, description=\"New time placement\")\n",
    "\n",
    "\n",
    "class MoveEvent(BaseModel):\n",
    "    \"\"\"Move an event to a different position in the ordered list.\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    op: Literal[\"me\"] = \"me\"\n",
    "    fr: int = Field(..., description=\"From index\")\n",
    "    to: int = Field(..., description=\"To index\")\n",
    "\n",
    "\n",
    "class ReplaceAll(BaseModel):\n",
    "    \"\"\"Replace the entire event list (initial generation or full rebuild).\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    op: Literal[\"ra\"] = \"ra\"\n",
    "    events: list[TBEvent] = Field(..., min_length=1)\n",
    "\n",
    "\n",
    "TBOp = Annotated[\n",
    "    Union[AddEvents, RemoveEvent, UpdateEvent, MoveEvent, ReplaceAll],\n",
    "    Field(discriminator=\"op\"),\n",
    "]\n",
    "\n",
    "\n",
    "class TBPatch(BaseModel):\n",
    "    \"\"\"A batch of typed operations to apply to a TBPlan.\"\"\"\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    ops: list[TBOp] = Field(..., min_length=1)\n",
    "\n",
    "\n",
    "# ── Patch applicator ─────────────────────────────────────────────────────\n",
    "\n",
    "def apply_tb_ops(plan: TBPlan, patch: TBPatch) -> TBPlan:\n",
    "    \"\"\"Apply domain operations sequentially, return a new validated TBPlan.\"\"\"\n",
    "    events = list(plan.events)  # mutable copy\n",
    "\n",
    "    for op in patch.ops:\n",
    "        match op.op:\n",
    "            case \"ae\":  # add_events\n",
    "                if op.after is not None:\n",
    "                    for offset, ev in enumerate(op.events):\n",
    "                        events.insert(op.after + 1 + offset, ev)\n",
    "                else:\n",
    "                    events.extend(op.events)\n",
    "\n",
    "            case \"re\":  # remove_event\n",
    "                if op.i < 0 or op.i >= len(events):\n",
    "                    raise IndexError(f\"remove: index {op.i} out of range (0..{len(events)-1})\")\n",
    "                events.pop(op.i)\n",
    "\n",
    "            case \"ue\":  # update_event\n",
    "                if op.i < 0 or op.i >= len(events):\n",
    "                    raise IndexError(f\"update: index {op.i} out of range (0..{len(events)-1})\")\n",
    "                current = events[op.i]\n",
    "                # Build merged dict and re-validate to preserve discriminated unions\n",
    "                merged = current.model_dump()\n",
    "                updates = {k: v for k, v in [\n",
    "                    (\"n\", op.n), (\"d\", op.d), (\"t\", op.t), (\"p\", op.p),\n",
    "                ] if v is not None}\n",
    "                # For Timing (p), pass the model directly so Pydantic re-validates\n",
    "                if \"p\" in updates and isinstance(updates[\"p\"], BaseModel):\n",
    "                    updates[\"p\"] = updates[\"p\"].model_dump()\n",
    "                if \"t\" in updates and isinstance(updates[\"t\"], ET):\n",
    "                    updates[\"t\"] = updates[\"t\"].value\n",
    "                merged.update(updates)\n",
    "                events[op.i] = TBEvent.model_validate(merged)\n",
    "\n",
    "            case \"me\":  # move_event\n",
    "                if op.fr < 0 or op.fr >= len(events):\n",
    "                    raise IndexError(f\"move: from_index {op.fr} out of range\")\n",
    "                ev = events.pop(op.fr)\n",
    "                to = min(op.to, len(events))\n",
    "                events.insert(to, ev)\n",
    "\n",
    "            case \"ra\":  # replace_all\n",
    "                events = list(op.events)\n",
    "\n",
    "    return TBPlan(events=events, date=plan.date, tz=plan.tz)\n",
    "\n",
    "\n",
    "print(\"=== TBPatch JSON Schema ===\")\n",
    "print(json.dumps(TBPatch.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c851034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Resolved schedule ===\n",
      "  07:00–07:30  Morning routine (H)\n",
      "  07:30–09:30  Deep work: thesis (DW)\n",
      "  09:30–09:45  Coffee break (BU)\n",
      "  10:00–10:15  Standup (M)\n",
      "  10:15–11:45  Deep work: thesis (DW)\n",
      "  11:45–12:30  Lunch (R)\n",
      "\n",
      "=== 6 GCalEvent objects ready for MCP ===\n",
      "  Morning routine: 2026-02-07T07:00:00+01:00 → 2026-02-07T07:30:00+01:00\n",
      "  Deep work: thesis: 2026-02-07T07:30:00+01:00 → 2026-02-07T09:30:00+01:00\n",
      "  Coffee break: 2026-02-07T09:30:00+01:00 → 2026-02-07T09:45:00+01:00\n",
      "  Standup: 2026-02-07T10:00:00+01:00 → 2026-02-07T10:15:00+01:00\n",
      "  Deep work: thesis: 2026-02-07T10:15:00+01:00 → 2026-02-07T11:45:00+01:00\n",
      "  Lunch: 2026-02-07T11:45:00+01:00 → 2026-02-07T12:30:00+01:00\n",
      "\n",
      "=== TBPlan JSON size: 992 chars ===\n",
      "{\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"n\": \"Morning routine\",\n",
      "      \"d\": \"Shower, coffee\",\n",
      "      \"t\": \"H\",\n",
      "      \"p\": {\n",
      "        \"a\": \"fs\",\n",
      "        \"st\": \"07:00:00\",\n",
      "        \"dur\": \"PT30M\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"n\": \"Deep work: thesis\",\n",
      "      \"d\": \"Chapter 3 draft\",\n",
      "      \"t\": \"DW\",\n",
      "      \"p\": {\n",
      "        \"a\": \"ap\",\n",
      "        \"dur\": \"PT2H\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"n\": \"Coffee break\",\n",
      "      \"d\": \"\",\n",
      "      \"t\": \"BU\",\n",
      "      \"p\": {\n",
      "        \"a\": \"ap\",\n",
      "        \"dur\": \"PT15M\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"n\": \" ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Conversion: TBPlan → GCalEvent list for the MCP calendar tool.\"\"\"\n",
    "\n",
    "from zoneinfo import ZoneInfo\n",
    "from fateforger.adapters.calendar.models import GCalEvent, GCalEventDateTime\n",
    "\n",
    "# Map ET codes → production EventType color_ids for Google Calendar\n",
    "_ET_COLOR_MAP: dict[str, str] = {\n",
    "    \"M\": \"6\", \"C\": \"4\", \"DW\": \"9\", \"SW\": \"8\",\n",
    "    \"PR\": \"10\", \"H\": \"7\", \"R\": \"2\", \"BU\": \"5\", \"BG\": \"1\",\n",
    "}\n",
    "\n",
    "\n",
    "def tb_plan_to_gcal_events(plan: TBPlan) -> list[GCalEvent]:\n",
    "    \"\"\"\n",
    "    Resolve times and convert a TBPlan into GCalEvent objects\n",
    "    ready for the Google Calendar MCP `create-event` tool.\n",
    "    \"\"\"\n",
    "    resolved = plan.resolve_times()\n",
    "    tz = ZoneInfo(plan.tz)\n",
    "    gcal_events: list[GCalEvent] = []\n",
    "\n",
    "    for r in resolved:\n",
    "        start_dt = datetime.combine(plan.date, r[\"start_time\"], tzinfo=tz)\n",
    "        end_dt = datetime.combine(plan.date, r[\"end_time\"], tzinfo=tz)\n",
    "\n",
    "        gcal_events.append(\n",
    "            GCalEvent.model_construct(\n",
    "                id=\"\",  # will be assigned by Google Calendar\n",
    "                summary=r[\"n\"],\n",
    "                start=GCalEventDateTime(\n",
    "                    date_time=start_dt.isoformat(),\n",
    "                    time_zone=plan.tz,\n",
    "                ),\n",
    "                end=GCalEventDateTime(\n",
    "                    date_time=end_dt.isoformat(),\n",
    "                    time_zone=plan.tz,\n",
    "                ),\n",
    "                status=\"confirmed\",\n",
    "                # colorId is passed separately via the MCP tool call\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return gcal_events\n",
    "\n",
    "\n",
    "# ── Test the full pipeline ────────────────────────────────────────────────\n",
    "\n",
    "# 1) Build a sample plan using compact aliases\n",
    "sample_plan = TBPlan(\n",
    "    date=date_type(2026, 2, 7),\n",
    "    tz=\"Europe/Amsterdam\",\n",
    "    events=[\n",
    "        TBEvent(n=\"Morning routine\", d=\"Shower, coffee\", t=ET.H,\n",
    "                p=FixedStart(st=time(7, 0), dur=timedelta(minutes=30))),\n",
    "        TBEvent(n=\"Deep work: thesis\", d=\"Chapter 3 draft\", t=ET.DW,\n",
    "                p=AfterPrev(dur=timedelta(hours=2))),\n",
    "        TBEvent(n=\"Coffee break\", d=\"\", t=ET.BU,\n",
    "                p=AfterPrev(dur=timedelta(minutes=15))),\n",
    "        TBEvent(n=\"Standup\", d=\"Team sync\", t=ET.M,\n",
    "                p=FixedWindow(st=time(10, 0), et=time(10, 15))),\n",
    "        TBEvent(n=\"Deep work: thesis\", d=\"Polish + references\", t=ET.DW,\n",
    "                p=AfterPrev(dur=timedelta(hours=1, minutes=30))),\n",
    "        TBEvent(n=\"Lunch\", d=\"\", t=ET.R,\n",
    "                p=AfterPrev(dur=timedelta(minutes=45))),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 2) Resolve times\n",
    "resolved = sample_plan.resolve_times()\n",
    "print(\"=== Resolved schedule ===\")\n",
    "for r in resolved:\n",
    "    print(f\"  {r['start_time'].strftime('%H:%M')}–{r['end_time'].strftime('%H:%M')}  {r['n']} ({r['t']})\")\n",
    "\n",
    "# 3) Convert to GCalEvent\n",
    "gcal_events = tb_plan_to_gcal_events(sample_plan)\n",
    "print(f\"\\n=== {len(gcal_events)} GCalEvent objects ready for MCP ===\")\n",
    "for ge in gcal_events:\n",
    "    print(f\"  {ge.summary}: {ge.start.date_time} → {ge.end.date_time}\")\n",
    "\n",
    "# 4) Show token savings: what the LLM actually generates\n",
    "raw_json = sample_plan.model_dump_json(indent=2)\n",
    "print(f\"\\n=== TBPlan JSON size: {len(raw_json)} chars ===\")\n",
    "print(raw_json[:500], \"...\" if len(raw_json) > 500 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffae1718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Patched schedule ===\n",
      "  07:00–07:30  Morning routine (H)\n",
      "  07:30–09:30  Deep work: thesis (DW)\n",
      "  09:30–09:45  Coffee break (BU)\n",
      "  09:45–10:00  Standup (M)\n",
      "  10:00–12:00  Deep work: thesis (DW)\n",
      "  12:00–13:00  Gym (H)\n",
      "  13:00–13:45  Lunch (R)\n",
      "\n",
      "=== Patch JSON (279 chars) ===\n",
      "{\n",
      "  \"ops\": [\n",
      "    {\n",
      "      \"op\": \"ue\",\n",
      "      \"i\": 3,\n",
      "      \"n\": null,\n",
      "      \"d\": null,\n",
      "      \"t\": null,\n",
      "      \"p\": {\n",
      "        \"a\": \"fw\",\n",
      "        \"st\": \"09:45:00\",\n",
      "        \"et\": \"10:00:00\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"op\": \"ue\",\n",
      "      \"i\": 4,\n",
      "      \"n\": null,\n",
      "      \"d\": null,\n",
      "      \"t\": null,\n",
      "      \"p\": {\n",
      "        \"a\": \"ap\",\n",
      "        \"dur\": \"PT2H\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"op\": \"ae\",\n",
      "      \"events\": [\n",
      "        {\n",
      "          \"n\": \"Gym\",\n",
      "          \"d\": \"Strength training\",\n",
      "          \"t\": \"H\",\n",
      "          \"p\": {\n",
      "            \"a\": \"ap\",\n",
      "            \"dur\": \"PT1H\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"after\": 4\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test domain ops: patch the sample plan with realistic user requests.\"\"\"\n",
    "\n",
    "# Scenario: \"Move the standup earlier, extend deep work, add gym before lunch\"\n",
    "patch = TBPatch(ops=[\n",
    "    # Update standup to 09:45-10:00\n",
    "    UpdateEvent(i=3, p=FixedWindow(st=time(9, 45), et=time(10, 0))),\n",
    "    # Extend second deep work to 2 hours\n",
    "    UpdateEvent(i=4, p=AfterPrev(dur=timedelta(hours=2))),\n",
    "    # Add gym before lunch\n",
    "    AddEvents(\n",
    "        after=4,\n",
    "        events=[TBEvent(n=\"Gym\", d=\"Strength training\", t=ET.H,\n",
    "                        p=AfterPrev(dur=timedelta(hours=1)))],\n",
    "    ),\n",
    "])\n",
    "\n",
    "patched = apply_tb_ops(sample_plan, patch)\n",
    "resolved_patched = patched.resolve_times()\n",
    "\n",
    "print(\"=== Patched schedule ===\")\n",
    "for r in resolved_patched:\n",
    "    print(f\"  {r['start_time'].strftime('%H:%M')}–{r['end_time'].strftime('%H:%M')}  {r['n']} ({r['t']})\")\n",
    "\n",
    "# Show the patch JSON (what LLM would output)\n",
    "print(f\"\\n=== Patch JSON ({len(patch.model_dump_json())} chars) ===\")\n",
    "print(patch.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c7d1b",
   "metadata": {},
   "source": [
    "# End-to-End Pipeline: GCal MCP → TBPlan → Patch → Submit\n",
    "\n",
    "## Flow\n",
    "```\n",
    "GCal MCP list-events → GCalEventsResponse → TBPlan (immovables as fw)\n",
    "    ↓\n",
    "LLM generates TBPatch (domain ops) against TBPlan\n",
    "    ↓\n",
    "apply_tb_ops → patched TBPlan\n",
    "    ↓\n",
    "resolve_times() → concrete start/end for every event\n",
    "    ↓\n",
    "tb_plan_to_gcal_create_args() → list of MCP create-event argument dicts\n",
    "    ↓\n",
    "diff with original → create/update/delete ops\n",
    "    ↓\n",
    "BatchCalendarSubmitter.apply() via MCP\n",
    "```\n",
    "\n",
    "## Key mappings\n",
    "| GCal MCP field | TBPlan field | Direction |\n",
    "|---|---|---|\n",
    "| `summary` | `TBEvent.n` | both ways |\n",
    "| `description` | `TBEvent.d` | both ways |\n",
    "| `start.dateTime` | resolved `start_time` | receive → `fw`; submit → ISO8601 |\n",
    "| `end.dateTime` | resolved `end_time` | receive → `fw`; submit → ISO8601 |\n",
    "| `colorId` | `_ET_COLOR_MAP[TBEvent.t]` | submit only |\n",
    "| `id` / `eventId` | tracked for diff | receive + submit |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b912535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline loaded: gcal_response_to_tb_plan, tb_plan_to_mcp_ops, diff_tb_plans, TBSubmitter\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 1: GCal MCP → TBPlan\n",
    "    Fetch events from Google Calendar via MCP and convert to our lightweight TBPlan.\n",
    "    Existing calendar events become fixed-window (fw) anchors.\n",
    "\n",
    "Step 2: TBPlan → GCal MCP create-event args\n",
    "    Convert resolved TBPlan events back into the exact dict shape\n",
    "    that the MCP `create-event` / `update-event` tools expect.\n",
    "\"\"\"\n",
    "\n",
    "import base64\n",
    "import hashlib\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from autogen_ext.tools.mcp import McpWorkbench, StreamableHttpServerParams\n",
    "from dateutil import parser as date_parser\n",
    "from fateforger.adapters.calendar.models import GCalEventsResponse\n",
    "from fateforger.core.config import settings\n",
    "\n",
    "\n",
    "# ── GCal MCP → TBPlan ────────────────────────────────────────────────────\n",
    "\n",
    "def _gcal_color_to_et(color_id: str | None) -> ET:\n",
    "    \"\"\"Best-effort reverse mapping: GCal colorId → ET code.\"\"\"\n",
    "    _reverse = {v: k for k, v in _ET_COLOR_MAP.items()}\n",
    "    if color_id and color_id in _reverse:\n",
    "        return ET(_reverse[color_id])\n",
    "    return ET.M  # default: treat unknown calendar events as meetings\n",
    "\n",
    "\n",
    "def gcal_response_to_tb_plan(\n",
    "    resp: GCalEventsResponse,\n",
    "    *,\n",
    "    plan_date: date_type,\n",
    "    tz_name: str = \"Europe/Amsterdam\",\n",
    ") -> TBPlan:\n",
    "    \"\"\"\n",
    "    Convert a GCalEventsResponse (from MCP list-events) into a TBPlan.\n",
    "    \n",
    "    All existing calendar events become FixedWindow anchors since\n",
    "    they already have concrete start/end times.\n",
    "    \"\"\"\n",
    "    tz = ZoneInfo(tz_name)\n",
    "    events: list[TBEvent] = []\n",
    "\n",
    "    for ge in resp.events:\n",
    "        # Skip all-day events (no dateTime)\n",
    "        if not ge.start.date_time or not ge.end.date_time:\n",
    "            continue\n",
    "        \n",
    "        # Skip cancelled\n",
    "        if ge.status and ge.status.lower() == \"cancelled\":\n",
    "            continue\n",
    "\n",
    "        start_dt = date_parser.isoparse(ge.start.date_time).astimezone(tz)\n",
    "        end_dt = date_parser.isoparse(ge.end.date_time).astimezone(tz)\n",
    "\n",
    "        # Skip events not on our planning date\n",
    "        if start_dt.date() != plan_date:\n",
    "            continue\n",
    "\n",
    "        # Detect event type from colorId if available\n",
    "        et = _gcal_color_to_et(getattr(ge, \"colorId\", None) or getattr(ge, \"color_id\", None))\n",
    "\n",
    "        events.append(TBEvent(\n",
    "            n=ge.summary or \"Busy\",\n",
    "            d=\"\",  # GCal description is often long HTML; skip for generation context\n",
    "            t=et,\n",
    "            p=FixedWindow(st=start_dt.time(), et=end_dt.time()),\n",
    "        ))\n",
    "\n",
    "    # Sort by start time\n",
    "    events.sort(key=lambda e: e.p.st if hasattr(e.p, \"st\") else time(0, 0))\n",
    "\n",
    "    return TBPlan(events=events, date=plan_date, tz=tz_name)\n",
    "\n",
    "\n",
    "# ── TBPlan → MCP create-event args ───────────────────────────────────────\n",
    "\n",
    "def _base32hex_id(seed: str, *, prefix: str = \"fftb\", max_len: int = 64) -> str:\n",
    "    \"\"\"Deterministic event ID for owned timebox events.\n",
    "    \n",
    "    GCal event IDs must only contain lowercase a-v and 0-9 (base32hex).\n",
    "    \"\"\"\n",
    "    digest = hashlib.sha1(seed.encode(\"utf-8\")).digest()\n",
    "    token = base64.b32hexencode(digest).decode(\"ascii\").lower().rstrip(\"=\")\n",
    "    return (prefix + token)[:max_len]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MCPCalendarOp:\n",
    "    \"\"\"A single MCP calendar operation (create / update / delete).\"\"\"\n",
    "    tool_name: str  # \"create-event\" | \"update-event\" | \"delete-event\"\n",
    "    arguments: dict\n",
    "\n",
    "\n",
    "def tb_plan_to_mcp_ops(\n",
    "    plan: TBPlan,\n",
    "    *,\n",
    "    original_event_ids: dict[int, str] | None = None,\n",
    "    calendar_id: str = \"primary\",\n",
    ") -> list[MCPCalendarOp]:\n",
    "    \"\"\"\n",
    "    Convert a resolved TBPlan into MCP tool call arguments.\n",
    "    \n",
    "    Args:\n",
    "        plan: The TBPlan with events to submit.\n",
    "        original_event_ids: {event_index: gcal_event_id} for events that\n",
    "            already exist in GCal (so we can update instead of create).\n",
    "        calendar_id: Target calendar.\n",
    "    \n",
    "    Returns:\n",
    "        List of MCPCalendarOp with tool_name + arguments dicts.\n",
    "    \"\"\"\n",
    "    resolved = plan.resolve_times()\n",
    "    tz = ZoneInfo(plan.tz)\n",
    "    original_event_ids = original_event_ids or {}\n",
    "    ops: list[MCPCalendarOp] = []\n",
    "\n",
    "    for r in resolved:\n",
    "        idx = r[\"index\"]\n",
    "        start_dt = datetime.combine(plan.date, r[\"start_time\"], tzinfo=tz)\n",
    "        end_dt = datetime.combine(plan.date, r[\"end_time\"], tzinfo=tz)\n",
    "        color_id = _ET_COLOR_MAP.get(r[\"t\"], \"0\")\n",
    "\n",
    "        args = {\n",
    "            \"calendarId\": calendar_id,\n",
    "            \"summary\": r[\"n\"],\n",
    "            \"description\": r[\"d\"] or \"\",\n",
    "            \"start\": start_dt.isoformat(),\n",
    "            \"end\": end_dt.isoformat(),\n",
    "            \"timeZone\": plan.tz,\n",
    "            \"colorId\": color_id,\n",
    "        }\n",
    "\n",
    "        if idx in original_event_ids:\n",
    "            # This event already exists in GCal → update\n",
    "            args[\"eventId\"] = original_event_ids[idx]\n",
    "            ops.append(MCPCalendarOp(tool_name=\"update-event\", arguments=args))\n",
    "        else:\n",
    "            # New event → create with deterministic ID\n",
    "            seed = f\"{plan.date}|{r['n']}|{r['start_time']}|{idx}\"\n",
    "            args[\"eventId\"] = _base32hex_id(seed)\n",
    "            ops.append(MCPCalendarOp(tool_name=\"create-event\", arguments=args))\n",
    "\n",
    "    return ops\n",
    "\n",
    "\n",
    "def diff_tb_plans(\n",
    "    before: TBPlan,\n",
    "    after: TBPlan,\n",
    "    *,\n",
    "    event_id_map: dict[int, str],\n",
    "    calendar_id: str = \"primary\",\n",
    ") -> list[MCPCalendarOp]:\n",
    "    \"\"\"\n",
    "    Diff two TBPlans and return the minimal set of MCP ops.\n",
    "    \n",
    "    Args:\n",
    "        before: Original plan (from GCal).\n",
    "        after: Patched plan.\n",
    "        event_id_map: {before_index: gcal_event_id} for events in `before`.\n",
    "        calendar_id: Target calendar.\n",
    "    \n",
    "    Returns:\n",
    "        create/update/delete MCPCalendarOps.\n",
    "    \"\"\"\n",
    "    before_resolved = {r[\"index\"]: r for r in before.resolve_times()}\n",
    "    after_resolved = after.resolve_times()\n",
    "    tz = ZoneInfo(after.tz)\n",
    "    ops: list[MCPCalendarOp] = []\n",
    "\n",
    "    after_indices = set()\n",
    "\n",
    "    for r in after_resolved:\n",
    "        idx = r[\"index\"]\n",
    "        after_indices.add(idx)\n",
    "        start_dt = datetime.combine(after.date, r[\"start_time\"], tzinfo=tz)\n",
    "        end_dt = datetime.combine(after.date, r[\"end_time\"], tzinfo=tz)\n",
    "        color_id = _ET_COLOR_MAP.get(r[\"t\"], \"0\")\n",
    "\n",
    "        args = {\n",
    "            \"calendarId\": calendar_id,\n",
    "            \"summary\": r[\"n\"],\n",
    "            \"description\": r[\"d\"] or \"\",\n",
    "            \"start\": start_dt.isoformat(),\n",
    "            \"end\": end_dt.isoformat(),\n",
    "            \"timeZone\": after.tz,\n",
    "            \"colorId\": color_id,\n",
    "        }\n",
    "\n",
    "        if idx in event_id_map:\n",
    "            # Check if actually changed\n",
    "            old = before_resolved.get(idx)\n",
    "            if old and (old[\"n\"] != r[\"n\"] or old[\"start_time\"] != r[\"start_time\"]\n",
    "                        or old[\"end_time\"] != r[\"end_time\"] or old.get(\"d\") != r.get(\"d\")):\n",
    "                args[\"eventId\"] = event_id_map[idx]\n",
    "                ops.append(MCPCalendarOp(tool_name=\"update-event\", arguments=args))\n",
    "        else:\n",
    "            seed = f\"{after.date}|{r['n']}|{r['start_time']}|{idx}\"\n",
    "            args[\"eventId\"] = _base32hex_id(seed)\n",
    "            ops.append(MCPCalendarOp(tool_name=\"create-event\", arguments=args))\n",
    "\n",
    "    # Deletes: events in before that are not in after\n",
    "    for before_idx, gcal_id in event_id_map.items():\n",
    "        if before_idx not in after_indices:\n",
    "            ops.append(MCPCalendarOp(\n",
    "                tool_name=\"delete-event\",\n",
    "                arguments={\"calendarId\": calendar_id, \"eventId\": gcal_id},\n",
    "            ))\n",
    "\n",
    "    return ops\n",
    "\n",
    "\n",
    "# ── MCP Batch Submitter ──────────────────────────────────────────────────\n",
    "\n",
    "class TBSubmitter:\n",
    "    \"\"\"Submit TBPlan operations to Google Calendar via MCP.\"\"\"\n",
    "\n",
    "    def __init__(self, *, server_url: str | None = None, timeout_s: float = 10.0):\n",
    "        url = server_url or settings.mcp_calendar_server_url\n",
    "        self._workbench = McpWorkbench(\n",
    "            StreamableHttpServerParams(url=url, timeout=timeout_s)\n",
    "        )\n",
    "\n",
    "    async def apply_ops(self, ops: list[MCPCalendarOp]) -> list[dict]:\n",
    "        \"\"\"Execute MCP ops sequentially and return results.\"\"\"\n",
    "        results = []\n",
    "        for op in ops:\n",
    "            result = await self._workbench.call_tool(op.tool_name, arguments=op.arguments)\n",
    "            results.append({\n",
    "                \"tool\": op.tool_name,\n",
    "                \"event_id\": op.arguments.get(\"eventId\"),\n",
    "                \"summary\": op.arguments.get(\"summary\"),\n",
    "                \"ok\": not getattr(result, \"is_error\", False),\n",
    "                \"content\": getattr(result, \"content\", str(result)),\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    async def submit_plan(\n",
    "        self,\n",
    "        plan: TBPlan,\n",
    "        *,\n",
    "        original_event_ids: dict[int, str] | None = None,\n",
    "        calendar_id: str = \"primary\",\n",
    "    ) -> list[dict]:\n",
    "        \"\"\"Resolve times, build ops, and submit to GCal.\"\"\"\n",
    "        ops = tb_plan_to_mcp_ops(\n",
    "            plan,\n",
    "            original_event_ids=original_event_ids,\n",
    "            calendar_id=calendar_id,\n",
    "        )\n",
    "        return await self.apply_ops(ops)\n",
    "\n",
    "\n",
    "print(\"Pipeline loaded: gcal_response_to_tb_plan, tb_plan_to_mcp_ops, diff_tb_plans, TBSubmitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bcef02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline from GCal (immovables) ===\n",
      "  [0] Team standup (M) — a='fw' st=datetime.time(10, 0) et=datetime.time(10, 15)\n",
      "  [1] Lunch with Sarah (M) — a='fw' st=datetime.time(12, 30) et=datetime.time(13, 30)\n",
      "\n",
      "GCal IDs: {'Team standup': 'abc123', 'Lunch with Sarah': 'def456'}\n",
      "\n",
      "=== Patched schedule ===\n",
      "  07:00–07:30  Morning routine (H)\n",
      "  07:30–09:30  Deep work: thesis (DW)\n",
      "  09:30–09:45  Coffee break (BU)\n",
      "  10:00–10:15  Team standup (M)\n",
      "  10:15–11:45  Deep work: thesis (DW)\n",
      "  12:30–13:30  Lunch with Sarah (M)\n",
      "  13:30–14:15  Shallow work (SW)\n",
      "  14:15–15:15  Gym (H)\n",
      "\n",
      "Matched GCal IDs: {3: 'abc123', 5: 'def456'}\n",
      "\n",
      "=== 8 MCP operations ===\n",
      "  CREATE   Morning routine           id=fftb_j73av1ltk1pmge3  start=2026-02-08T07:00:00+01:00\n",
      "  CREATE   Deep work: thesis         id=fftb_9uqg08rcpmb55r1  start=2026-02-08T07:30:00+01:00\n",
      "  CREATE   Coffee break              id=fftb_02itvpp3vo75aop  start=2026-02-08T09:30:00+01:00\n",
      "  UPDATE   Team standup              id=abc123  start=2026-02-08T10:00:00+01:00\n",
      "  CREATE   Deep work: thesis         id=fftb_kvug84ktjujusju  start=2026-02-08T10:15:00+01:00\n",
      "  UPDATE   Lunch with Sarah          id=def456  start=2026-02-08T12:30:00+01:00\n",
      "  CREATE   Shallow work              id=fftb_tpkk1h2ul6o22su  start=2026-02-08T13:30:00+01:00\n",
      "  CREATE   Gym                       id=fftb_k7r8ugnhkhvmngt  start=2026-02-08T14:15:00+01:00\n",
      "\n",
      "=== LLM output size: 666 chars ===\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Full pipeline test (offline — no MCP server needed).\n",
    "Uses simulated GCal events + LLM-generated plan, then shows MCP ops.\n",
    "\"\"\"\n",
    "\n",
    "# ── Simulate: pretend these 2 events came from GCal list-events ──────────\n",
    "from fateforger.adapters.calendar.models import GCalEventsResponse, GCalEvent, GCalEventDateTime\n",
    "\n",
    "fake_gcal_response = GCalEventsResponse(\n",
    "    events=[\n",
    "        GCalEvent(\n",
    "            id=\"abc123\",\n",
    "            summary=\"Team standup\",\n",
    "            start=GCalEventDateTime(dateTime=\"2026-02-08T10:00:00+01:00\", timeZone=\"Europe/Amsterdam\"),\n",
    "            end=GCalEventDateTime(dateTime=\"2026-02-08T10:15:00+01:00\", timeZone=\"Europe/Amsterdam\"),\n",
    "            status=\"confirmed\",\n",
    "        ),\n",
    "        GCalEvent(\n",
    "            id=\"def456\",\n",
    "            summary=\"Lunch with Sarah\",\n",
    "            start=GCalEventDateTime(dateTime=\"2026-02-08T12:30:00+01:00\", timeZone=\"Europe/Amsterdam\"),\n",
    "            end=GCalEventDateTime(dateTime=\"2026-02-08T13:30:00+01:00\", timeZone=\"Europe/Amsterdam\"),\n",
    "            status=\"confirmed\",\n",
    "        ),\n",
    "    ],\n",
    "    totalCount=2,\n",
    ")\n",
    "\n",
    "plan_date = date_type(2026, 2, 8)\n",
    "\n",
    "# ── Step 1: GCal → TBPlan (immovables as fixed windows) ──────────────────\n",
    "baseline = gcal_response_to_tb_plan(fake_gcal_response, plan_date=plan_date)\n",
    "print(\"=== Baseline from GCal (immovables) ===\")\n",
    "for i, ev in enumerate(baseline.events):\n",
    "    print(f\"  [{i}] {ev.n} ({ev.t.value}) — {ev.p}\")\n",
    "\n",
    "# Track which GCal event IDs map to summaries (for after-patching lookup)\n",
    "gcal_id_by_summary = {ge.summary: ge.id for ge in fake_gcal_response.events}\n",
    "print(f\"\\nGCal IDs: {gcal_id_by_summary}\")\n",
    "\n",
    "# ── Step 2: LLM generates full plan via replace_all ──────────────────────\n",
    "#  Initial generation = ReplaceAll: the LLM builds the whole day,\n",
    "#  keeping immovables as FixedWindow and filling gaps with new events.\n",
    "llm_patch = TBPatch(ops=[\n",
    "    ReplaceAll(events=[\n",
    "        # Morning block\n",
    "        TBEvent(n=\"Morning routine\", d=\"Shower + coffee\", t=ET.H,\n",
    "                p=FixedStart(st=time(7, 0), dur=timedelta(minutes=30))),\n",
    "        TBEvent(n=\"Deep work: thesis\", d=\"Chapter 3\", t=ET.DW,\n",
    "                p=AfterPrev(dur=timedelta(hours=2))),\n",
    "        TBEvent(n=\"Coffee break\", d=\"\", t=ET.BU,\n",
    "                p=AfterPrev(dur=timedelta(minutes=15))),\n",
    "        # Immovable: standup (LLM preserves it as-is)\n",
    "        TBEvent(n=\"Team standup\", d=\"\", t=ET.M,\n",
    "                p=FixedWindow(st=time(10, 0), et=time(10, 15))),\n",
    "        # Fill gap after standup\n",
    "        TBEvent(n=\"Deep work: thesis\", d=\"Polish draft\", t=ET.DW,\n",
    "                p=AfterPrev(dur=timedelta(hours=1, minutes=30))),\n",
    "        # Immovable: lunch (LLM preserves it as-is)\n",
    "        TBEvent(n=\"Lunch with Sarah\", d=\"\", t=ET.M,\n",
    "                p=FixedWindow(st=time(12, 30), et=time(13, 30))),\n",
    "        # Afternoon\n",
    "        TBEvent(n=\"Shallow work\", d=\"Emails + admin\", t=ET.SW,\n",
    "                p=AfterPrev(dur=timedelta(minutes=45))),\n",
    "        TBEvent(n=\"Gym\", d=\"\", t=ET.H,\n",
    "                p=AfterPrev(dur=timedelta(hours=1))),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "# ── Step 3: Apply patch ──────────────────────────────────────────────────\n",
    "patched_plan = apply_tb_ops(baseline, llm_patch)\n",
    "resolved = patched_plan.resolve_times()\n",
    "\n",
    "print(\"\\n=== Patched schedule ===\")\n",
    "for r in resolved:\n",
    "    print(f\"  {r['start_time'].strftime('%H:%M')}–{r['end_time'].strftime('%H:%M')}  {r['n']} ({r['t']})\")\n",
    "\n",
    "# ── Step 4: Map GCal IDs to patched indices ──────────────────────────────\n",
    "# Match by summary to find which patched events are existing GCal events\n",
    "original_event_ids: dict[int, str] = {}\n",
    "for r in resolved:\n",
    "    if r[\"n\"] in gcal_id_by_summary:\n",
    "        original_event_ids[r[\"index\"]] = gcal_id_by_summary[r[\"n\"]]\n",
    "print(f\"\\nMatched GCal IDs: {original_event_ids}\")\n",
    "\n",
    "# ── Step 5: Generate MCP ops ─────────────────────────────────────────────\n",
    "ops = tb_plan_to_mcp_ops(\n",
    "    patched_plan,\n",
    "    original_event_ids=original_event_ids,\n",
    "    calendar_id=\"primary\",\n",
    ")\n",
    "\n",
    "print(f\"\\n=== {len(ops)} MCP operations ===\")\n",
    "for op in ops:\n",
    "    verb = op.tool_name.replace(\"-event\", \"\").upper()\n",
    "    summary = op.arguments.get(\"summary\", \"\")\n",
    "    eid = op.arguments.get(\"eventId\", \"\")[:20]\n",
    "    start = op.arguments.get(\"start\", \"\")\n",
    "    print(f\"  {verb:8s} {summary:25s} id={eid}  start={start}\")\n",
    "\n",
    "# ── Show what the LLM actually generated (token count) ───────────────────\n",
    "patch_json = llm_patch.model_dump_json()\n",
    "print(f\"\\n=== LLM output size: {len(patch_json)} chars ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c5d8c",
   "metadata": {},
   "source": [
    "## 🔴 Live MCP Pipeline Test\n",
    "\n",
    "**End-to-end**: GCal MCP `list-events` → `TBPlan` → patch → `create-event` / `update-event` back to GCal.\n",
    "\n",
    "Uses the real calendar MCP at `http://localhost:3000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95f1a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw JSON:\n",
      "{\"events\":[],\"totalCount\":0}\n",
      "\n",
      "✅ Parsed 0 events for 2026-02-08\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Live MCP test — Step 1: Fetch real events from GCal via MCP.\n",
    "\"\"\"\n",
    "import asyncio\n",
    "import json\n",
    "from datetime import date as date_type, datetime, time, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "from autogen_ext.tools.mcp import McpWorkbench, StreamableHttpServerParams\n",
    "from fateforger.adapters.calendar.models import GCalEventsResponse\n",
    "\n",
    "MCP_URL = \"http://localhost:3000\"\n",
    "TZ = \"Europe/Amsterdam\"\n",
    "\n",
    "# ── Use tomorrow so we can freely create/delete without messing up today ──\n",
    "plan_date = date_type(2026, 2, 8)\n",
    "\n",
    "async def fetch_events(target_date: date_type) -> str:\n",
    "    \"\"\"Fetch events from GCal MCP for a specific date, returns raw JSON string.\"\"\"\n",
    "    wb = McpWorkbench(StreamableHttpServerParams(url=MCP_URL, timeout=15))\n",
    "    async with wb:\n",
    "        result = await wb.call_tool(\n",
    "            \"list-events\",\n",
    "            arguments={\n",
    "                \"calendarId\": \"primary\",\n",
    "                \"timeMin\": datetime.combine(target_date, time(0, 0), tzinfo=ZoneInfo(TZ)).isoformat(),\n",
    "                \"timeMax\": datetime.combine(target_date + timedelta(days=1), time(0, 0), tzinfo=ZoneInfo(TZ)).isoformat(),\n",
    "            },\n",
    "        )\n",
    "    # ToolResult → .result is a list of TextResultContent\n",
    "    for part in result.result:\n",
    "        if hasattr(part, \"content\") and isinstance(part.content, str):\n",
    "            return part.content\n",
    "    raise ValueError(f\"No text content in MCP response: {result}\")\n",
    "\n",
    "raw_json = await fetch_events(plan_date)\n",
    "print(f\"Raw JSON:\\n{raw_json[:500]}\")\n",
    "\n",
    "# Parse into our model\n",
    "gcal_resp = GCalEventsResponse.model_validate_json(raw_json)\n",
    "print(f\"\\n✅ Parsed {len(gcal_resp.events)} events for {plan_date}\")\n",
    "for ge in gcal_resp.events:\n",
    "    start = ge.start.date_time or ge.start.date\n",
    "    print(f\"  • {ge.summary or '(no title)'} — {start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f3ab591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0 events\n",
      "\n",
      "=== Patched schedule (6 events) ===\n",
      "  07:00–07:30  Morning routine (H)\n",
      "  07:30–09:30  Deep work: thesis (DW)\n",
      "  09:30–09:45  Coffee break (BU)\n",
      "  09:45–10:30  Shallow work: emails (SW)\n",
      "  10:30–11:30  Lunch (BU)\n",
      "  11:30–13:00  Deep work: thesis (DW)\n",
      "\n",
      "=== 6 MCP operations ===\n",
      "  CREATE   Morning routine                2026-02-08T07:00:00+01:00\n",
      "  CREATE   Deep work: thesis              2026-02-08T07:30:00+01:00\n",
      "  CREATE   Coffee break                   2026-02-08T09:30:00+01:00\n",
      "  CREATE   Shallow work: emails           2026-02-08T09:45:00+01:00\n",
      "  CREATE   Lunch                          2026-02-08T10:30:00+01:00\n",
      "  CREATE   Deep work: thesis              2026-02-08T11:30:00+01:00\n",
      "\n",
      "⏳ Submitting to GCal...\n",
      "\n",
      "✅ 6/6 operations succeeded\n",
      "  ✅ create-event    Morning routine               \n",
      "  ✅ create-event    Deep work: thesis             \n",
      "  ✅ create-event    Coffee break                  \n",
      "  ✅ create-event    Shallow work: emails          \n",
      "  ✅ create-event    Lunch                         \n",
      "  ✅ create-event    Deep work: thesis             \n",
      "\n",
      "⏳ Verifying: re-fetching events from GCal...\n",
      "\n",
      "✅ Verification: 6 events on 2026-02-08\n",
      "  • Morning routine — 2026-02-08T07:00:00+01:00\n",
      "  • Deep work: thesis — 2026-02-08T07:30:00+01:00\n",
      "  • Coffee break — 2026-02-08T09:30:00+01:00\n",
      "  • Shallow work: emails — 2026-02-08T09:45:00+01:00\n",
      "  • Lunch — 2026-02-08T10:30:00+01:00\n",
      "  • Deep work: thesis — 2026-02-08T11:30:00+01:00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Live MCP test — Step 2: Full pipeline\n",
    "  Create a TBPlan → generate MCP ops → submit to GCal → verify.\n",
    "\"\"\"\n",
    "\n",
    "# ── 1. Start from whatever GCal returned (0 events = empty baseline) ─────\n",
    "baseline = gcal_response_to_tb_plan(gcal_resp, plan_date=plan_date, tz_name=TZ)\n",
    "print(f\"Baseline: {len(baseline.events)} events\")\n",
    "\n",
    "# ── 2. Simulate LLM output: a full day plan via ReplaceAll ───────────────\n",
    "llm_patch = TBPatch(ops=[\n",
    "    ReplaceAll(events=[\n",
    "        TBEvent(n=\"Morning routine\", d=\"Shower + coffee\", t=ET.H,\n",
    "                p=FixedStart(st=time(7, 0), dur=timedelta(minutes=30))),\n",
    "        TBEvent(n=\"Deep work: thesis\", d=\"Chapter 3 draft\", t=ET.DW,\n",
    "                p=AfterPrev(dur=timedelta(hours=2))),\n",
    "        TBEvent(n=\"Coffee break\", d=\"\", t=ET.BU,\n",
    "                p=AfterPrev(dur=timedelta(minutes=15))),\n",
    "        TBEvent(n=\"Shallow work: emails\", d=\"Inbox zero\", t=ET.SW,\n",
    "                p=AfterPrev(dur=timedelta(minutes=45))),\n",
    "        TBEvent(n=\"Lunch\", d=\"\", t=ET.BU,\n",
    "                p=AfterPrev(dur=timedelta(hours=1))),\n",
    "        TBEvent(n=\"Deep work: thesis\", d=\"Revisions\", t=ET.DW,\n",
    "                p=AfterPrev(dur=timedelta(hours=1, minutes=30))),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "# Apply patch\n",
    "patched = apply_tb_ops(baseline, llm_patch)\n",
    "resolved = patched.resolve_times()\n",
    "\n",
    "print(f\"\\n=== Patched schedule ({len(resolved)} events) ===\")\n",
    "for r in resolved:\n",
    "    print(f\"  {r['start_time'].strftime('%H:%M')}–{r['end_time'].strftime('%H:%M')}  {r['n']} ({r['t']})\")\n",
    "\n",
    "# ── 3. Generate MCP ops (all creates since baseline was empty) ────────────\n",
    "ops = tb_plan_to_mcp_ops(patched, calendar_id=\"primary\")\n",
    "\n",
    "print(f\"\\n=== {len(ops)} MCP operations ===\")\n",
    "for op in ops:\n",
    "    verb = op.tool_name.replace(\"-event\", \"\").upper()\n",
    "    print(f\"  {verb:8s} {op.arguments.get('summary', ''):30s} {op.arguments.get('start', '')}\")\n",
    "\n",
    "# ── 4. Submit to GCal via MCP ────────────────────────────────────────────\n",
    "async def submit_ops(operations: list[MCPCalendarOp]) -> list[dict]:\n",
    "    wb = McpWorkbench(StreamableHttpServerParams(url=MCP_URL, timeout=15))\n",
    "    results = []\n",
    "    async with wb:\n",
    "        for op in operations:\n",
    "            try:\n",
    "                result = await wb.call_tool(op.tool_name, arguments=op.arguments)\n",
    "                is_err = getattr(result, \"is_error\", False)\n",
    "                # Extract text content from result\n",
    "                text = \"\"\n",
    "                for part in result.result:\n",
    "                    if hasattr(part, \"content\"):\n",
    "                        text = part.content\n",
    "                        break\n",
    "                results.append({\n",
    "                    \"tool\": op.tool_name,\n",
    "                    \"summary\": op.arguments.get(\"summary\", \"\"),\n",
    "                    \"ok\": not is_err,\n",
    "                    \"response\": text[:200] if text else str(result)[:200],\n",
    "                })\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"tool\": op.tool_name,\n",
    "                    \"summary\": op.arguments.get(\"summary\", \"\"),\n",
    "                    \"ok\": False,\n",
    "                    \"response\": str(e)[:200],\n",
    "                })\n",
    "    return results\n",
    "\n",
    "print(\"\\n⏳ Submitting to GCal...\")\n",
    "submit_results = await submit_ops(ops)\n",
    "\n",
    "ok_count = sum(1 for r in submit_results if r[\"ok\"])\n",
    "print(f\"\\n✅ {ok_count}/{len(submit_results)} operations succeeded\")\n",
    "for r in submit_results:\n",
    "    status = \"✅\" if r[\"ok\"] else \"❌\"\n",
    "    print(f\"  {status} {r['tool']:15s} {r['summary']:30s}\")\n",
    "    if not r[\"ok\"]:\n",
    "        print(f\"     Error: {r['response']}\")\n",
    "\n",
    "# ── 5. Verify: fetch events again ────────────────────────────────────────\n",
    "print(\"\\n⏳ Verifying: re-fetching events from GCal...\")\n",
    "verify_json = await fetch_events(plan_date)\n",
    "verify_resp = GCalEventsResponse.model_validate_json(verify_json)\n",
    "print(f\"\\n✅ Verification: {len(verify_resp.events)} events on {plan_date}\")\n",
    "for ge in verify_resp.events:\n",
    "    start = ge.start.date_time or ge.start.date\n",
    "    print(f\"  • {ge.summary or '(no title)'} — {start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1194673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Current GCal events: 6\n",
      "Event ID map (6 mapped):\n",
      "\n",
      "Before (6 events):\n",
      "  [0] Morning routine                (H) — a='fw' st=datetime.time(7, 0) et=datetime.time(7, 30)  gcal=fftbj73av1ltk1pmge3n\n",
      "  [1] Deep work: thesis              (DW) — a='fw' st=datetime.time(7, 30) et=datetime.time(9, 30)  gcal=fftb9uqg08rcpmb55r1n\n",
      "  [2] Coffee break                   (BU) — a='fw' st=datetime.time(9, 30) et=datetime.time(9, 45)  gcal=fftb02itvpp3vo75aopv\n",
      "  [3] Shallow work: emails           (SW) — a='fw' st=datetime.time(9, 45) et=datetime.time(10, 30)  gcal=fftbn6kbqh87gm2dt0li\n",
      "  [4] Lunch                          (BU) — a='fw' st=datetime.time(10, 30) et=datetime.time(11, 30)  gcal=fftbcsqf00rplk6rhe8t\n",
      "  [5] Deep work: thesis              (DW) — a='fw' st=datetime.time(11, 30) et=datetime.time(13, 0)  gcal=fftbrm3t6ovsloulqpg7\n",
      "\n",
      "After (6 events):\n",
      "  07:00–07:30  Morning routine (H)\n",
      "  07:30–09:30  Deep work: thesis (DW)\n",
      "  09:45–10:30  Admin + Slack (SW)\n",
      "  10:30–11:30  Lunch (BU)\n",
      "  11:30–13:00  Deep work: thesis (DW)\n",
      "  13:00–14:00  Gym session (H)\n",
      "\n",
      "=== 4 MCP diff operations ===\n",
      "  UPDATE   Admin + Slack                  id=fftb02itvpp3vo75aopv\n",
      "  UPDATE   Lunch                          id=fftbn6kbqh87gm2dt0li\n",
      "  UPDATE   Deep work: thesis              id=fftbcsqf00rplk6rhe8t\n",
      "  UPDATE   Gym session                    id=fftbrm3t6ovsloulqpg7\n",
      "\n",
      "⏳ Submitting diff to GCal...\n",
      "\n",
      "✅ 4/4 diff ops succeeded\n",
      "  ✅ update-event    Admin + Slack                 \n",
      "  ✅ update-event    Lunch                         \n",
      "  ✅ update-event    Deep work: thesis             \n",
      "  ✅ update-event    Gym session                   \n",
      "\n",
      "⏳ Final verification...\n",
      "\n",
      "✅ Final state: 6 events on 2026-02-08\n",
      "  • Morning routine — 2026-02-08T07:00:00+01:00\n",
      "  • Deep work: thesis — 2026-02-08T07:30:00+01:00\n",
      "  • Admin + Slack — 2026-02-08T09:45:00+01:00\n",
      "  • Lunch — 2026-02-08T10:30:00+01:00\n",
      "  • Deep work: thesis — 2026-02-08T11:30:00+01:00\n",
      "  • Gym session — 2026-02-08T13:00:00+01:00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Live MCP test — Step 3: Patch existing events (update + delete + create).\n",
    "Fetch back what we just created, apply edits, submit the diff.\n",
    "\"\"\"\n",
    "\n",
    "# ── 1. Fetch current events (the 6 we just created) ──────────────────────\n",
    "current_json = await fetch_events(plan_date)\n",
    "current_resp = GCalEventsResponse.model_validate_json(current_json)\n",
    "print(f\"📅 Current GCal events: {len(current_resp.events)}\")\n",
    "\n",
    "# Build baseline TBPlan from current GCal state\n",
    "before = gcal_response_to_tb_plan(current_resp, plan_date=plan_date, tz_name=TZ)\n",
    "\n",
    "# Build the GCal ID map: {tb_plan_index → gcal_event_id}\n",
    "# Match by summary+start to handle duplicate summaries\n",
    "gcal_id_lookup: dict[tuple[str, str], str] = {}\n",
    "for ge in current_resp.events:\n",
    "    if ge.start.date_time:\n",
    "        gcal_id_lookup[(ge.summary or \"\", ge.start.date_time)] = ge.id\n",
    "\n",
    "event_id_map: dict[int, str] = {}\n",
    "for i, ev in enumerate(before.events):\n",
    "    # before events are FixedWindow with concrete start\n",
    "    st = ev.p.st if hasattr(ev.p, \"st\") else None\n",
    "    if st:\n",
    "        start_dt = datetime.combine(plan_date, st, tzinfo=ZoneInfo(TZ))\n",
    "        key = (ev.n, start_dt.isoformat())\n",
    "        if key in gcal_id_lookup:\n",
    "            event_id_map[i] = gcal_id_lookup[key]\n",
    "\n",
    "print(f\"Event ID map ({len(event_id_map)} mapped):\")\n",
    "print(f\"\\nBefore ({len(before.events)} events):\")\n",
    "for i, ev in enumerate(before.events):\n",
    "    gcal_id = event_id_map.get(i, \"???\")[:20]\n",
    "    print(f\"  [{i}] {ev.n:30s} ({ev.t.value}) — {ev.p}  gcal={gcal_id}\")\n",
    "\n",
    "# ── 2. Apply edits: rename, remove coffee break, add gym ─────────────────\n",
    "# UpdateEvent uses: i (index), n/d/t/p (optional field updates)\n",
    "edit_patch = TBPatch(ops=[\n",
    "    # Rename \"Shallow work: emails\" → \"Admin + Slack\"\n",
    "    UpdateEvent(i=3, n=\"Admin + Slack\"),\n",
    "    # Remove the coffee break (index 2)\n",
    "    RemoveEvent(i=2),\n",
    "    # Add a gym session at the end\n",
    "    AddEvents(after=None, events=[\n",
    "        TBEvent(n=\"Gym session\", d=\"Legs day\", t=ET.H,\n",
    "                p=AfterPrev(dur=timedelta(hours=1))),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "after = apply_tb_ops(before, edit_patch)\n",
    "after_resolved = after.resolve_times()\n",
    "\n",
    "print(f\"\\nAfter ({len(after_resolved)} events):\")\n",
    "for r in after_resolved:\n",
    "    print(f\"  {r['start_time'].strftime('%H:%M')}–{r['end_time'].strftime('%H:%M')}  {r['n']} ({r['t']})\")\n",
    "\n",
    "# ── 3. Diff → minimal MCP ops ────────────────────────────────────────────\n",
    "diff_ops = diff_tb_plans(before, after, event_id_map=event_id_map)\n",
    "\n",
    "print(f\"\\n=== {len(diff_ops)} MCP diff operations ===\")\n",
    "for op in diff_ops:\n",
    "    verb = op.tool_name.replace(\"-event\", \"\").upper()\n",
    "    summary = op.arguments.get(\"summary\", \"—\")\n",
    "    eid = op.arguments.get(\"eventId\", \"\")[:20]\n",
    "    print(f\"  {verb:8s} {summary:30s} id={eid}\")\n",
    "\n",
    "# ── 4. Submit diff ───────────────────────────────────────────────────────\n",
    "print(\"\\n⏳ Submitting diff to GCal...\")\n",
    "diff_results = await submit_ops(diff_ops)\n",
    "\n",
    "ok_count = sum(1 for r in diff_results if r[\"ok\"])\n",
    "print(f\"\\n✅ {ok_count}/{len(diff_results)} diff ops succeeded\")\n",
    "for r in diff_results:\n",
    "    status = \"✅\" if r[\"ok\"] else \"❌\"\n",
    "    print(f\"  {status} {r['tool']:15s} {r['summary']:30s}\")\n",
    "    if not r[\"ok\"]:\n",
    "        print(f\"     Error: {r['response']}\")\n",
    "\n",
    "# ── 5. Final verification ────────────────────────────────────────────────\n",
    "print(\"\\n⏳ Final verification...\")\n",
    "final_json = await fetch_events(plan_date)\n",
    "final_resp = GCalEventsResponse.model_validate_json(final_json)\n",
    "print(f\"\\n✅ Final state: {len(final_resp.events)} events on {plan_date}\")\n",
    "for ge in final_resp.events:\n",
    "    start = ge.start.date_time or ge.start.date\n",
    "    print(f\"  • {ge.summary or '(no title)'} — {start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c98912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Current: 6 events\n",
      "  [0] Morning routine                gcal=fftbj73av1ltk1pmge3n\n",
      "  [1] Deep work: thesis              gcal=fftb9uqg08rcpmb55r1n\n",
      "  [2] Admin + Slack                  gcal=fftb02itvpp3vo75aopv\n",
      "  [3] Lunch                          gcal=fftbn6kbqh87gm2dt0li\n",
      "  [4] Deep work: thesis              gcal=fftbcsqf00rplk6rhe8t\n",
      "  [5] Gym session                    gcal=fftbrm3t6ovsloulqpg7\n",
      "\n",
      "After removal: 4 events\n",
      "  07:00–07:30  Morning routine\n",
      "  07:30–09:30  Deep work: thesis\n",
      "  09:45–10:30  Admin + Slack\n",
      "  10:30–11:30  Lunch\n",
      "\n",
      "=== 2 MCP diff ops ===\n",
      "  DELETE   —                              id=fftbcsqf00rplk6rhe8t\n",
      "  DELETE   —                              id=fftbrm3t6ovsloulqpg7\n",
      "\n",
      "⏳ Submitting deletes...\n",
      "  ✅ delete-event                                  \n",
      "  ✅ delete-event                                  \n",
      "\n",
      "✅ After delete: 4 events (was 6)\n",
      "  • Morning routine — 2026-02-08T07:00:00+01:00\n",
      "  • Deep work: thesis — 2026-02-08T07:30:00+01:00\n",
      "  • Admin + Slack — 2026-02-08T09:45:00+01:00\n",
      "  • Lunch — 2026-02-08T10:30:00+01:00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Live MCP test — Step 4: Test DELETE path.\n",
    "Remove 2 events and verify they're deleted from GCal.\n",
    "\"\"\"\n",
    "\n",
    "# ── 1. Fetch current state ───────────────────────────────────────────────\n",
    "current_json = await fetch_events(plan_date)\n",
    "current_resp = GCalEventsResponse.model_validate_json(current_json)\n",
    "print(f\"📅 Current: {len(current_resp.events)} events\")\n",
    "\n",
    "before = gcal_response_to_tb_plan(current_resp, plan_date=plan_date, tz_name=TZ)\n",
    "\n",
    "# Build event_id_map by summary+start\n",
    "gcal_id_lookup: dict[tuple[str, str], str] = {}\n",
    "for ge in current_resp.events:\n",
    "    if ge.start.date_time:\n",
    "        gcal_id_lookup[(ge.summary or \"\", ge.start.date_time)] = ge.id\n",
    "\n",
    "event_id_map: dict[int, str] = {}\n",
    "for i, ev in enumerate(before.events):\n",
    "    st = ev.p.st if hasattr(ev.p, \"st\") else None\n",
    "    if st:\n",
    "        start_dt = datetime.combine(plan_date, st, tzinfo=ZoneInfo(TZ))\n",
    "        key = (ev.n, start_dt.isoformat())\n",
    "        if key in gcal_id_lookup:\n",
    "            event_id_map[i] = gcal_id_lookup[key]\n",
    "\n",
    "for i, ev in enumerate(before.events):\n",
    "    gcal_id = event_id_map.get(i, \"???\")[:20]\n",
    "    print(f\"  [{i}] {ev.n:30s} gcal={gcal_id}\")\n",
    "\n",
    "# ── 2. Remove last 2 events ──────────────────────────────────────────────\n",
    "n_before = len(before.events)\n",
    "delete_patch = TBPatch(ops=[\n",
    "    RemoveEvent(i=n_before - 1),  # remove last\n",
    "    RemoveEvent(i=n_before - 2),  # remove second-to-last (after first removal, this is the new last)\n",
    "])\n",
    "\n",
    "after = apply_tb_ops(before, delete_patch)\n",
    "print(f\"\\nAfter removal: {len(after.events)} events\")\n",
    "for r in after.resolve_times():\n",
    "    print(f\"  {r['start_time'].strftime('%H:%M')}–{r['end_time'].strftime('%H:%M')}  {r['n']}\")\n",
    "\n",
    "# ── 3. Diff → should produce 2 DELETEs ───────────────────────────────────\n",
    "diff_ops = diff_tb_plans(before, after, event_id_map=event_id_map)\n",
    "print(f\"\\n=== {len(diff_ops)} MCP diff ops ===\")\n",
    "for op in diff_ops:\n",
    "    verb = op.tool_name.replace(\"-event\", \"\").upper()\n",
    "    summary = op.arguments.get(\"summary\", \"—\")\n",
    "    eid = op.arguments.get(\"eventId\", \"\")[:20]\n",
    "    print(f\"  {verb:8s} {summary:30s} id={eid}\")\n",
    "\n",
    "# ── 4. Submit ─────────────────────────────────────────────────────────────\n",
    "print(\"\\n⏳ Submitting deletes...\")\n",
    "del_results = await submit_ops(diff_ops)\n",
    "for r in del_results:\n",
    "    status = \"✅\" if r[\"ok\"] else \"❌\"\n",
    "    print(f\"  {status} {r['tool']:15s} {r['summary']:30s}\")\n",
    "    if not r[\"ok\"]:\n",
    "        print(f\"     Error: {r['response']}\")\n",
    "\n",
    "# ── 5. Verify ─────────────────────────────────────────────────────────────\n",
    "verify_json = await fetch_events(plan_date)\n",
    "verify_resp = GCalEventsResponse.model_validate_json(verify_json)\n",
    "print(f\"\\n✅ After delete: {len(verify_resp.events)} events (was {len(current_resp.events)})\")\n",
    "for ge in verify_resp.events:\n",
    "    start = ge.start.date_time or ge.start.date\n",
    "    print(f\"  • {ge.summary or '(no title)'} — {start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e914d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Cleaning up 4 events on 2026-02-08...\n",
      "✅ Deleted 4/4 events\n",
      "\n",
      "📅 2026-02-08: 0 events remaining\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cleanup: delete all remaining test events for plan_date.\n",
    "\"\"\"\n",
    "cleanup_json = await fetch_events(plan_date)\n",
    "cleanup_resp = GCalEventsResponse.model_validate_json(cleanup_json)\n",
    "print(f\"🧹 Cleaning up {len(cleanup_resp.events)} events on {plan_date}...\")\n",
    "\n",
    "cleanup_ops = [\n",
    "    MCPCalendarOp(\n",
    "        tool_name=\"delete-event\",\n",
    "        arguments={\"calendarId\": \"primary\", \"eventId\": ge.id},\n",
    "    )\n",
    "    for ge in cleanup_resp.events\n",
    "    if ge.id  # safety check\n",
    "]\n",
    "\n",
    "if cleanup_ops:\n",
    "    results = await submit_ops(cleanup_ops)\n",
    "    ok = sum(1 for r in results if r[\"ok\"])\n",
    "    print(f\"✅ Deleted {ok}/{len(cleanup_ops)} events\")\n",
    "    for r in results:\n",
    "        if not r[\"ok\"]:\n",
    "            print(f\"  ❌ {r['response']}\")\n",
    "else:\n",
    "    print(\"Nothing to clean up.\")\n",
    "\n",
    "# Verify empty\n",
    "verify_json = await fetch_events(plan_date)\n",
    "verify_resp = GCalEventsResponse.model_validate_json(verify_json)\n",
    "print(f\"\\n📅 {plan_date}: {len(verify_resp.events)} events remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46915a59",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'supports_population'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     17\u001b[39m initial_timebox_dict = initial_timebox.model_dump(\n\u001b[32m     18\u001b[39m     exclude={\u001b[33m'\u001b[39m\u001b[33mevents\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33m__all__\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33mcolorId\u001b[39m\u001b[33m'\u001b[39m}}}  \u001b[38;5;66;03m# Exclude colorId computed field\u001b[39;00m\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m model_client = build_autogen_chat_client(\u001b[33m\"\u001b[39m\u001b[33mtimebox_patcher\u001b[39m\u001b[33m\"\u001b[39m, model=model)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m timebox_patcher = \u001b[43mObjectPatcher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTimebox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_timebox_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema_by_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m timebox_instruction = (\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMove the deep work to start at 10:00 and add a 30-minute buffer before it.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m )\n\u001b[32m     33\u001b[39m timebox_result = \u001b[38;5;28;01mawait\u001b[39;00m timebox_patcher.run(timebox_instruction, max_attempts=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 198\u001b[39m, in \u001b[36mObjectPatcher.__init__\u001b[39m\u001b[34m(self, model_cls, model_client, schema_by_alias, initial_state, list_field)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28mself\u001b[39m.spec = ArtifactEditorToolSpec(model_cls)\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m._set_initial_state(initial_state)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[38;5;28mself\u001b[39m._initial_snapshot = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28mself\u001b[39m._last_patch: BaseModel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m._last_success: BaseModel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 252\u001b[39m, in \u001b[36mObjectPatcher._artifact\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_artifact\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_current_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m {\u001b[38;5;28mself\u001b[39m.list_field: []}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VScode-projects/admonish-1/.venv/lib/python3.11/site-packages/llama_index/tools/artifact_editor/base.py:93\u001b[39m, in \u001b[36mArtifactEditorToolSpec.get_current_artifact\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_current_artifact\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Optional[\u001b[38;5;28mdict\u001b[39m]:\n\u001b[32m     92\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the current artifact instance.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcurrent_artifact\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_artifact \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VScode-projects/admonish-1/.venv/lib/python3.11/site-packages/pydantic/main.py:463\u001b[39m, in \u001b[36mBaseModel.model_dump\u001b[39m\u001b[34m(self, mode, include, exclude, context, by_alias, exclude_unset, exclude_defaults, exclude_none, round_trip, warnings, fallback, serialize_as_any)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_dump\u001b[39m(\n\u001b[32m    422\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    423\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    435\u001b[39m     serialize_as_any: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    436\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    437\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"!!! abstract \"Usage Documentation\"\u001b[39;00m\n\u001b[32m    438\u001b[39m \u001b[33;03m        [`model_dump`](../concepts/serialization.md#modelmodel_dump)\u001b[39;00m\n\u001b[32m    439\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    461\u001b[39m \u001b[33;03m        A dictionary representation of the model.\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_serializer__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mround_trip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mround_trip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialize_as_any\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserialize_as_any\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VScode-projects/admonish-1/.venv/lib/python3.11/site-packages/pydantic/main.py:988\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    986\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m, item):\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m         \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m    991\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VScode-projects/admonish-1/src/fateforger/agents/schedular/models/calendar.py:395\u001b[39m, in \u001b[36mCalendarEvent.colorId\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;129m@computed_field\u001b[39m\n\u001b[32m    392\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcolorId\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:  \u001b[38;5;66;03m# should not be part of the json schema\u001b[39;00m\n\u001b[32m    394\u001b[39m     \u001b[38;5;66;03m# uses the dynamic .color_id property on EventType\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     et = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevent_type\u001b[49m\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(et, \u001b[33m\"\u001b[39m\u001b[33mcolor_id\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VScode-projects/admonish-1/.venv/lib/python3.11/site-packages/pydantic/main.py:988\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    986\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m, item):\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m         \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m    991\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VScode-projects/admonish-1/.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:562\u001b[39m, in \u001b[36mInstrumentedAttribute.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m    561\u001b[39m dict_ = instance_dict(instance)\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43msupports_population\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.key \u001b[38;5;129;01min\u001b[39;00m dict_:\n\u001b[32m    563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dict_[\u001b[38;5;28mself\u001b[39m.key]  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'supports_population'"
     ]
    }
   ],
   "source": [
    "from datetime import time, timedelta\n",
    "from fateforger.agents.timeboxing.timebox import Timebox\n",
    "from fateforger.agents.schedular.models.calendar import CalendarEvent, EventType\n",
    "\n",
    "# Create proper validated objects then dump to dict (matching production MCP flow)\n",
    "# Use model_construct to bypass SQLAlchemy instrumentation in notebook context\n",
    "event = CalendarEvent.model_construct(\n",
    "    summary=\"Deep work\",\n",
    "    event_type=EventType.DEEP_WORK,\n",
    "    start_time=time(9, 0),\n",
    "    duration=timedelta(hours=2),\n",
    ")\n",
    "\n",
    "initial_timebox = Timebox.model_construct(events=[event])\n",
    "\n",
    "# Dump to dict, excluding computed fields that trigger SQLAlchemy\n",
    "initial_timebox_dict = initial_timebox.model_dump(\n",
    "    exclude={'events': {'__all__': {'colorId'}}}  # Exclude colorId computed field\n",
    ")\n",
    "\n",
    "model_client = build_autogen_chat_client(\"timebox_patcher\", model=model)\n",
    "timebox_patcher = ObjectPatcher(\n",
    "    Timebox,\n",
    "    model_client=model_client,\n",
    "    initial_state=initial_timebox_dict,\n",
    "    schema_by_alias=True,\n",
    ")\n",
    "\n",
    "timebox_instruction = (\n",
    "    \"Move the deep work to start at 10:00 and add a 30-minute buffer before it.\"\n",
    ")\n",
    "\n",
    "timebox_result = await timebox_patcher.run(timebox_instruction, max_attempts=3)\n",
    "timebox_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b15a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Output ---\n",
      "orders[3]{size,crust,toppings}:\n",
      "  Large,Thin,Pepperoni|Mushrooms|Onions\n",
      "  Medium,Stuffed,Sausage|Green Peppers\n",
      "  Small,Gluten-Free,Spinach|Feta|Black Olives\n",
      "Parsing Failed: 1 validation error for PizzaResponse\n",
      "orders.2.crust\n",
      "  Input should be 'Thin', 'Thick' or 'Stuffed' [type=literal_error, input_value='Gluten-Free', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/literal_error\n"
     ]
    }
   ],
   "source": [
    "import toon\n",
    "from typing import List, Literal\n",
    "from pydantic import BaseModel, Field, field_validator, AliasChoices\n",
    "import itertools\n",
    "from openai import OpenAI\n",
    "\n",
    "# 1. Global counter for IDs (The \"Factory\")\n",
    "id_iterator = itertools.count(101)\n",
    "\n",
    "class PizzaOrder(BaseModel):\n",
    "    # ID is now optional in the constructor so Pydantic can handle it\n",
    "    id: int = Field(default_factory=lambda: next(id_iterator))\n",
    "    size: Literal[\"Small\", \"Medium\", \"Large\"]\n",
    "    crust: Literal[\"Thin\", \"Thick\", \"Stuffed\"]\n",
    "    toppings: List[str]\n",
    "\n",
    "    @field_validator(\"toppings\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def split_pipes(cls, v):\n",
    "        if isinstance(v, str):\n",
    "            return [t.strip() for t in v.split(\"|\")]\n",
    "        return v\n",
    "\n",
    "class PizzaResponse(BaseModel):\n",
    "    orders: List[PizzaOrder]\n",
    "\n",
    "# 2. UPDATED GBNF: Notice 'id' is REMOVED from the row\n",
    "# This forces the LLM to only provide the 3 data points we need.\n",
    "pizza_gbnf = \"\"\"\n",
    "root      ::= header \":\" \"\\\\n\" row+\n",
    "header    ::= \"orders[\" [0-9]+ \"]{size,crust,toppings}\"\n",
    "row       ::= \"  \" size \",\" crust \",\" toppings \"\\\\n\"\n",
    "\n",
    "size      ::= \"Small\" | \"Medium\" | \"Large\"\n",
    "crust     ::= \"Thin\" | \"Thick\" | \"Stuffed\"\n",
    "toppings  ::= [a-zA-Z ]+ (\"|\" [a-zA-Z ]+)*\n",
    "\"\"\"\n",
    "# 2. Refined Prompt for proper TOON indentation\n",
    "system_prompt = f\"\"\"You are a data generator.\n",
    "Output strictly in TOON Tabular format.\n",
    "\n",
    "{toon.generate_structure_from_pydantic(PizzaOrder)}\n",
    "\n",
    "STRICT RULES:\n",
    "1. Every row MUST be indented with exactly TWO SPACES.\n",
    "2. Format: \n",
    "orders[count]{{size,crust,toppings}}:\n",
    "  value,value,value\n",
    "  value,value,value\n",
    "\n",
    "3. No keys, no quotes, use '|' for toppings.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"Generate 3 random pizza orders.\"}\n",
    "    ],\n",
    "    extra_body={\n",
    "        \"guided_grammar\": pizza_gbnf,\n",
    "        \"guided_decoding_backend\": \"xgrammar\"\n",
    "    }\n",
    ")\n",
    "\n",
    "raw_output = response.choices[0].message.content\n",
    "print(f\"--- Model Output ---\\n{raw_output}\")\n",
    "\n",
    "# 4. Decode\n",
    "# 4. Decode - FIXED: Use the wrapper class, then iterate through the .orders list\n",
    "try:\n",
    "    # This will now auto-assign IDs 101, 102, 103\n",
    "    validated_response = toon.decode_to_pydantic(raw_output, PizzaResponse)\n",
    "    \n",
    "    for o in validated_response.orders:\n",
    "        print(f\"ID {o.id} (Auto): {o.size} {o.crust} - {o.toppings}\")\n",
    "except Exception as e:\n",
    "    print(f\"Parsing Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and validate the TOON string back to Pydantic objects\n",
    "try:\n",
    "    orders = decode_to_pydantic(toon_output, PizzaOrder)\n",
    "    for order in orders:\n",
    "        print(f\"Validated Order: {order.id} - {order.size} {order.crust} pizza\")\n",
    "except Exception as e:\n",
    "    print(f\"Validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb996db",
   "metadata": {},
   "source": [
    "getting up at 9, its valentines day so we should do brunch, go to the market, light work after brunch, gym.\n",
    "so i think lets order it like getting up, oats, mayve some light work, gym, brunch (around 11, 12?) and we need to do some groceries at the market, then get back and i want to do some work on ticketing and mapping c2f, and then valentines cooking dinner together around 18:00, dinner,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b7eff6",
   "metadata": {},
   "source": [
    "the one thing os to make a backlog for the C2F engine and the custom work for my client, and maybe try setting up some experiments or marketing and sales leads (like bart scheerder), o and i definitely have to respond to that professor guy.\n",
    " my DW blocks are usually 2 hours long..\n",
    "so we have a max of two blocks (for this specific day, right?) with a small break in the middle, quesiton is how we are going to distribute that.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fateforger-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
