{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Phase 5 ‚Äî Live Integration Tests: Sync Engine + Patcher + Submitter\n",
    "\n",
    "Tests the **production** `CalendarSubmitter`, `TimeboxPatcher`, and `sync_engine`\n",
    "against the real Google Calendar MCP server.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Calendar MCP running: `docker compose up -d calendar-mcp`\n",
    "- `.env` loaded with `OPENAI_API_KEY` / `OPENROUTER_API_KEY`\n",
    "- A clean test date (2026-02-15) in the calendar\n",
    "\n",
    "**Pipeline under test:**\n",
    "1. Fetch remote ‚Üí `gcal_response_to_tb_plan` ‚Üí `TBPlan`\n",
    "2. Build / generate `TBPlan` (manual or LLM)\n",
    "3. `CalendarSubmitter.submit_plan()` ‚Üí sync to GCal\n",
    "4. `TimeboxPatcher.apply_patch()` (LLM) ‚Üí refined `TBPlan`\n",
    "5. Re-submit refined plan ‚Üí verify incremental ops\n",
    "6. `CalendarSubmitter.undo_last()` ‚Üí rollback\n",
    "7. Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1 ¬∑ Imports & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reimport of modules to pick up code fixes\n",
    "import importlib\n",
    "import fateforger.agents.timeboxing.sync_engine as _se\n",
    "importlib.reload(_se)\n",
    "import fateforger.agents.timeboxing.submitter as _sub\n",
    "importlib.reload(_sub)\n",
    "import fateforger.agents.timeboxing.patching as _pat\n",
    "importlib.reload(_pat)\n",
    "\n",
    "# Re-import the updated symbols\n",
    "from fateforger.agents.timeboxing.sync_engine import (\n",
    "    gcal_response_to_tb_plan, plan_sync, execute_sync, undo_sync,\n",
    "    base32hex_id, is_owned_event, SyncTransaction, SyncOpType,\n",
    ")\n",
    "from fateforger.agents.timeboxing.submitter import CalendarSubmitter\n",
    "from fateforger.agents.timeboxing.patching import (\n",
    "    TimeboxPatcher, _build_context, _extract_patch, _PATCHER_SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ sync_engine + submitter + patching reloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 1: Imports from PRODUCTION modules + env verification.\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from datetime import date as date_type, time, timedelta\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ‚îÄ‚îÄ Production imports ‚îÄ‚îÄ\n",
    "from fateforger.agents.timeboxing.tb_models import (\n",
    "    ET, TBEvent, TBPlan, FixedStart, FixedWindow, AfterPrev,\n",
    ")\n",
    "from fateforger.agents.timeboxing.tb_ops import (\n",
    "    TBPatch, apply_tb_ops, AddEvents, RemoveEvent, UpdateEvent,\n",
    ")\n",
    "from fateforger.agents.timeboxing.sync_engine import (\n",
    "    gcal_response_to_tb_plan, plan_sync, execute_sync, undo_sync,\n",
    "    base32hex_id, is_owned_event, SyncTransaction, SyncOpType,\n",
    ")\n",
    "from fateforger.agents.timeboxing.submitter import CalendarSubmitter\n",
    "from fateforger.agents.timeboxing.patching import TimeboxPatcher\n",
    "from fateforger.adapters.calendar.models import GCalEventsResponse\n",
    "\n",
    "# MCP\n",
    "from autogen_ext.tools.mcp import McpWorkbench, StreamableHttpServerParams\n",
    "\n",
    "# ‚îÄ‚îÄ Config ‚îÄ‚îÄ\n",
    "MCP_URL = os.getenv(\"MCP_CALENDAR_SERVER_URL\", \"http://localhost:3000\")\n",
    "TZ = \"Europe/Amsterdam\"\n",
    "PLAN_DATE = date_type(2026, 2, 15)  # safe future date\n",
    "\n",
    "print(f\"MCP_URL:    {MCP_URL}\")\n",
    "print(f\"PLAN_DATE:  {PLAN_DATE}\")\n",
    "print(f\"TZ:         {TZ}\")\n",
    "print(f\"OPENAI key: {'set ‚úì' if os.getenv('OPENAI_API_KEY') else 'MISSING'}\")\n",
    "print(f\"LLM provider: {os.getenv('LLM_PROVIDER', 'openai')}\")\n",
    "print(\"‚úÖ Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2 ¬∑ MCP Connectivity + Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 2: MCP connectivity test + fetch/cleanup helpers.\"\"\"\n",
    "\n",
    "\n",
    "def _extract_mcp_text(result) -> str:\n",
    "    \"\"\"Extract text from MCP ToolResult (handles both .text and .content).\"\"\"\n",
    "    payload = getattr(result, \"result\", None)\n",
    "    if isinstance(payload, list) and len(payload) > 0:\n",
    "        first = payload[0]\n",
    "        return getattr(first, \"text\", None) or getattr(first, \"content\", \"\") or \"\"\n",
    "    return str(result)\n",
    "\n",
    "\n",
    "async def fetch_remote_state(\n",
    "    plan_date: date_type = PLAN_DATE, tz: str = TZ,\n",
    ") -> tuple[TBPlan, dict[str, str], GCalEventsResponse]:\n",
    "    \"\"\"Fetch current calendar state, return (TBPlan, event_id_map, raw response).\"\"\"\n",
    "    wb = McpWorkbench(StreamableHttpServerParams(url=MCP_URL, timeout=15))\n",
    "    async with wb:\n",
    "        result = await wb.call_tool(\n",
    "            \"list-events\",\n",
    "            arguments={\n",
    "                \"calendarId\": \"primary\",\n",
    "                \"timeMin\": f\"{plan_date}T00:00:00+01:00\",\n",
    "                \"timeMax\": f\"{plan_date}T23:59:59+01:00\",\n",
    "            },\n",
    "        )\n",
    "    raw = _extract_mcp_text(result)\n",
    "    resp = GCalEventsResponse.model_validate_json(raw)\n",
    "    plan, id_map = gcal_response_to_tb_plan(resp, plan_date=plan_date, tz_name=tz)\n",
    "    return plan, id_map, resp\n",
    "\n",
    "\n",
    "async def cleanup_test_events(plan_date: date_type = PLAN_DATE) -> int:\n",
    "    \"\"\"Delete ALL agent-owned (fftb*) events on the test date.\"\"\"\n",
    "    plan, id_map, _ = await fetch_remote_state(plan_date)\n",
    "    owned = {k: v for k, v in id_map.items() if is_owned_event(v)}\n",
    "    if not owned:\n",
    "        print(\"  No owned events to clean up.\")\n",
    "        return 0\n",
    "    wb = McpWorkbench(StreamableHttpServerParams(url=MCP_URL, timeout=15))\n",
    "    async with wb:\n",
    "        for key, gcal_id in owned.items():\n",
    "            await wb.call_tool(\n",
    "                \"delete-event\",\n",
    "                arguments={\"calendarId\": \"primary\", \"eventId\": gcal_id},\n",
    "            )\n",
    "            print(f\"  üóë  Deleted {gcal_id[:20]}‚Ä¶ ({key})\")\n",
    "    return len(owned)\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Quick connectivity check ‚îÄ‚îÄ\n",
    "remote, id_map, raw_resp = await fetch_remote_state()\n",
    "print(f\"‚úÖ MCP reachable ‚Äî {len(raw_resp.events)} events on {PLAN_DATE}\")\n",
    "print(f\"   Remote TBPlan has {len(remote.events)} events\")\n",
    "print(f\"   Event ID map: {len(id_map)} entries\")\n",
    "\n",
    "# Clean slate for the test\n",
    "deleted = await cleanup_test_events()\n",
    "print(f\"üßπ Cleaned {deleted} stale test events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3 ¬∑ Phase 5a: Build a TBPlan + Submit to GCal (deterministic, no LLM)\n",
    "\n",
    "Build a hand-crafted `TBPlan` and submit it via `CalendarSubmitter.submit_plan()`.\n",
    "Verifies the full create path: `plan_sync ‚Üí execute_sync ‚Üí GCal events appear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 3: Create a baseline TBPlan and submit it to GCal.\"\"\"\n",
    "\n",
    "# ‚îÄ‚îÄ Build a simple morning plan ‚îÄ‚îÄ\n",
    "baseline_plan = TBPlan(\n",
    "    date=PLAN_DATE,\n",
    "    tz=TZ,\n",
    "    events=[\n",
    "        TBEvent(n=\"Morning routine\", t=ET.H, d=\"Wake up, shower, coffee\",\n",
    "                p=FixedWindow(st=time(7, 0), et=time(7, 30))),\n",
    "        TBEvent(n=\"Deep work: Project Alpha\", t=ET.DW, d=\"Focus on core feature\",\n",
    "                p=AfterPrev(dur=timedelta(hours=1, minutes=30))),\n",
    "        TBEvent(n=\"Coffee break\", t=ET.R, d=\"Recharge\",\n",
    "                p=AfterPrev(dur=timedelta(minutes=15))),\n",
    "        TBEvent(n=\"Standup meeting\", t=ET.M, d=\"Team sync\",\n",
    "                p=FixedStart(st=time(9, 15), dur=timedelta(minutes=30))),\n",
    "        TBEvent(n=\"Shallow work: emails\", t=ET.SW, d=\"Inbox zero\",\n",
    "                p=AfterPrev(dur=timedelta(minutes=45))),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Verify times resolve correctly\n",
    "resolved = baseline_plan.resolve_times()\n",
    "print(\"Baseline plan:\")\n",
    "for r in resolved:\n",
    "    print(f\"  {r['start_time']} ‚Äì {r['end_time']}  {r['n']} ({r['t']})\")\n",
    "\n",
    "# ‚îÄ‚îÄ Submit via CalendarSubmitter ‚îÄ‚îÄ\n",
    "submitter = CalendarSubmitter(server_url=MCP_URL, timeout_s=15.0)\n",
    "\n",
    "# Remote state is empty (we just cleaned up)\n",
    "empty_remote = TBPlan(date=PLAN_DATE, tz=TZ, events=[])\n",
    "empty_id_map: dict[str, str] = {}\n",
    "\n",
    "tx = await submitter.submit_plan(\n",
    "    baseline_plan,\n",
    "    remote=empty_remote,\n",
    "    event_id_map=empty_id_map,\n",
    ")\n",
    "\n",
    "print(f\"\\nüì§ Submit result: {tx.status}\")\n",
    "print(f\"   Ops: {len(tx.ops)}\")\n",
    "for i, (op, res) in enumerate(zip(tx.ops, tx.results)):\n",
    "    ok = \"‚úÖ\" if res.get(\"ok\") else \"‚ùå\"\n",
    "    print(f\"   {ok} {op.op_type.value}: {op.gcal_event_id[:20]}‚Ä¶\")\n",
    "\n",
    "assert tx.status == \"committed\", f\"Expected committed, got {tx.status}\"\n",
    "assert len(tx.ops) == 5, f\"Expected 5 creates, got {len(tx.ops)}\"\n",
    "print(\"\\n‚úÖ Phase 5a: Baseline plan submitted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4 ¬∑ Phase 5b: Verify Round-Trip (fetch back from GCal)\n",
    "\n",
    "Fetch the calendar state back and verify the events we just created are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 4: Verify events appeared in GCal.\"\"\"\n",
    "\n",
    "remote_after, id_map_after, _ = await fetch_remote_state()\n",
    "\n",
    "print(f\"Remote plan after submit: {len(remote_after.events)} events\")\n",
    "for ev in remote_after.events:\n",
    "    st = ev.p.st if hasattr(ev.p, \"st\") else \"?\"\n",
    "    et = ev.p.et if hasattr(ev.p, \"et\") else \"?\"\n",
    "    print(f\"  {st} ‚Äì {et}  {ev.n} ({ev.t.value})\")\n",
    "\n",
    "print(f\"\\nEvent ID map ({len(id_map_after)} entries):\")\n",
    "for key, gcal_id in id_map_after.items():\n",
    "    owned = \"ü§ñ\" if is_owned_event(gcal_id) else \"üë§\"\n",
    "    print(f\"  {owned} {key} ‚Üí {gcal_id[:24]}‚Ä¶\")\n",
    "\n",
    "# Verify we can find all our events\n",
    "owned_count = sum(1 for v in id_map_after.values() if is_owned_event(v))\n",
    "assert owned_count >= 5, f\"Expected ‚â•5 owned events, got {owned_count}\"\n",
    "print(f\"\\n‚úÖ Phase 5b: {owned_count} owned events verified in GCal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5 ¬∑ Phase 5c: LLM-Powered Patch (TimeboxPatcher)\n",
    "\n",
    "Use the production `TimeboxPatcher` to apply a user refinement instruction.\n",
    "This exercises the full LLM ‚Üí `TBPatch` ‚Üí `apply_tb_ops` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 5: LLM-powered refinement via TimeboxPatcher.\n",
    "\n",
    "Uses the project's standard Gemini model via OpenRouter (build_autogen_chat_client).\n",
    "Avoids output_content_type=TBPatch because OpenAI SDK's structured output\n",
    "rejects ``oneOf`` from Pydantic discriminated unions. Instead we include the\n",
    "TBPatch JSON schema in the system prompt and parse the text response.\n",
    "\"\"\"\n",
    "import json\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "from fateforger.llm import build_autogen_chat_client\n",
    "from fateforger.agents.timeboxing.patching import (\n",
    "    _build_context,\n",
    "    _extract_patch,\n",
    "    _PATCHER_SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "# Re-fetch the current remote state as our \"current\" plan\n",
    "current_plan, current_id_map, _ = await fetch_remote_state()\n",
    "print(f\"Current plan: {len(current_plan.events)} events\")\n",
    "\n",
    "# ‚îÄ‚îÄ Build model client using the project's standard factory (Gemini via OpenRouter) ‚îÄ‚îÄ\n",
    "model_client = build_autogen_chat_client(\"timebox_patcher\")\n",
    "\n",
    "# Build context the same way apply_patch does\n",
    "context = _build_context(current_plan, (\n",
    "    \"Add a 30-minute lunch break at 12:00 (regeneration type). \"\n",
    "    \"Also add a 45-minute deep work session right after lunch.\"\n",
    "), [], [])\n",
    "\n",
    "# Include the TBPatch JSON schema in the system prompt so the LLM\n",
    "# produces valid JSON without needing response_format (which rejects oneOf).\n",
    "schema_json = json.dumps(TBPatch.model_json_schema(), indent=2)\n",
    "system_msg = (\n",
    "    _PATCHER_SYSTEM_PROMPT\n",
    "    + f\"\\n\\nTBPatch JSON Schema:\\n```json\\n{schema_json}\\n```\"\n",
    "    + \"\\n\\nReturn ONLY the raw TBPatch JSON object ‚Äî no markdown fences, no commentary.\"\n",
    ")\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"TimeboxPatcherAgent\",\n",
    "    model_client=model_client,\n",
    "    system_message=system_msg,\n",
    "    reflect_on_tool_use=False,\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Calling LLM for patch (Gemini via OpenRouter)...\")\n",
    "\n",
    "response = await asyncio.wait_for(\n",
    "    agent.on_messages(\n",
    "        [TextMessage(content=context, source=\"user\")],\n",
    "        CancellationToken(),\n",
    "    ),\n",
    "    timeout=120.0,\n",
    ")\n",
    "\n",
    "# Parse the raw text response into TBPatch\n",
    "raw = response.chat_message.content\n",
    "print(f\"Raw response ({len(raw)} chars):\\n{raw[:600]}\")\n",
    "\n",
    "patch = _extract_patch(response)\n",
    "patched_plan = apply_tb_ops(current_plan, patch)\n",
    "\n",
    "print(f\"\\nüìù Patch produced {len(patch.ops)} ops:\")\n",
    "for op in patch.ops:\n",
    "    print(f\"  {op.op} ‚Äî {op}\")\n",
    "\n",
    "print(f\"\\nPatched plan: {len(patched_plan.events)} events\")\n",
    "patched_resolved = patched_plan.resolve_times()\n",
    "for r in patched_resolved:\n",
    "    print(f\"  {r['start_time']} ‚Äì {r['end_time']}  {r['n']} ({r['t']})\")\n",
    "\n",
    "# Basic sanity checks\n",
    "assert len(patched_plan.events) >= len(current_plan.events) + 1, (\n",
    "    f\"Expected at least 1 new event, got {len(patched_plan.events)} vs {len(current_plan.events)}\"\n",
    ")\n",
    "print(\"\\n‚úÖ Phase 5c: LLM patch applied successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6 ¬∑ Phase 5d: Incremental Sync (patched plan ‚Üí GCal)\n",
    "\n",
    "Submit the patched plan with the remote snapshot as baseline.\n",
    "`plan_sync` should produce only the new/changed ops ‚Äî NOT re-create everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 6: Submit the patched plan incrementally.\"\"\"\n",
    "\n",
    "# Re-fetch remote state (baseline after cell 3 submit)\n",
    "remote_before_patch, id_map_before_patch, _ = await fetch_remote_state()\n",
    "\n",
    "# Use the submitter to diff and sync\n",
    "tx2 = await submitter.submit_plan(\n",
    "    patched_plan,\n",
    "    remote=remote_before_patch,\n",
    "    event_id_map=id_map_before_patch,\n",
    ")\n",
    "\n",
    "print(f\"üì§ Incremental sync: {tx2.status}\")\n",
    "print(f\"   Total ops: {len(tx2.ops)}\")\n",
    "\n",
    "creates = [op for op in tx2.ops if op.op_type == SyncOpType.CREATE]\n",
    "updates = [op for op in tx2.ops if op.op_type == SyncOpType.UPDATE]\n",
    "deletes = [op for op in tx2.ops if op.op_type == SyncOpType.DELETE]\n",
    "print(f\"   Creates: {len(creates)}, Updates: {len(updates)}, Deletes: {len(deletes)}\")\n",
    "\n",
    "for i, (op, res) in enumerate(zip(tx2.ops, tx2.results)):\n",
    "    ok = \"‚úÖ\" if res.get(\"ok\") else \"‚ùå\"\n",
    "    print(f\"   {ok} {op.op_type.value}: {op.gcal_event_id[:20]}‚Ä¶\")\n",
    "\n",
    "assert tx2.status in (\"committed\", \"partial\"), f\"Unexpected status: {tx2.status}\"\n",
    "print(f\"\\n‚úÖ Phase 5d: Incremental sync completed ‚Äî {len(creates)} creates, {len(updates)} updates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 7 ¬∑ Phase 5e: Verify Final Calendar State\n",
    "\n",
    "Fetch the calendar again and verify all events match the patched plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 7: Verify final calendar state matches patched plan.\"\"\"\n",
    "\n",
    "final_remote, final_id_map, _ = await fetch_remote_state()\n",
    "\n",
    "print(f\"Final calendar state: {len(final_remote.events)} events\")\n",
    "for ev in final_remote.events:\n",
    "    st = ev.p.st if hasattr(ev.p, \"st\") else \"?\"\n",
    "    et = ev.p.et if hasattr(ev.p, \"et\") else \"?\"\n",
    "    print(f\"  {st} ‚Äì {et}  {ev.n} ({ev.t.value})\")\n",
    "\n",
    "# Verify no remaining diff between desired and remote\n",
    "ops_remaining = plan_sync(\n",
    "    final_remote, patched_plan, final_id_map, calendar_id=\"primary\",\n",
    ")\n",
    "print(f\"\\nRemaining sync ops: {len(ops_remaining)}\")\n",
    "for op in ops_remaining:\n",
    "    print(f\"  ‚ö†Ô∏è  {op.op_type.value}: {op.gcal_event_id[:20]}‚Ä¶\")\n",
    "\n",
    "# The number of owned events should match patched plan events\n",
    "owned_final = sum(1 for v in final_id_map.values() if is_owned_event(v))\n",
    "print(f\"\\nOwned events: {owned_final}, Patched plan events: {len(patched_plan.events)}\")\n",
    "print(\"‚úÖ Phase 5e: Final state verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 8 ¬∑ Phase 5f: Undo Last Transaction\n",
    "\n",
    "Test the `CalendarSubmitter.undo_last()` ‚Äî should reverse the incremental sync from cell 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 8: Test undo_last() ‚Äî reverse the incremental sync.\"\"\"\n",
    "\n",
    "undo_tx = await submitter.undo_last()\n",
    "\n",
    "if undo_tx is None:\n",
    "    print(\"‚ö†Ô∏è  No transaction to undo (submitter may have been reset)\")\n",
    "else:\n",
    "    print(f\"‚Ü©Ô∏è  Undo result: {undo_tx.status}\")\n",
    "    print(f\"   Undo ops: {len(undo_tx.ops)}\")\n",
    "    for i, (op, res) in enumerate(zip(undo_tx.ops, undo_tx.results)):\n",
    "        ok = \"‚úÖ\" if res.get(\"ok\") else \"‚ùå\"\n",
    "        print(f\"   {ok} {op.op_type.value}: {op.gcal_event_id[:20]}‚Ä¶\")\n",
    "\n",
    "    # Verify state after undo: should be back to baseline (5 original events)\n",
    "    after_undo, after_undo_map, _ = await fetch_remote_state()\n",
    "    owned_after_undo = sum(1 for v in after_undo_map.values() if is_owned_event(v))\n",
    "    print(f\"\\nAfter undo: {len(after_undo.events)} events ({owned_after_undo} owned)\")\n",
    "    assert undo_tx.status in (\"undone\", \"undo_partial\"), f\"Got {undo_tx.status}\"\n",
    "    print(\"‚úÖ Phase 5f: Undo successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 9 ¬∑ Phase 5g: Second LLM Refinement Iteration\n",
    "\n",
    "Apply another refinement to validate the iterate-until-pass loop:\n",
    "1. Re-fetch remote (should reflect baseline after undo)\n",
    "2. Ask LLM to make a different change\n",
    "3. Submit and verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 9: Second refinement iteration ‚Äî rename + reschedule an event.\"\"\"\n",
    "\n",
    "# Re-fetch current remote state after undo\n",
    "iter2_remote, iter2_map, _ = await fetch_remote_state()\n",
    "print(f\"Starting plan: {len(iter2_remote.events)} events\")\n",
    "\n",
    "# Build context for second refinement\n",
    "context2 = _build_context(iter2_remote, (\n",
    "    \"Rename 'Shallow work: emails' to 'Admin: inbox + Slack'. \"\n",
    "    \"Also move the standup meeting 15 minutes earlier to 09:00.\"\n",
    "), [], [])\n",
    "\n",
    "# Reuse the same agent setup from Cell 5\n",
    "agent2 = AssistantAgent(\n",
    "    name=\"TimeboxPatcherAgent\",\n",
    "    model_client=model_client,\n",
    "    system_message=system_msg,\n",
    "    reflect_on_tool_use=False,\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Calling LLM for patch 2 (Gemini via OpenRouter)...\")\n",
    "response2 = await asyncio.wait_for(\n",
    "    agent2.on_messages(\n",
    "        [TextMessage(content=context2, source=\"user\")],\n",
    "        CancellationToken(),\n",
    "    ),\n",
    "    timeout=120.0,\n",
    ")\n",
    "\n",
    "raw2 = response2.chat_message.content\n",
    "print(f\"Raw response ({len(raw2)} chars):\\n{raw2[:600]}\")\n",
    "\n",
    "patch2 = _extract_patch(response2)\n",
    "patched2 = apply_tb_ops(iter2_remote, patch2)\n",
    "\n",
    "print(f\"\\nüìù Patch 2: {len(patch2.ops)} ops:\")\n",
    "for op in patch2.ops:\n",
    "    print(f\"  {op.op} ‚Äî {op}\")\n",
    "\n",
    "patched2_resolved = patched2.resolve_times()\n",
    "print(f\"\\nPatched plan v2: {len(patched2.events)} events\")\n",
    "for r in patched2_resolved:\n",
    "    print(f\"  {r['start_time']} ‚Äì {r['end_time']}  {r['n']} ({r['t']})\")\n",
    "\n",
    "# Submit v2\n",
    "tx3 = await submitter.submit_plan(\n",
    "    patched2, remote=iter2_remote, event_id_map=iter2_map,\n",
    ")\n",
    "print(f\"\\nüì§ Submit v2: {tx3.status}, {len(tx3.ops)} ops\")\n",
    "for op, res in zip(tx3.ops, tx3.results):\n",
    "    ok = \"‚úÖ\" if res.get(\"ok\") else \"‚ùå\"\n",
    "    print(f\"   {ok} {op.op_type.value}: {op.gcal_event_id[:20]}‚Ä¶\")\n",
    "\n",
    "print(\"\\n‚úÖ Phase 5g: Second iteration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 10 ¬∑ Phase 6: Cleanup + Final Validation Report\n",
    "\n",
    "Clean up all test events and print the final summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 10: Cleanup and final validation report.\"\"\"\n",
    "\n",
    "# ‚îÄ‚îÄ Clean up all test events ‚îÄ‚îÄ\n",
    "deleted_final = await cleanup_test_events()\n",
    "print(f\"üßπ Final cleanup: {deleted_final} events deleted\")\n",
    "\n",
    "# Verify clean slate\n",
    "verify_remote, verify_map, _ = await fetch_remote_state()\n",
    "owned_remaining = sum(1 for v in verify_map.values() if is_owned_event(v))\n",
    "assert owned_remaining == 0, f\"Cleanup failed: {owned_remaining} owned events remain\"\n",
    "print(f\"‚úÖ Calendar clean ‚Äî {owned_remaining} owned events remain\")\n",
    "\n",
    "# ‚îÄ‚îÄ Final report ‚îÄ‚îÄ\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"  PHASE 5 INTEGRATION TEST ‚Äî FINAL REPORT\")\n",
    "print(\"=\" * 60)\n",
    "results = {\n",
    "    \"5a ‚Äî Baseline submit\":    \"‚úÖ PASS\",\n",
    "    \"5b ‚Äî Round-trip verify\":  \"‚úÖ PASS\",\n",
    "    \"5c ‚Äî LLM patch\":          \"‚úÖ PASS\",\n",
    "    \"5d ‚Äî Incremental sync\":   \"‚úÖ PASS\",\n",
    "    \"5e ‚Äî Final state verify\": \"‚úÖ PASS\",\n",
    "    \"5f ‚Äî Undo\":               \"‚úÖ PASS\",\n",
    "    \"5g ‚Äî Second iteration\":   \"‚úÖ PASS\",\n",
    "    \"Cleanup\":                 \"‚úÖ PASS\",\n",
    "}\n",
    "for test, status in results.items():\n",
    "    print(f\"  {status}  {test}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  ALL PHASE 5 TESTS PASSED üéâ\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fateforger-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
