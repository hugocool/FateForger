# Decision Log

| Date | Decision | Rationale |
|------|----------|-----------|
| 2025-07-19 | Use AutoGen AssistantAgent with MCP integration for calendar operations | User explicitly required "no bypassing AutoGen MCP system" and "no manual HTTP calls". Must use AutoGen's built-in MCP tools, not custom implementations or direct API calls. User was frustrated with repeated violations of this architectural choice. |
| 2025-07-20 | Implement Ticket #1: Data contracts and hand-off stub for AutoGen Sequential Workflow | User provided detailed specification for a 7-ticket project to create a structured multi-agent calendar pipeline. Starting with Ticket #1 to establish the foundational data models (PlanDiff, CalendarOp) and sync_plan_to_calendar stub function that will enable LLMs to emit structured Pydantic output and route messages through AutoGen's runtime topics. |
| 2025-07-20 | Implement Ticket #2: PlannerAgent structured JSON output with calendar diffing | User provided complete specification for updating PlannerAgent to use AutoGen's json_output=PlanDiff for structured output, integrate list-events MCP tool for calendar fetching, and implement CREATE/UPDATE/DELETE diff logic. This enables LLMs to emit validated Pydantic models directly without manual JSON parsing. |
| 2025-07-22 | Successfully integrated Notion MCP server with VS Code Copilot | The Notion MCP server is now authenticated and accessible through VS Code Copilot tools, enabling direct interaction with Notion pages, databases, and content management within the development environment. This provides seamless project documentation and task management capabilities. |
| 2025-07-28 | Fixed SQLModel JSON column support for complex Pydantic objects | SQLModel requires sa_column=Column(JSON) for complex types like nested Pydantic models in table=True classes. This allows storing CreatorOrganizer, EventDateTime, and other complex objects as JSON in the database instead of trying to serialize them as primitive SQLAlchemy types. |
| 2025-07-28 | Implemented nested Pydantic models with JSON columns instead of raw Dict types | User correctly pointed out that SQLModel supports nested Pydantic models with sa_column=Column(JSON), which provides type safety, validation, and auto-completion while storing efficiently as JSON. This is much better than raw Dict types which lose all type information and validation. |
| 2025-07-29 | Converted ScheduleDraft from JSON-based events storage to proper relational one-to-many model | Benefits: (1) Full CRUD on individual events instead of JSON blob updates, (2) Easy querying/filtering on event fields using SQL WHERE clauses, (3) Automatic cascade deletes, (4) No JSON serialization complexity, (5) True relational database design. Trade-off: SQLAlchemy 2.0 relationship syntax is complex in SQLModel, but the foreign key works perfectly for all practical purposes. |
| 2025-07-30 | Added TickTick MCP server to Docker Compose infrastructure following the same pattern as Google Calendar MCP | Provides task management capabilities alongside calendar functionality. Uses the same architectural patterns for consistency - separate MCP service container, proper networking, health checks, and volume persistence for OAuth tokens. Integrates with existing AutoGen MCP system as required by user's explicit choices. |
| 2025-07-31 | MCP library version 1.12.2 is latest - no version 2.0+ exists yet | User mentioned pinning to "2.0+" but PyPI shows 1.12.2 as latest. Container shows correct version. API compatibility issue is due to incorrect parameter usage, not version mismatch |
| 2025-07-31 | Use streamable-http transport for TickTick MCP service | Streamable HTTP is the modern transport superseding SSE for production deployments. It supports both stateful and stateless operation modes with better scalability for multi-node deployments |
| 2025-07-31 | TickTick MCP URL endpoint requires /mcp suffix for proper connection | Hugo discovered that AutoGen's MCP client needs the full endpoint URL including '/mcp' path (http://localhost:8150/mcp) rather than just the base URL (http://localhost:8150). This fixed the SSE transport connection issues we were troubleshooting. |
